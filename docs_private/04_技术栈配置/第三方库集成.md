# 第三方库集成

- **标题**: AI协作开发第三方库集成管理指南
- **当前版本**: v1.0
- **最后更新**: 2025-09-10
- **负责人**: Kelin

---

## 依赖管理策略

### 🎯 库分类和优先级

#### 核心依赖库 (Critical)
```yaml
tier_1_dependencies:
  boost:
    priority: "critical"
    replacement_cost: "very_high"
    integration_complexity: "medium"
    reason: "核心系统基础库，filesystem、thread、asio等关键功能"

  cuda_toolkit:
    priority: "critical"
    replacement_cost: "very_high"
    integration_complexity: "high"
    reason: "GPU加速计算核心，无可替代"

  yaml_cpp:
    priority: "critical"
    replacement_cost: "low"
    integration_complexity: "low"
    reason: "配置文件解析，可替代但成本低"

  spdlog:
    priority: "critical"
    replacement_cost: "medium"
    integration_complexity: "low"
    reason: "高性能日志库，有替代方案但切换成本中等"
```

#### 功能增强库 (Important)
```yaml
tier_2_dependencies:
  opengl:
    priority: "important"
    replacement_cost: "high"
    integration_complexity: "high"
    reason: "图形渲染核心，替代方案复杂"

  glfw:
    priority: "important"
    replacement_cost: "medium"
    integration_complexity: "medium"
    reason: "窗口管理，有其他选择如SDL2"

  eigen3:
    priority: "important"
    replacement_cost: "medium"
    integration_complexity: "medium"
    reason: "线性代数库，可选择Intel MKL或OpenBLAS"

  imgui:
    priority: "important"
    replacement_cost: "medium"
    integration_complexity: "low"
    reason: "调试界面，开发阶段重要，可选"
```

#### 开发工具库 (Optional)
```yaml
tier_3_dependencies:
  googletest:
    priority: "optional"
    replacement_cost: "low"
    integration_complexity: "low"
    reason: "测试框架，有多种替代方案"

  google_benchmark:
    priority: "optional"
    replacement_cost: "low"
    integration_complexity: "low"
    reason: "性能测试，非生产必需"

  intel_mkl:
    priority: "optional"
    replacement_cost: "low"
    integration_complexity: "medium"
    reason: "数学库优化，性能提升但非必需"
```

### 📦 包管理器集成

#### vcpkg 主要配置
```json
{
  "name": "radar-mvp-system",
  "version": "1.0.0",
  "dependencies": [
    {
      "name": "boost",
      "version>=": "1.75.0",
      "default-features": false,
      "features": ["system", "filesystem", "thread", "program-options", "asio"]
    },
    {
      "name": "yaml-cpp",
      "version>=": "0.7.0"
    },
    {
      "name": "spdlog",
      "version>=": "1.9.0",
      "default-features": false,
      "features": ["std_format"]
    },
    {
      "name": "glfw3",
      "version>=": "3.3.0"
    },
    {
      "name": "glew",
      "version>=": "2.2.0"
    },
    {
      "name": "eigen3",
      "version>=": "3.4.0"
    }
  ],
  "features": {
    "gui": {
      "description": "Enable GUI components",
      "dependencies": [
        {
          "name": "imgui",
          "version>=": "1.89.0",
          "features": ["opengl3-binding", "glfw-binding"]
        }
      ]
    },
    "testing": {
      "description": "Enable testing frameworks",
      "dependencies": [
        {
          "name": "gtest",
          "version>=": "1.12.0"
        },
        {
          "name": "benchmark",
          "version>=": "1.7.0"
        }
      ]
    },
    "performance": {
      "description": "Enable performance optimizations",
      "dependencies": [
        {
          "name": "intel-mkl",
          "platform": "x64 & !osx"
        }
      ]
    }
  },
  "builtin-baseline": "2023.08.09"
}
```

#### Conan 备用配置
```python
# conanfile.py
from conan import ConanFile
from conan.tools.cmake import CMakeToolchain, CMakeDeps
from conan.tools.files import copy


class RadarMvpConan(ConanFile):
    settings = "os", "compiler", "build_type", "arch"

    options = {
        "shared": [True, False],
        "with_gui": [True, False],
        "with_mkl": [True, False],
        "with_cuda": [True, False]
    }

    default_options = {
        "shared": False,
        "with_gui": True,
        "with_mkl": False,
        "with_cuda": True
    }

    def requirements(self):
        # 核心依赖
        self.requires("boost/1.82.0")
        self.requires("yaml-cpp/0.7.0")
        self.requires("spdlog/1.12.0")

        # 数学库
        self.requires("eigen/3.4.0")
        if self.options.with_mkl:
            self.requires("intel-oneapi-mkl/2023.1.0")

        # GUI依赖
        if self.options.with_gui:
            self.requires("glfw/3.3.8")
            self.requires("glew/2.2.0")
            self.requires("imgui/1.89.9")

    def build_requirements(self):
        self.test_requires("gtest/1.13.0")
        self.test_requires("benchmark/1.8.0")

    def configure(self):
        # 配置选项依赖
        if not self.options.with_gui:
            del self.options.imgui

        # Windows特定配置
        if self.settings.os == "Windows":
            self.options["boost"].shared = True

    def generate(self):
        tc = CMakeToolchain(self)
        tc.variables["WITH_GUI"] = self.options.with_gui
        tc.variables["WITH_MKL"] = self.options.with_mkl
        tc.variables["WITH_CUDA"] = self.options.with_cuda
        tc.generate()

        deps = CMakeDeps(self)
        deps.generate()
```

---

## 核心库集成配置

### ⚡ Boost 库集成

#### CMake 查找和配置
```cmake
# cmake/FindBoost.cmake
# Boost 库查找和配置

# 设置 Boost 查找策略
set(Boost_USE_STATIC_LIBS ON)
set(Boost_USE_MULTITHREADED ON)
set(Boost_USE_STATIC_RUNTIME OFF)

# 查找所需组件
find_package(Boost 1.75.0 REQUIRED COMPONENTS
    system
    filesystem
    thread
    program_options
    asio
)

if(NOT Boost_FOUND)
    message(FATAL_ERROR "Boost not found. Please install Boost 1.75.0 or later.")
endif()

# 创建导入目标
if(NOT TARGET Boost::boost)
    add_library(Boost::boost INTERFACE IMPORTED)
    target_include_directories(Boost::boost INTERFACE ${Boost_INCLUDE_DIRS})
    target_link_libraries(Boost::boost INTERFACE ${Boost_LIBRARIES})

    # 线程支持
    if(Boost_thread_FOUND)
        find_package(Threads REQUIRED)
        target_link_libraries(Boost::boost INTERFACE Threads::Threads)
    endif()

    # Windows 特定链接库
    if(WIN32)
        target_link_libraries(Boost::boost INTERFACE ws2_32 wsock32)
    endif()
endif()

# 配置编译定义
target_compile_definitions(Boost::boost INTERFACE
    BOOST_ALL_NO_LIB              # 禁用自动链接
    BOOST_SYSTEM_NO_DEPRECATED    # 禁用过时API
    BOOST_FILESYSTEM_NO_DEPRECATED
    BOOST_ASIO_NO_DEPRECATED
)

# 性能优化
if(CMAKE_BUILD_TYPE STREQUAL "Release")
    target_compile_definitions(Boost::boost INTERFACE
        BOOST_DISABLE_ASSERTS
    )
endif()

message(STATUS "Found Boost: ${Boost_VERSION}")
message(STATUS "Boost libraries: ${Boost_LIBRARIES}")
```

#### Boost 使用示例
```cpp
// src/common/boost_config.h
#pragma once

// Boost 版本检查
#include <boost/version.hpp>
#if BOOST_VERSION < 107500
#error "Boost 1.75.0 or later required"
#endif

// 常用头文件包含
#include <boost/system/error_code.hpp>
#include <boost/filesystem.hpp>
#include <boost/thread.hpp>
#include <boost/asio.hpp>
#include <boost/program_options.hpp>

// 命名空间别名
namespace fs = boost::filesystem;
namespace asio = boost::asio;
namespace po = boost::program_options;

// 类型别名
using error_code = boost::system::error_code;
using thread_group = boost::thread_group;

// 实用函数
inline std::string get_boost_version() {
    return BOOST_LIB_VERSION;
}

// 配置检查
static_assert(BOOST_VERSION >= 107500, "Boost version too old");
```

### 🎮 CUDA 工具包集成

#### CUDA CMake 配置
```cmake
# cmake/FindCUDA.cmake
# CUDA 工具包查找和配置

# 检查 CUDA 支持
include(CheckLanguage)
check_language(CUDA)

if(CMAKE_CUDA_COMPILER)
    enable_language(CUDA)

    # 查找 CUDA 工具包
    find_package(CUDAToolkit 12.0 REQUIRED)

    if(NOT CUDAToolkit_FOUND)
        message(FATAL_ERROR "CUDA Toolkit 12.0 or later required")
    endif()

    # CUDA 架构配置
    if(NOT CMAKE_CUDA_ARCHITECTURES)
        # 自动检测 GPU 架构
        include(FindCUDAArchitectures)
        find_cuda_architectures()
        if(CUDA_ARCHITECTURES)
            set(CMAKE_CUDA_ARCHITECTURES ${CUDA_ARCHITECTURES})
        else()
            # 默认架构
            set(CMAKE_CUDA_ARCHITECTURES "60;61;70;75;80;86;89")
        endif()
    endif()

    # CUDA 编译选项
    set(CMAKE_CUDA_STANDARD 17)
    set(CMAKE_CUDA_STANDARD_REQUIRED ON)
    set(CMAKE_CUDA_EXTENSIONS OFF)

    # 全局 CUDA 编译选项
    add_compile_options(
        $<$<COMPILE_LANGUAGE:CUDA>:
            --extended-lambda
            --expt-relaxed-constexpr
            --expt-extended-lambda
        >
    )

    # Release 优化
    if(CMAKE_BUILD_TYPE STREQUAL "Release")
        add_compile_options(
            $<$<COMPILE_LANGUAGE:CUDA>:
                --use_fast_math
                -O3
            >
        )
    endif()

    # Debug 选项
    if(CMAKE_BUILD_TYPE STREQUAL "Debug")
        add_compile_options(
            $<$<COMPILE_LANGUAGE:CUDA>:
                -G
                -g
            >
        )
    endif()

    # 创建 CUDA 目标辅助函数
    function(add_cuda_library target_name)
        add_library(${target_name} ${ARGN})

        set_target_properties(${target_name} PROPERTIES
            CUDA_STANDARD 17
            CUDA_STANDARD_REQUIRED ON
            CUDA_EXTENSIONS OFF
            CUDA_SEPARABLE_COMPILATION ON
            POSITION_INDEPENDENT_CODE ON
        )

        # 链接 CUDA 运行时
        target_link_libraries(${target_name}
            PUBLIC
                CUDA::cudart
                CUDA::cuda_driver
        )
    endfunction()

    message(STATUS "Found CUDA: ${CUDAToolkit_VERSION}")
    message(STATUS "CUDA Architectures: ${CMAKE_CUDA_ARCHITECTURES}")

else()
    message(WARNING "CUDA compiler not found. GPU acceleration disabled.")
    set(ENABLE_CUDA OFF)
endif()
```

#### CUDA 架构自动检测
```cmake
# cmake/FindCUDAArchitectures.cmake
# 自动检测可用的 GPU 架构

function(find_cuda_architectures)
    set(CUDA_DETECT_SCRIPT "${CMAKE_CURRENT_LIST_DIR}/detect_cuda_architectures.cu")

    # 检测脚本
    file(WRITE ${CUDA_DETECT_SCRIPT}
"#include <cuda_runtime.h>
#include <iostream>

int main() {
    int deviceCount = 0;
    cudaError_t error = cudaGetDeviceCount(&deviceCount);

    if (error != cudaSuccess || deviceCount == 0) {
        return 1;
    }

    for (int device = 0; device < deviceCount; ++device) {
        cudaDeviceProp deviceProp;
        cudaGetDeviceProperties(&deviceProp, device);

        int major = deviceProp.major;
        int minor = deviceProp.minor;

        std::cout << major << minor;
        if (device < deviceCount - 1) {
            std::cout << \";\";
        }
    }

    return 0;
}
")

    # 编译和运行检测程序
    try_run(CUDA_DETECT_RUN_RESULT CUDA_DETECT_COMPILE_RESULT
        ${CMAKE_BINARY_DIR}/CMakeFiles
        ${CUDA_DETECT_SCRIPT}
        LINK_LIBRARIES CUDA::cudart
        RUN_OUTPUT_VARIABLE CUDA_ARCHITECTURES_OUTPUT
    )

    if(CUDA_DETECT_COMPILE_RESULT AND CUDA_DETECT_RUN_RESULT EQUAL 0)
        set(CUDA_ARCHITECTURES ${CUDA_ARCHITECTURES_OUTPUT} PARENT_SCOPE)
        message(STATUS "Detected CUDA architectures: ${CUDA_ARCHITECTURES_OUTPUT}")
    else()
        message(STATUS "Could not detect CUDA architectures, using defaults")
    endif()

    # 清理临时文件
    file(REMOVE ${CUDA_DETECT_SCRIPT})
endfunction()
```

### 🔧 配置管理库集成

#### yaml-cpp 集成
```cmake
# cmake/FindYamlCpp.cmake
find_package(yaml-cpp 0.7.0 REQUIRED)

if(NOT yaml-cpp_FOUND)
    message(FATAL_ERROR "yaml-cpp not found. Please install yaml-cpp 0.7.0 or later.")
endif()

# 创建配置包装类
configure_file(
    "${CMAKE_SOURCE_DIR}/src/common/config_wrapper.h.in"
    "${CMAKE_BINARY_DIR}/include/common/config_wrapper.h"
    @ONLY
)
```

#### 配置文件包装类
```cpp
// src/common/config_wrapper.h.in
#pragma once

#include <yaml-cpp/yaml.h>
#include <string>
#include <optional>
#include <stdexcept>

namespace radar::config {

class ConfigManager {
public:
    explicit ConfigManager(const std::string& config_file) {
        try {
            config_ = YAML::LoadFile(config_file);
        } catch (const YAML::Exception& e) {
            throw std::runtime_error("Failed to load config: " + std::string(e.what()));
        }
    }

    template<typename T>
    std::optional<T> get(const std::string& key) const {
        try {
            auto node = config_;

            // 支持嵌套键 "section.subsection.key"
            std::string::size_type pos = 0;
            std::string::size_type found = 0;
            while ((found = key.find('.', pos)) != std::string::npos) {
                node = node[key.substr(pos, found - pos)];
                if (!node) return std::nullopt;
                pos = found + 1;
            }

            node = node[key.substr(pos)];
            if (!node) return std::nullopt;

            return node.as<T>();
        } catch (const YAML::Exception&) {
            return std::nullopt;
        }
    }

    template<typename T>
    T get_or(const std::string& key, const T& default_value) const {
        auto value = get<T>(key);
        return value ? *value : default_value;
    }

    bool has_key(const std::string& key) const {
        return get<YAML::Node>(key).has_value();
    }

    void reload(const std::string& config_file) {
        config_ = YAML::LoadFile(config_file);
    }

private:
    YAML::Node config_;
};

// 全局配置实例
extern ConfigManager* g_config;

// 初始化函数
inline void initialize_config(const std::string& config_file) {
    g_config = new ConfigManager(config_file);
}

// 清理函数
inline void cleanup_config() {
    delete g_config;
    g_config = nullptr;
}

} // namespace radar::config
```

### 📝 日志库集成

#### spdlog 配置
```cmake
# cmake/FindSpdlog.cmake
find_package(spdlog 1.9.0 REQUIRED)

if(NOT spdlog_FOUND)
    message(FATAL_ERROR "spdlog not found. Please install spdlog 1.9.0 or later.")
endif()

# 生成日志配置
configure_file(
    "${CMAKE_SOURCE_DIR}/src/common/logging.h.in"
    "${CMAKE_BINARY_DIR}/include/common/logging.h"
    @ONLY
)
```

#### 日志系统包装
```cpp
// src/common/logging.h.in
#pragma once

#include <spdlog/spdlog.h>
#include <spdlog/sinks/stdout_color_sinks.h>
#include <spdlog/sinks/rotating_file_sink.h>
#include <spdlog/sinks/basic_file_sink.h>
#include <memory>
#include <string>

namespace radar::logging {

// 日志级别映射
enum class Level {
    Trace = SPDLOG_LEVEL_TRACE,
    Debug = SPDLOG_LEVEL_DEBUG,
    Info = SPDLOG_LEVEL_INFO,
    Warn = SPDLOG_LEVEL_WARN,
    Error = SPDLOG_LEVEL_ERROR,
    Critical = SPDLOG_LEVEL_CRITICAL,
    Off = SPDLOG_LEVEL_OFF
};

class Logger {
public:
    static void initialize(const std::string& log_file = "", Level level = Level::Info) {
        std::vector<spdlog::sink_ptr> sinks;

        // 控制台输出
        auto console_sink = std::make_shared<spdlog::sinks::stdout_color_sink_mt>();
        console_sink->set_level(static_cast<spdlog::level::level_enum>(level));
        console_sink->set_pattern("[%H:%M:%S.%f] [%^%l%$] [%t] %v");
        sinks.push_back(console_sink);

        // 文件输出
        if (!log_file.empty()) {
            auto file_sink = std::make_shared<spdlog::sinks::rotating_file_sink_mt>(
                log_file, 1024 * 1024 * 10, 5); // 10MB, 5 files
            file_sink->set_level(static_cast<spdlog::level::level_enum>(level));
            file_sink->set_pattern("[%Y-%m-%d %H:%M:%S.%f] [%l] [%t] [%s:%#] %v");
            sinks.push_back(file_sink);
        }

        // 创建日志器
        auto logger = std::make_shared<spdlog::logger>("radar", sinks.begin(), sinks.end());
        logger->set_level(static_cast<spdlog::level::level_enum>(level));
        logger->flush_on(spdlog::level::warn);

        spdlog::set_default_logger(logger);
        spdlog::set_automatic_registration(true);
    }

    static void shutdown() {
        spdlog::shutdown();
    }
};

} // namespace radar::logging

// 便利宏
#define RADAR_TRACE(...)    SPDLOG_TRACE(__VA_ARGS__)
#define RADAR_DEBUG(...)    SPDLOG_DEBUG(__VA_ARGS__)
#define RADAR_INFO(...)     SPDLOG_INFO(__VA_ARGS__)
#define RADAR_WARN(...)     SPDLOG_WARN(__VA_ARGS__)
#define RADAR_ERROR(...)    SPDLOG_ERROR(__VA_ARGS__)
#define RADAR_CRITICAL(...) SPDLOG_CRITICAL(__VA_ARGS__)

// 性能测量宏
#define RADAR_TIMER(name) \
    auto timer_start_##name = std::chrono::high_resolution_clock::now(); \
    auto timer_guard_##name = [&]() { \
        auto end = std::chrono::high_resolution_clock::now(); \
        auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - timer_start_##name); \
        RADAR_DEBUG("Timer [{}]: {} μs", #name, duration.count()); \
    }; \
    (void)timer_guard_##name;
```

---

## 图形和数学库集成

### 🎨 OpenGL 生态集成

#### OpenGL 核心配置
```cmake
# cmake/FindOpenGL.cmake
# OpenGL 相关库查找和配置

# OpenGL 核心
find_package(OpenGL REQUIRED)
if(NOT OPENGL_FOUND)
    message(FATAL_ERROR "OpenGL not found")
endif()

# GLFW (窗口管理)
find_package(glfw3 3.3 REQUIRED)
if(NOT glfw3_FOUND)
    message(FATAL_ERROR "GLFW3 not found")
endif()

# GLEW (扩展加载)
find_package(GLEW 2.2.0 REQUIRED)
if(NOT GLEW_FOUND)
    message(FATAL_ERROR "GLEW not found")
endif()

# 创建 OpenGL 目标
add_library(radar_opengl INTERFACE)

target_link_libraries(radar_opengl INTERFACE
    OpenGL::GL
    glfw
    GLEW::GLEW
)

# OpenGL 版本检查
target_compile_definitions(radar_opengl INTERFACE
    GL_VERSION_REQUIRED_MAJOR=4
    GL_VERSION_REQUIRED_MINOR=5
)

# 平台特定配置
if(WIN32)
    target_link_libraries(radar_opengl INTERFACE opengl32)
elseif(APPLE)
    find_library(COCOA_LIBRARY Cocoa REQUIRED)
    find_library(IOKIT_LIBRARY IOKit REQUIRED)
    find_library(COREVIDEO_LIBRARY CoreVideo REQUIRED)
    target_link_libraries(radar_opengl INTERFACE
        ${COCOA_LIBRARY}
        ${IOKIT_LIBRARY}
        ${COREVIDEO_LIBRARY}
    )
elseif(UNIX)
    find_package(X11 REQUIRED)
    target_link_libraries(radar_opengl INTERFACE
        ${X11_LIBRARIES}
        ${CMAKE_DL_LIBS}
    )
endif()

message(STATUS "OpenGL integration configured")
```

#### OpenGL 包装类
```cpp
// include/graphics/opengl_context.h
#pragma once

#include <GL/glew.h>
#include <GLFW/glfw3.h>
#include <memory>
#include <string>
#include <functional>

namespace radar::graphics {

class OpenGLContext {
public:
    struct Config {
        int width = 1280;
        int height = 720;
        std::string title = "Radar Display";
        bool fullscreen = false;
        bool vsync = true;
        int samples = 4; // MSAA
        int gl_major = 4;
        int gl_minor = 5;
    };

    explicit OpenGLContext(const Config& config = {});
    ~OpenGLContext();

    // 禁用拷贝
    OpenGLContext(const OpenGLContext&) = delete;
    OpenGLContext& operator=(const OpenGLContext&) = delete;

    // 移动构造
    OpenGLContext(OpenGLContext&& other) noexcept;
    OpenGLContext& operator=(OpenGLContext&& other) noexcept;

    bool should_close() const;
    void swap_buffers();
    void poll_events();

    void set_resize_callback(std::function<void(int, int)> callback);
    void set_key_callback(std::function<void(int, int, int, int)> callback);

    GLFWwindow* get_window() const { return window_; }

private:
    GLFWwindow* window_ = nullptr;
    Config config_;

    static void glfw_error_callback(int error, const char* description);
    static void framebuffer_size_callback(GLFWwindow* window, int width, int height);
    static void key_callback(GLFWwindow* window, int key, int scancode, int action, int mods);

    std::function<void(int, int)> resize_callback_;
    std::function<void(int, int, int, int)> key_callback_;
};

// OpenGL 错误检查
void check_gl_error(const std::string& operation);

#ifdef DEBUG
#define GL_CHECK(call) do { call; check_gl_error(#call); } while(0)
#else
#define GL_CHECK(call) call
#endif

} // namespace radar::graphics
```

### 🧮 数学库集成

#### Eigen3 集成配置
```cmake
# cmake/FindEigen.cmake
find_package(Eigen3 3.4.0 QUIET)

if(Eigen3_FOUND)
    # 创建数学库目标
    add_library(radar_math INTERFACE)

    target_link_libraries(radar_math INTERFACE
        Eigen3::Eigen
    )

    # Eigen 编译优化
    target_compile_definitions(radar_math INTERFACE
        EIGEN_NO_DEBUG                    # Release优化
        EIGEN_DONT_PARALLELIZE           # 禁用内置并行化
        EIGEN_USE_THREADS                # 使用外部线程
        EIGEN_FAST_MATH                  # 快速数学
    )

    # SIMD 优化
    if(CMAKE_CXX_COMPILER_ID STREQUAL "GNU" OR CMAKE_CXX_COMPILER_ID STREQUAL "Clang")
        target_compile_options(radar_math INTERFACE
            -march=native
            -mtune=native
        )
    elseif(CMAKE_CXX_COMPILER_ID STREQUAL "MSVC")
        target_compile_options(radar_math INTERFACE
            /arch:AVX2
        )
    endif()

    set(HAVE_EIGEN3 TRUE)
    message(STATUS "Found Eigen3: ${Eigen3_VERSION}")

else()
    # 创建空的数学库目标
    add_library(radar_math INTERFACE)
    set(HAVE_EIGEN3 FALSE)
    message(STATUS "Eigen3 not found - using standard library implementations")
endif()
```

#### Intel MKL 可选集成
```cmake
# cmake/FindMKL.cmake
# Intel MKL 数学库集成

find_package(MKL QUIET)

if(MKL_FOUND)
    # MKL 配置
    add_library(radar_math_mkl INTERFACE)

    target_link_libraries(radar_math_mkl INTERFACE
        MKL::MKL
    )

    # MKL 编译定义
    target_compile_definitions(radar_math_mkl INTERFACE
        EIGEN_USE_MKL_ALL           # Eigen 使用 MKL
        MKL_DIRECT_CALL_SEQ         # 顺序调用优化
        MKL_DIRECT_CALL             # 直接调用优化
    )

    # 线程配置
    if(CMAKE_BUILD_TYPE STREQUAL "Release")
        target_compile_definitions(radar_math_mkl INTERFACE
            MKL_THREADING_INTEL     # Intel 线程库
        )
    endif()

    # 将 MKL 添加到数学库
    if(TARGET radar_math)
        target_link_libraries(radar_math INTERFACE radar_math_mkl)
    endif()

    set(HAVE_MKL TRUE)
    message(STATUS "Found Intel MKL: ${MKL_VERSION}")

else()
    set(HAVE_MKL FALSE)
    message(STATUS "Intel MKL not found")
endif()
```

#### 数学工具包装
```cpp
// include/math/math_utils.h
#pragma once

#include "common/config.h"

#ifdef HAVE_EIGEN3
#include <Eigen/Dense>
#include <Eigen/Sparse>
#include <Eigen/FFT>
#endif

#ifdef HAVE_MKL
#include <mkl.h>
#include <mkl_dfti.h>
#endif

#include <complex>
#include <vector>
#include <array>

namespace radar::math {

// 类型定义
using Real = float;
using Complex = std::complex<Real>;

#ifdef HAVE_EIGEN3
using Vector3r = Eigen::Vector3f;
using Matrix3r = Eigen::Matrix3f;
using MatrixXr = Eigen::MatrixXf;
using VectorXr = Eigen::VectorXf;
using VectorXc = Eigen::VectorXcf;
#else
// 简单替代实现
struct Vector3r {
    Real x, y, z;
    Vector3r(Real x = 0, Real y = 0, Real z = 0) : x(x), y(y), z(z) {}
};
#endif

// FFT 实现选择
class FFTProcessor {
public:
    FFTProcessor(size_t size);
    ~FFTProcessor();

    void forward(const std::vector<Complex>& input, std::vector<Complex>& output);
    void inverse(const std::vector<Complex>& input, std::vector<Complex>& output);

private:
    size_t size_;

#ifdef HAVE_MKL
    DFTI_DESCRIPTOR_HANDLE mkl_handle_;
#elif defined(HAVE_EIGEN3)
    Eigen::FFT<Real> eigen_fft_;
#else
    // 简单的 DFT 实现
    void dft(const std::vector<Complex>& input, std::vector<Complex>& output, bool inverse);
#endif
};

// 线性代数工具
namespace linalg {

template<typename T>
std::vector<T> matrix_vector_multiply(const std::vector<std::vector<T>>& matrix,
                                     const std::vector<T>& vector);

template<typename T>
T dot_product(const std::vector<T>& a, const std::vector<T>& b);

template<typename T>
std::vector<T> cross_product(const std::vector<T>& a, const std::vector<T>& b);

} // namespace linalg

// 信号处理工具
namespace signal {

std::vector<Real> gaussian_window(size_t size, Real sigma);
std::vector<Real> hamming_window(size_t size);
std::vector<Real> blackman_window(size_t size);

template<typename T>
std::vector<T> convolution(const std::vector<T>& signal, const std::vector<T>& kernel);

} // namespace signal

} // namespace radar::math
```

---

## 测试框架集成

### 🧪 Google Test 配置

#### Google Test CMake 集成
```cmake
# cmake/FindGoogleTest.cmake
include(FetchContent)

option(BUILD_TESTS "Build tests" ON)
if(NOT BUILD_TESTS)
    return()
endif()

# 查找已安装的 Google Test
find_package(GTest 1.12.0 QUIET)

if(NOT GTest_FOUND)
    message(STATUS "Google Test not found, downloading...")

    # 下载和构建 Google Test
    FetchContent_Declare(
        googletest
        URL https://github.com/google/googletest/archive/v1.13.0.zip
        URL_HASH SHA256=ad7fdba11ea011c1d925b3289cf4af2c66a352e18d4c7264392fead75e919363
    )

    # 配置选项
    set(gtest_force_shared_crt ON CACHE BOOL "" FORCE)
    set(BUILD_GMOCK ON CACHE BOOL "" FORCE)
    set(INSTALL_GTEST OFF CACHE BOOL "" FORCE)

    FetchContent_MakeAvailable(googletest)

    # 创建别名目标
    add_library(GTest::gtest ALIAS gtest)
    add_library(GTest::gtest_main ALIAS gtest_main)
    add_library(GTest::gmock ALIAS gmock)
    add_library(GTest::gmock_main ALIAS gmock_main)
endif()

# 测试辅助函数
function(add_radar_test test_name)
    set(options CUDA)
    set(oneValueArgs TIMEOUT)
    set(multiValueArgs SOURCES LIBRARIES LABELS)
    cmake_parse_arguments(TEST "${options}" "${oneValueArgs}" "${multiValueArgs}" ${ARGN})

    # 设置默认值
    if(NOT TEST_TIMEOUT)
        set(TEST_TIMEOUT 30)
    endif()

    if(NOT TEST_LABELS)
        set(TEST_LABELS "unit")
    endif()

    # 创建测试可执行文件
    add_executable(${test_name} ${TEST_SOURCES})

    # 链接库
    target_link_libraries(${test_name}
        PRIVATE
            GTest::gtest
            GTest::gtest_main
            GTest::gmock
            ${TEST_LIBRARIES}
    )

    # 包含目录
    target_include_directories(${test_name}
        PRIVATE
            ${CMAKE_SOURCE_DIR}/include
            ${CMAKE_SOURCE_DIR}/tests/mock
    )

    # CUDA 支持
    if(TEST_CUDA AND ENABLE_CUDA)
        set_target_properties(${test_name} PROPERTIES
            CUDA_STANDARD 17
            CUDA_STANDARD_REQUIRED ON
        )
        target_link_libraries(${test_name} PRIVATE CUDA::cudart)
        list(APPEND TEST_LABELS "gpu")
    endif()

    # 添加测试
    add_test(NAME ${test_name} COMMAND ${test_name})

    # 测试属性
    set_tests_properties(${test_name} PROPERTIES
        TIMEOUT ${TEST_TIMEOUT}
        LABELS "${TEST_LABELS}"
    )

    # GPU 测试资源限制
    if("gpu" IN_LIST TEST_LABELS)
        set_tests_properties(${test_name} PROPERTIES
            RESOURCE_GROUPS "gpu:1"
        )
    endif()
endfunction()

message(STATUS "Google Test integration configured")
```

#### 测试基础设施
```cpp
// tests/common/test_base.h
#pragma once

#include <gtest/gtest.h>
#include <gmock/gmock.h>
#include "common/logging.h"
#include "common/config_wrapper.h"

namespace radar::test {

// 测试基类
class RadarTestBase : public ::testing::Test {
protected:
    void SetUp() override {
        // 设置测试日志
        radar::logging::Logger::initialize("", radar::logging::Level::Debug);

        // 加载测试配置
        test_config_ = std::make_unique<radar::config::ConfigManager>("test_config.yaml");
    }

    void TearDown() override {
        test_config_.reset();
        radar::logging::Logger::shutdown();
    }

    radar::config::ConfigManager& config() { return *test_config_; }

private:
    std::unique_ptr<radar::config::ConfigManager> test_config_;
};

// GPU 测试基类
class RadarGpuTestBase : public RadarTestBase {
protected:
    void SetUp() override {
        RadarTestBase::SetUp();

        // 检查 GPU 可用性
        int device_count = 0;
        cudaError_t error = cudaGetDeviceCount(&device_count);

        if (error != cudaSuccess || device_count == 0) {
            GTEST_SKIP() << "No CUDA-capable GPU found";
        }

        // 设置 GPU 设备
        cudaSetDevice(0);
    }

    void TearDown() override {
        cudaDeviceSynchronize();
        cudaDeviceReset();
        RadarTestBase::TearDown();
    }
};

// 性能测试基类
class RadarBenchmarkBase : public RadarTestBase {
protected:
    void SetUp() override {
        RadarTestBase::SetUp();
        start_time_ = std::chrono::high_resolution_clock::now();
    }

    void TearDown() override {
        auto end_time = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(
            end_time - start_time_);

        RADAR_INFO("Test duration: {} ms", duration.count());
        RadarTestBase::TearDown();
    }

private:
    std::chrono::high_resolution_clock::time_point start_time_;
};

// 测试工具函数
template<typename T>
void expect_near_vector(const std::vector<T>& actual,
                       const std::vector<T>& expected,
                       T tolerance) {
    ASSERT_EQ(actual.size(), expected.size());
    for (size_t i = 0; i < actual.size(); ++i) {
        EXPECT_NEAR(actual[i], expected[i], tolerance)
            << "Vectors differ at index " << i;
    }
}

// 随机数据生成器
template<typename T>
std::vector<T> generate_random_data(size_t size, T min_val = T(0), T max_val = T(1)) {
    std::vector<T> data(size);
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_real_distribution<T> dis(min_val, max_val);

    for (auto& val : data) {
        val = dis(gen);
    }

    return data;
}

} // namespace radar::test

// 测试辅助宏
#define RADAR_TEST(test_case, test_name) \
    class test_case##_##test_name##_Test : public radar::test::RadarTestBase {}; \
    TEST_F(test_case##_##test_name##_Test, test_name)

#define RADAR_GPU_TEST(test_case, test_name) \
    class test_case##_##test_name##_GpuTest : public radar::test::RadarGpuTestBase {}; \
    TEST_F(test_case##_##test_name##_GpuTest, test_name)

#define RADAR_BENCHMARK_TEST(test_case, test_name) \
    class test_case##_##test_name##_BenchmarkTest : public radar::test::RadarBenchmarkBase {}; \
    TEST_F(test_case##_##test_name##_BenchmarkTest, test_name)
```

### 📊 Google Benchmark 集成

#### Benchmark CMake 配置
```cmake
# cmake/FindGoogleBenchmark.cmake
option(BUILD_BENCHMARKS "Build benchmarks" OFF)
if(NOT BUILD_BENCHMARKS)
    return()
endif()

# 查找已安装的 Google Benchmark
find_package(benchmark 1.7.0 QUIET)

if(NOT benchmark_FOUND)
    message(STATUS "Google Benchmark not found, downloading...")

    FetchContent_Declare(
        googlebenchmark
        URL https://github.com/google/benchmark/archive/v1.8.0.zip
        URL_HASH SHA256=ea2e94c24ddf6594d15c711c06ccd4486434d9cf3eca954e2af8a20c88f9f172
    )

    # 配置选项
    set(BENCHMARK_ENABLE_TESTING OFF CACHE BOOL "" FORCE)
    set(BENCHMARK_ENABLE_INSTALL OFF CACHE BOOL "" FORCE)
    set(BENCHMARK_ENABLE_DOXYGEN OFF CACHE BOOL "" FORCE)
    set(BENCHMARK_INSTALL_DOCS OFF CACHE BOOL "" FORCE)
    set(BENCHMARK_DOWNLOAD_DEPENDENCIES ON CACHE BOOL "" FORCE)

    FetchContent_MakeAvailable(googlebenchmark)
endif()

# 基准测试辅助函数
function(add_radar_benchmark benchmark_name)
    set(options CUDA)
    set(oneValueArgs)
    set(multiValueArgs SOURCES LIBRARIES)
    cmake_parse_arguments(BENCH "${options}" "${oneValueArgs}" "${multiValueArgs}" ${ARGN})

    # 创建基准测试可执行文件
    add_executable(${benchmark_name} ${BENCH_SOURCES})

    # 链接库
    target_link_libraries(${benchmark_name}
        PRIVATE
            benchmark::benchmark
            benchmark::benchmark_main
            ${BENCH_LIBRARIES}
    )

    # 包含目录
    target_include_directories(${benchmark_name}
        PRIVATE
            ${CMAKE_SOURCE_DIR}/include
    )

    # CUDA 支持
    if(BENCH_CUDA AND ENABLE_CUDA)
        set_target_properties(${benchmark_name} PROPERTIES
            CUDA_STANDARD 17
            CUDA_STANDARD_REQUIRED ON
        )
        target_link_libraries(${benchmark_name} PRIVATE CUDA::cudart)
    endif()

    # 优化设置
    target_compile_options(${benchmark_name} PRIVATE
        $<$<CONFIG:Release>:-O3 -DNDEBUG>
    )
endfunction()

message(STATUS "Google Benchmark integration configured")
```

---

## 依赖版本锁定

### 🔒 版本锁定文件

#### 精确版本控制
```yaml
# dependency_versions.lock
# 依赖版本锁定文件 - 确保构建一致性
lockfile_version: "1.0"
generated_at: "2025-09-10T10:00:00Z"
generated_by: "radar-mvp-build-system"

core_dependencies:
  boost:
    version: "1.82.0"
    hash: "sha256:a6e1ab9b0860e6a2881dd7b21fe9f737a095e5f33a3a874afc6a345228597ee6"
    source: "vcpkg"
    features: ["system", "filesystem", "thread", "program-options", "asio"]

  cuda_toolkit:
    version: "12.2.0"
    hash: "sha256:4a23e8c1ab4d3e25c5a7d8e6d9bfb3a8c9fde1234567890abcdef1234567890a"
    source: "nvidia"
    compute_capabilities: ["6.0", "6.1", "7.0", "7.5", "8.0", "8.6", "8.9"]

  yaml_cpp:
    version: "0.7.0"
    hash: "sha256:43e6a9fcb146ad871515f0d0873947e5d497a1c9c60c58cb102a97b47208b7c3"
    source: "vcpkg"

  spdlog:
    version: "1.12.0"
    hash: "sha256:4dccf2d10f410c1e2feaff89966bfc49a1abb29ef6dc7631a1b670c96a1c571a"
    source: "vcpkg"
    features: ["std_format"]

graphics_dependencies:
  opengl:
    version: "system"
    minimum_version: "4.5"

  glfw:
    version: "3.3.8"
    hash: "sha256:f30f42e05f11e5fc62483e513b0488d5bceeab7d9319c5b0c3e56a6dd9ad7b63"
    source: "vcpkg"

  glew:
    version: "2.2.0"
    hash: "sha256:d4fc82893cfb00109578d0a1a2b0c8153e4380b42e6e2c9c6b100f9fd4b51b78"
    source: "vcpkg"

  eigen3:
    version: "3.4.0"
    hash: "sha256:b4c198460eba6f28d34894e3a5710998818515104d6e74e5cc331ce31e46e626"
    source: "vcpkg"

optional_dependencies:
  intel_mkl:
    version: "2023.1.0"
    hash: "sha256:e8b2e5b9a7e4a5b8c7d5e3f2a1e4d3c5b8a7e4d3c5b8a7e4d3c5b8a7e4d3c5b8"
    source: "intel"
    enabled: false

  imgui:
    version: "1.89.9"
    hash: "sha256:1acc27a778b71d859878121a3f7b287cd81c29d720893d2b4c62b123d0b7c6d8"
    source: "vcpkg"
    features: ["opengl3-binding", "glfw-binding"]
    enabled: true

test_dependencies:
  googletest:
    version: "1.13.0"
    hash: "sha256:ad7fdba11ea011c1d925b3289cf4af2c66a352e18d4c7264392fead75e919363"
    source: "fetchcontent"

  google_benchmark:
    version: "1.8.0"
    hash: "sha256:ea2e94c24ddf6594d15c711c06ccd4486434d9cf3eca954e2af8a20c88f9f172"
    source: "fetchcontent"

build_tools:
  cmake:
    minimum_version: "3.20.0"
    recommended_version: "3.27.0"

  ninja:
    minimum_version: "1.10.0"
    recommended_version: "1.11.1"

  compiler_gcc:
    minimum_version: "9.0.0"
    recommended_version: "11.3.0"

  compiler_clang:
    minimum_version: "12.0.0"
    recommended_version: "14.0.0"

  compiler_msvc:
    minimum_version: "19.28.0"
    recommended_version: "19.30.0"
```

#### 版本验证脚本
```python
#!/usr/bin/env python3
# scripts/verify_dependencies.py
# 依赖版本验证脚本

import yaml
import subprocess
import sys
import hashlib
import os
from pathlib import Path
from typing import Dict, Any, List, Optional


class DependencyVerifier:
    def __init__(self, lockfile_path: str):
        self.lockfile_path = Path(lockfile_path)
        self.lockfile_data = self._load_lockfile()
        self.errors: List[str] = []
        self.warnings: List[str] = []

    def _load_lockfile(self) -> Dict[str, Any]:
        """加载版本锁定文件"""
        try:
            with open(self.lockfile_path, 'r') as f:
                return yaml.safe_load(f)
        except Exception as e:
            raise RuntimeError(f"Failed to load lockfile: {e}")

    def _run_command(self, cmd: List[str]) -> Optional[str]:
        """执行命令并返回输出"""
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            return result.stdout.strip() if result.returncode == 0 else None
        except Exception:
            return None

    def _check_cmake_version(self) -> bool:
        """检查 CMake 版本"""
        output = self._run_command(['cmake', '--version'])
        if not output:
            self.errors.append("CMake not found")
            return False

        version_line = output.split('\n')[0]
        version = version_line.split()[2]

        min_version = self.lockfile_data['build_tools']['cmake']['minimum_version']
        if self._compare_versions(version, min_version) < 0:
            self.errors.append(f"CMake version {version} < required {min_version}")
            return False

        print(f"✓ CMake version: {version}")
        return True

    def _check_compiler_versions(self) -> bool:
        """检查编译器版本"""
        success = True

        # GCC
        gcc_output = self._run_command(['gcc', '--version'])
        if gcc_output:
            gcc_version = gcc_output.split('\n')[0].split()[-1]
            min_gcc = self.lockfile_data['build_tools']['compiler_gcc']['minimum_version']
            if self._compare_versions(gcc_version, min_gcc) < 0:
                self.warnings.append(f"GCC version {gcc_version} < recommended {min_gcc}")
            else:
                print(f"✓ GCC version: {gcc_version}")

        # Clang
        clang_output = self._run_command(['clang', '--version'])
        if clang_output:
            clang_version = clang_output.split('\n')[0].split()[2]
            min_clang = self.lockfile_data['build_tools']['compiler_clang']['minimum_version']
            if self._compare_versions(clang_version, min_clang) < 0:
                self.warnings.append(f"Clang version {clang_version} < recommended {min_clang}")
            else:
                print(f"✓ Clang version: {clang_version}")

        # CUDA
        nvcc_output = self._run_command(['nvcc', '--version'])
        if nvcc_output:
            cuda_version = None
            for line in nvcc_output.split('\n'):
                if 'release' in line:
                    cuda_version = line.split('release')[1].split(',')[0].strip()
                    break

            if cuda_version:
                expected_cuda = self.lockfile_data['core_dependencies']['cuda_toolkit']['version']
                if not cuda_version.startswith(expected_cuda.split('.')[0]):
                    self.warnings.append(f"CUDA version {cuda_version} != expected {expected_cuda}")
                else:
                    print(f"✓ CUDA version: {cuda_version}")
        else:
            self.warnings.append("CUDA toolkit not found")

        return success

    def _check_vcpkg_packages(self) -> bool:
        """检查 vcpkg 包"""
        vcpkg_root = os.environ.get('VCPKG_ROOT')
        if not vcpkg_root:
            self.warnings.append("VCPKG_ROOT not set")
            return True

        vcpkg_exe = Path(vcpkg_root) / ('vcpkg.exe' if os.name == 'nt' else 'vcpkg')
        if not vcpkg_exe.exists():
            self.warnings.append("vcpkg executable not found")
            return True

        # 检查已安装包
        output = self._run_command([str(vcpkg_exe), 'list'])
        if not output:
            self.warnings.append("Failed to query vcpkg packages")
            return True

        installed_packages = {}
        for line in output.split('\n'):
            if ':' in line:
                parts = line.split()
                if len(parts) >= 2:
                    package_name = parts[0].split(':')[0]
                    package_version = parts[1]
                    installed_packages[package_name] = package_version

        # 验证核心依赖
        for dep_name, dep_info in self.lockfile_data['core_dependencies'].items():
            if dep_info.get('source') == 'vcpkg':
                if dep_name.replace('_', '-') in installed_packages:
                    installed_version = installed_packages[dep_name.replace('_', '-')]
                    expected_version = dep_info['version']
                    if not installed_version.startswith(expected_version.split('.')[0]):
                        self.warnings.append(
                            f"Package {dep_name}: installed {installed_version} != expected {expected_version}"
                        )
                    else:
                        print(f"✓ {dep_name}: {installed_version}")
                else:
                    self.errors.append(f"Required package {dep_name} not installed")

        return len(self.errors) == 0

    def _compare_versions(self, version1: str, version2: str) -> int:
        """比较版本号"""
        def normalize(v):
            return [int(x) for x in v.replace('-', '.').split('.') if x.isdigit()]

        v1_parts = normalize(version1)
        v2_parts = normalize(version2)

        # 补齐到相同长度
        max_len = max(len(v1_parts), len(v2_parts))
        v1_parts.extend([0] * (max_len - len(v1_parts)))
        v2_parts.extend([0] * (max_len - len(v2_parts)))

        if v1_parts < v2_parts:
            return -1
        elif v1_parts > v2_parts:
            return 1
        else:
            return 0

    def verify_all(self) -> bool:
        """执行所有验证"""
        print("=== Dependency Verification ===")

        success = True
        success &= self._check_cmake_version()
        success &= self._check_compiler_versions()
        success &= self._check_vcpkg_packages()

        # 输出结果
        if self.warnings:
            print("\n⚠️ Warnings:")
            for warning in self.warnings:
                print(f"  - {warning}")

        if self.errors:
            print("\n❌ Errors:")
            for error in self.errors:
                print(f"  - {error}")
            success = False

        if success and not self.errors:
            print("\n✅ All dependencies verified successfully")

        return success


def main():
    script_dir = Path(__file__).parent
    lockfile_path = script_dir.parent / "dependency_versions.lock"

    if not lockfile_path.exists():
        print(f"❌ Lockfile not found: {lockfile_path}")
        return 1

    verifier = DependencyVerifier(str(lockfile_path))
    success = verifier.verify_all()

    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())
```

---

## 变更记录

| 版本 | 日期       | 修改人 | 变更摘要                             |
| :--- | :--------- | :----- | :----------------------------------- |
| v1.0 | 2025-09-10 | Kelin  | 创建第三方库集成管理指南和自动化验证 |
