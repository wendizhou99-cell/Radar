# 注释和文档规范

- **标题**: AI协作开发注释和文档编写标准
- **当前版本**: v1.0
- **最后更新**: 2025-09-10
- **负责人**: Kelin

---

## Doxygen注释标准

### 📝 文件头注释模板

#### 接口头文件注释
```cpp
/**
 * @file IDataProcessor.h
 * @brief 数据处理模块的统一接口定义
 *
 * 本文件定义了雷达数据处理系统中数据处理模块的抽象接口。
 * 所有具体的数据处理器（CPU处理器、GPU处理器等）都应继承此接口。
 *
 * @author Kelin
 * @version 1.0
 * @date 2025-09-10
 * @since 1.0
 *
 * @see DataProcessor
 * @see GPUProcessor
 * @see CPUProcessor
 */

#pragma once

#include "common/Types.h"
#include "common/ErrorCodes.h"
```

#### 实现文件注释
```cpp
/**
 * @file DataProcessor.cpp
 * @brief IDataProcessor 接口的具体实现
 *
 * 实现了基于 GPU 加速的雷达数据处理功能，包括：
 * - 脉冲压缩算法
 * - 多普勒处理算法
 * - 波束形成算法
 *
 * @author Kelin
 * @version 1.0
 * @date 2025-09-10
 *
 * @todo 优化内存分配策略
 * @todo 添加自适应参数调整功能
 */

#include "processor/DataProcessor.h"
```

### 🏗️ 类和结构体注释

#### 接口类注释
```cpp
/**
 * @brief 数据处理模块的抽象接口
 *
 * 该接口定义了雷达数据处理的标准操作，包括初始化、数据处理、
 * 状态查询等功能。实现类需要提供具体的处理算法。
 *
 * @details
 * 处理流程：
 * 1. 调用 initialize() 初始化处理器
 * 2. 循环调用 process() 处理数据
 * 3. 根据需要调用 getStatistics() 获取统计信息
 * 4. 调用 cleanup() 清理资源
 *
 * @note 该接口的实现必须是线程安全的
 * @warning 在调用 process() 前必须先调用 initialize()
 *
 * @since 1.0
 * @see DataProcessor
 * @see ProcessingConfig
 */
class IDataProcessor {
public:
    virtual ~IDataProcessor() = default;

    // 接口方法...
};
```

#### 数据结构注释
```cpp
/**
 * @brief 雷达原始数据包结构
 *
 * 包含从雷达前端接收到的原始I/Q数据以及相关的元信息。
 * 该结构体设计为内存对齐，以优化GPU处理性能。
 *
 * @details
 * 数据布局：
 * - timestamp: 数据采集时间戳（微秒精度）
 * - sequenceId: 数据包序列号（用于丢包检测）
 * - iData: I路（同相）采样数据
 * - qData: Q路（正交）采样数据
 * - metadata: 采集参数和状态信息
 *
 * @note I/Q数据长度必须相等
 * @warning 直接修改数据内容可能影响处理结果
 */
struct alignas(16) RawDataPacket {
    uint64_t timestamp;           ///< 数据采集时间戳（微秒）
    uint32_t sequenceId;          ///< 数据包序列号
    uint32_t reserved;            ///< 保留字段，用于对齐

    std::vector<float> iData;     ///< I路采样数据
    std::vector<float> qData;     ///< Q路采样数据

    AcquisitionMetadata metadata; ///< 采集元信息

    /**
     * @brief 检查数据包的有效性
     * @return 数据包是否有效
     * @retval true 数据包格式正确，可以处理
     * @retval false 数据包存在错误，需要丢弃
     */
    bool isValid() const;
};
```

### 🔧 方法注释规范

#### 完整方法注释模板
```cpp
/**
 * @brief 处理单个雷达数据包
 *
 * 对输入的原始雷达数据执行完整的信号处理流程，包括脉冲压缩、
 * 多普勒处理和波束形成等算法。
 *
 * @param[in] input 待处理的原始数据包
 *                  - 必须是有效的 RawDataPacket 结构
 *                  - I/Q数据长度必须相等且大于0
 * @param[out] output 处理结果的输出对象
 *                    - 函数成功时包含处理后的数据
 *                    - 函数失败时内容未定义
 * @param[in] options 可选的处理参数
 *                    - 默认值使用标准处理配置
 *                    - nullptr 表示使用默认配置
 *
 * @return 处理状态码
 * @retval SUCCESS 处理成功完成
 * @retval INVALID_INPUT 输入数据格式错误
 * @retval PROCESSING_ERROR 处理过程中发生错误
 * @retval OUT_OF_MEMORY 内存不足
 *
 * @pre initialize() 必须已成功调用
 * @pre input.isValid() 必须返回 true
 * @post 成功时 output 包含有效的处理结果
 *
 * @note 该方法是线程安全的，可以并发调用
 * @warning 大数据量处理可能耗时较长（>100ms）
 * @warning GPU 内存使用量可能达到数GB
 *
 * @exception std::bad_alloc 内存分配失败时抛出
 * @exception cuda_error CUDA 操作失败时抛出
 *
 * @see initialize()
 * @see ProcessingOptions
 * @see ProcessingResult
 *
 * @since 1.0
 * @deprecated 使用 processBatch() 获得更好的性能
 */
virtual ProcessingStatus process(
    const RawDataPacket& input,
    ProcessedData& output,
    const ProcessingOptions* options = nullptr
) = 0;
```

#### 简化方法注释
```cpp
/**
 * @brief 获取处理器的当前状态
 * @return 当前处理器状态
 * @note 该方法是线程安全的
 */
virtual ProcessorState getState() const = 0;

/**
 * @brief 检查处理器是否已初始化
 * @return true 如果已初始化，false 否则
 */
virtual bool isInitialized() const = 0;

/**
 * @brief 重置处理器到初始状态
 * @warning 调用此方法会丢失所有缓存的数据
 */
virtual void reset() = 0;
```

### 📊 参数和返回值注释

#### 参数方向标记
```cpp
/**
 * @brief 批量处理多个数据包
 *
 * @param[in] inputs 输入数据包数组
 * @param[out] outputs 输出结果数组，大小必须与 inputs 相同
 * @param[in,out] stats 统计信息对象，输入当前统计，输出更新后的统计
 * @param[in] count 数据包数量
 *
 * @return 成功处理的数据包数量
 */
size_t processBatch(
    const RawDataPacket inputs[],
    ProcessedData outputs[],
    ProcessingStats& stats,
    size_t count
);
```

#### 复杂返回值说明
```cpp
/**
 * @brief 异步启动数据处理任务
 *
 * @param input 输入数据包
 * @param callback 处理完成回调函数
 *
 * @return 异步任务的 future 对象
 * @retval valid_future 任务成功提交
 * @retval empty_future 任务提交失败
 *
 * @note 通过返回的 future 可以：
 *       - 检查任务是否完成：future.wait_for(0s)
 *       - 获取处理结果：future.get()
 *       - 取消未开始的任务：future.cancel()
 */
std::future<ProcessingResult> processAsync(
    const RawDataPacket& input,
    std::function<void(const ProcessingResult&)> callback
);
```

---

## 内联注释原则

### 💡 何时写注释

#### 必须写注释的情况
```cpp
class DataProcessor {
private:
    // GPU 内存管理
    float* d_inputBuffer_;    ///< 设备端输入数据缓冲区
    float* d_outputBuffer_;   ///< 设备端输出数据缓冲区
    size_t bufferSize_;       ///< 缓冲区大小（字节数）

    // 性能统计
    mutable std::mutex statsMutex_;  ///< 保护统计数据的互斥锁
    uint64_t totalProcessed_;        ///< 已处理的数据包总数
    double avgProcessingTime_;       ///< 平均处理时间（毫秒）

public:
    bool initialize(const Config& config) {
        // 检查 GPU 可用性
        int deviceCount;
        cudaGetDeviceCount(&deviceCount);
        if (deviceCount == 0) {
            LOG_ERROR("No CUDA capable devices found");
            return false;
        }

        // 分配 GPU 内存 - 预分配足够大的缓冲区以避免频繁分配
        size_t maxDataSize = config.maxPacketSize * config.maxBatchSize;
        if (cudaMalloc(&d_inputBuffer_, maxDataSize) != cudaSuccess) {
            LOG_ERROR("Failed to allocate GPU input buffer");
            return false;
        }

        return true;
    }
};
```

#### 不需要写注释的情况
```cpp
// ❌ 过度注释：代码本身已经很清晰
int count = 0;  // 初始化计数器为0

// ❌ 重复代码内容的注释
data.clear();  // 清空数据

// ✅ 好的做法：代码自注释
void processValidPackets(const std::vector<RawDataPacket>& packets) {
    for (const auto& packet : packets) {
        if (packet.isValid()) {
            processPacket(packet);
        }
    }
}
```

### 📋 注释内容指南

#### 解释"为什么"而不是"做什么"
```cpp
// ❌ 解释做什么
i++;  // i 加 1

// ✅ 解释为什么
i++;  // 跳过数据包头，直接处理有效载荷

// ❌ 重复代码逻辑
if (buffer == nullptr) {
    return false;  // 如果缓冲区为空，返回 false
}

// ✅ 解释业务逻辑
if (buffer == nullptr) {
    return false;  // 未初始化的处理器不能执行处理操作
}
```

#### 解释复杂算法的思路
```cpp
void computeFFT(const float* input, cuComplex* output, int N) {
    // 使用 Cooley-Tukey 算法实现 FFT
    // 该算法将 N 点 DFT 分解为两个 N/2 点 DFT，递归计算
    // 时间复杂度从 O(N²) 降低到 O(N log N)

    if (N <= 1) return;

    // 分离偶数和奇数索引的元素
    // 这是分治策略的关键步骤
    separateEvenOdd(input, N);

    // 递归计算两个子问题
    computeFFT(evenElements, output, N/2);
    computeFFT(oddElements, output + N/2, N/2);

    // 合并结果，应用旋转因子
    // 旋转因子 W_N^k = e^(-2πik/N) 确保正确的频域映射
    combineResults(output, N);
}
```

### ⚠️ 特殊标记注释

#### TODO 注释规范
```cpp
// TODO(作者名): 简短描述需要做的事情
// TODO(张三): 优化 GPU 内存分配策略以减少碎片
void allocateMemory() {
    // 当前实现：简单分配
    cudaMalloc(&buffer, size);

    // TODO(李四): 添加内存池管理，预期性能提升 20%
    // 相关 issue: #123
    // 计划完成时间: 2025-10-01
}

// TODO(团队): 实现自适应批大小调整
// 根据 GPU 利用率动态调整处理批大小
// 预期收益: 提升吞吐量 15-30%
class BatchProcessor {
    // 实现...
};
```

#### FIXME 注释规范
```cpp
// FIXME(紧急): 内存泄漏问题
// 在处理大量数据时会发生内存泄漏
// 影响：长时间运行后系统内存耗尽
// 重现：连续处理 >10000 个数据包
void processData() {
    float* tempBuffer = new float[size];
    // ... 处理逻辑
    // FIXME: 这里缺少 delete[] tempBuffer
}

// FIXME(性能): 同步等待导致 GPU 利用率低
// 当前实现在每次处理后都同步等待，导致 GPU 空闲
// 影响：GPU 利用率仅达到 30-40%
// 解决方案：使用 CUDA 流实现异步处理
void processKernel() {
    launchKernel<<<...>>>();
    cudaDeviceSynchronize();  // FIXME: 移除同步等待
}
```

#### WARNING 和 NOTE 注释
```cpp
// WARNING: 此函数不是线程安全的
// 并发调用可能导致数据竞争和未定义行为
// 如需并发使用，请在外部添加互斥锁保护
void updateGlobalConfig(const Config& config) {
    globalConfig = config;  // 非原子操作
}

// NOTE: GPU 内存分配失败时会自动降级到 CPU 处理
// 这种降级是透明的，但性能会显著下降（约 10x）
bool initializeProcessor() {
    if (cudaMalloc(&d_buffer, size) != cudaSuccess) {
        // 降级到 CPU 处理
        h_buffer = new float[size];
        useGPU = false;
    }
}
```

---

## 算法注释策略

### 🧮 复杂算法注释

#### 数学公式和算法原理
```cpp
/**
 * @brief 实现脉冲压缩算法
 *
 * 脉冲压缩通过匹配滤波器提高距离分辨率：
 *
 * 数学原理：
 * y(t) = ∫ x(τ) * h(t-τ) dτ
 * 其中：
 * - x(t): 接收信号
 * - h(t): 匹配滤波器冲激响应
 * - y(t): 压缩后的输出信号
 *
 * 频域实现：
 * Y(f) = X(f) * H*(f)
 * 其中 H*(f) 是滤波器频率响应的共轭
 *
 * @param input 时域输入信号
 * @param filter 匹配滤波器系数
 * @param output 压缩后的输出信号
 */
void pulseCompression(
    const cuComplex* input,
    const cuComplex* filter,
    cuComplex* output,
    int N
) {
    // 1. 对输入信号进行 FFT
    // 将时域信号转换到频域进行快速卷积
    cufftExecC2C(fftPlan, input, d_inputFreq, CUFFT_FORWARD);

    // 2. 频域相乘实现卷积
    // output_freq[k] = input_freq[k] * conj(filter_freq[k])
    complexMultiplyConjugate<<<gridSize, blockSize>>>(
        d_inputFreq, d_filterFreq, d_outputFreq, N);

    // 3. 逆 FFT 回到时域
    // 得到脉冲压缩的最终结果
    cufftExecC2C(fftPlan, d_outputFreq, output, CUFFT_INVERSE);
}
```

#### 算法步骤分解
```cpp
/**
 * @brief 多普勒处理算法实现
 *
 * 算法流程：
 * Step 1: 距离-时间矩阵构建
 * Step 2: 沿慢时间维度的 FFT
 * Step 3: 多普勒滤波
 * Step 4: 非相干积累
 * Step 5: 恒虚警检测 (CFAR)
 */
void dopplerProcessing(const RadarData& input, DopplerResult& output) {
    // Step 1: 构建距离-时间数据矩阵 (Range-Time Matrix)
    // 将连续的脉冲数据重排为二维矩阵
    // 行：距离单元，列：脉冲时间
    arrangeRangeTimeMatrix(input.pulses, rangeTimeMatrix);

    // Step 2: 慢时间维度 FFT (Slow-Time FFT)
    // 沿每个距离单元的时间轴进行 FFT，提取多普勒信息
    // 这一步将速度信息转换为频域表示
    for (int rangeIndex = 0; rangeIndex < numRangeBins; ++rangeIndex) {
        fft1D(&rangeTimeMatrix[rangeIndex][0], dopplerMatrix[rangeIndex], numPulses);
    }

    // Step 3: 多普勒滤波
    // 应用窗函数减少旁瓣，提高检测性能
    applyHammingWindow(dopplerMatrix);

    // Step 4: 非相干积累
    // 计算幅度的平方，实现能量积累
    computePowerSpectrum(dopplerMatrix, powerMatrix);

    // Step 5: 恒虚警检测 (CFAR)
    // 自适应阈值检测，保持恒定的虚警概率
    cfarDetection(powerMatrix, output.detections);
}
```

### ⚡ CUDA Kernel 注释

#### Kernel 函数详细注释
```cuda
/**
 * @brief 并行脉冲压缩 CUDA 核函数
 *
 * 线程组织：
 * - 每个线程处理一个距离单元
 * - 使用共享内存缓存频域数据
 * - 利用 warp 内并行加速 FFT 计算
 *
 * 内存访问模式：
 * - 全局内存：合并访问输入数据
 * - 共享内存：缓存 FFT 中间结果
 * - 常量内存：存储滤波器系数
 *
 * 性能特征：
 * - 计算强度：高（大量复数乘法）
 * - 内存带宽：中等（数据重用度较高）
 * - 同步需求：块内同步（共享内存）
 *
 * @param input [in] 时域输入信号 (N 个复数)
 * @param output [out] 压缩后输出信号 (N 个复数)
 * @param N [in] 信号长度，必须是 2 的幂
 */
__global__ void pulseCompressionKernel(
    const cuComplex* input,
    cuComplex* output,
    int N
) {
    // 计算全局线程索引
    const int tid = blockIdx.x * blockDim.x + threadIdx.x;
    const int localTid = threadIdx.x;

    // 共享内存：缓存一个块的数据进行 FFT
    __shared__ cuComplex s_data[BLOCK_SIZE];
    __shared__ cuComplex s_temp[BLOCK_SIZE];

    // 边界检查：确保不会越界访问
    if (tid >= N) return;

    // 1. 从全局内存加载数据到共享内存
    // 使用合并访问模式提高内存带宽利用率
    s_data[localTid] = input[tid];
    __syncthreads();

    // 2. 块内 FFT 计算
    // 使用 Cooley-Tukey 算法的并行实现
    blockFFT(s_data, s_temp, BLOCK_SIZE);
    __syncthreads();

    // 3. 与匹配滤波器频域响应相乘
    // 滤波器系数存储在常量内存中，访问延迟低
    cuComplex filterCoeff = c_matchedFilter[localTid];
    s_data[localTid] = cuCmul(s_data[localTid], cuConj(filterCoeff));
    __syncthreads();

    // 4. 逆 FFT 回到时域
    blockIFFT(s_data, s_temp, BLOCK_SIZE);
    __syncthreads();

    // 5. 写回全局内存
    output[tid] = s_data[localTid];
}
```

#### 性能关键代码注释
```cuda
/**
 * @brief 高性能复数矩阵乘法核函数
 *
 * 优化技术：
 * 1. 使用共享内存分块 (Tiling) 减少全局内存访问
 * 2. 循环展开 (Loop Unrolling) 减少分支开销
 * 3. 寄存器重用减少内存访问
 * 4. 内存合并访问提高带宽利用率
 *
 * 性能指标：
 * - 理论峰值：~80% GPU 计算能力
 * - 内存效率：~90% 内存带宽
 * - 寄存器使用：32 个/线程（接近上限）
 */
__global__ void optimizedComplexMatMul(
    const cuComplex* A,
    const cuComplex* B,
    cuComplex* C,
    int M, int N, int K
) {
    // 分块大小：经过性能调优确定的最优值
    const int TILE_SIZE = 16;

    // 共享内存分块：减少全局内存访问次数
    __shared__ cuComplex s_A[TILE_SIZE][TILE_SIZE];
    __shared__ cuComplex s_B[TILE_SIZE][TILE_SIZE];

    // 线程和块索引计算
    int row = blockIdx.y * TILE_SIZE + threadIdx.y;
    int col = blockIdx.x * TILE_SIZE + threadIdx.x;

    cuComplex sum = make_cuComplex(0.0f, 0.0f);

    // 分块计算：每次处理 TILE_SIZE x TILE_SIZE 的子矩阵
    for (int tile = 0; tile < (K + TILE_SIZE - 1) / TILE_SIZE; ++tile) {
        // 协作加载：整个块的线程协同加载数据到共享内存
        // 这样可以实现内存合并访问，提高带宽利用率
        int aRow = row;
        int aCol = tile * TILE_SIZE + threadIdx.x;
        int bRow = tile * TILE_SIZE + threadIdx.y;
        int bCol = col;

        // 边界检查和数据加载
        s_A[threadIdx.y][threadIdx.x] =
            (aRow < M && aCol < K) ? A[aRow * K + aCol] : make_cuComplex(0.0f, 0.0f);
        s_B[threadIdx.y][threadIdx.x] =
            (bRow < K && bCol < N) ? B[bRow * N + bCol] : make_cuComplex(0.0f, 0.0f);

        __syncthreads();

        // 计算部分乘积：利用共享内存的低延迟特性
        #pragma unroll  // 编译器提示：展开循环以减少分支开销
        for (int k = 0; k < TILE_SIZE; ++k) {
            sum = cuCadd(sum, cuCmul(s_A[threadIdx.y][k], s_B[k][threadIdx.x]));
        }

        __syncthreads();
    }

    // 写回结果：确保边界检查
    if (row < M && col < N) {
        C[row * N + col] = sum;
    }
}
```

---

## 临时注释管理

### 🏷️ 临时标记规范

#### 开发阶段标记
```cpp
// DRAFT: 初步实现，需要进一步完善
class DataProcessor {
    // DRAFT: 简化的初始化流程，缺少错误处理
    bool initialize() {
        return allocateMemory();
    }
};

// PROTOTYPE: 原型实现，仅用于概念验证
void experimentalAlgorithm() {
    // PROTOTYPE: 基于论文的初步实现
    // 参考：IEEE Signal Processing Magazine, 2024
    // 性能未优化，仅验证算法正确性
}

// STUB: 桩函数，等待具体实现
bool validateConfiguration(const Config& config) {
    // STUB: 临时返回 true，实际验证逻辑待实现
    return true;
}
```

#### 问题追踪标记
```cpp
// BUG: 已知问题，等待修复
void processData() {
    // BUG: 在某些边界条件下会发生越界访问
    // 重现条件：数据大小为奇数且大于 10000
    // 临时解决：添加额外的边界检查
    if (dataSize % 2 == 1 && dataSize > 10000) {
        // 临时处理逻辑
    }
}

// HACK: 临时解决方案，需要更好的实现
void workaroundMemoryIssue() {
    // HACK: CUDA 驱动版本 xxx 的内存分配问题
    // 临时方案：分多次小块分配而不是一次大块分配
    // 正确方案：升级驱动或使用内存池
    for (int i = 0; i < largeSize; i += smallChunk) {
        cudaMalloc(&buffers[i], smallChunk);
    }
}
```

#### 性能和优化标记
```cpp
// PERF: 性能优化点
void computeIntensiveFunction() {
    // PERF: 这个循环是性能瓶颈（占用 60% CPU 时间）
    // 优化方案：
    // 1. 向量化（SIMD）
    // 2. 多线程并行
    // 3. GPU 加速
    for (int i = 0; i < largeN; ++i) {
        result[i] = expensiveComputation(data[i]);
    }
}

// OPTIMIZE: 待优化的代码
void suboptimalImplementation() {
    // OPTIMIZE: 当前实现 O(N²) 复杂度
    // 可以优化为 O(N log N) 使用快速算法
    // 预期性能提升：10x 对于大数据集
    for (int i = 0; i < n; ++i) {
        for (int j = 0; j < n; ++j) {
            // 计算逻辑
        }
    }
}
```

### 📅 临时注释生命周期

#### 注释跟踪模板
```cpp
// TODO(张三, 2025-09-15): 实现自适应滤波算法
// 优先级：高
// 预计工时：3天
// 依赖：等待滤波器系数计算完成
// 相关 issue: #456
void adaptiveFiltering() {
    // 当前占位实现
}

// FIXME(李四, 2025-09-10): 修复内存泄漏
// 发现时间：2025-09-08
// 影响：长时间运行后内存耗尽
// 修复deadline：2025-09-20
// 紧急程度：高
void leakyFunction() {
    // 有问题的实现
}

// REVIEW(团队, 2025-09-12): 代码审查待定
// 审查要点：算法正确性、性能表现
// 审查者：王五、赵六
// 预计审查时间：2小时
class NewAlgorithm {
    // 待审查的实现
};
```

#### 定期清理策略
```markdown
清理周期：
- 每周：检查 TODO 和 FIXME 的进展
- 每月：清理已完成的 DRAFT 和 PROTOTYPE 标记
- 每季度：评估长期 OPTIMIZE 标记的优先级

清理规则：
1. 已解决的问题立即移除标记
2. 过期的 TODO 重新评估优先级
3. 长期未处理的 HACK 制定正式解决方案
4. DRAFT 代码转为正式实现或移除
```

---

## 自动文档生成

### 🔧 Doxygen 配置

#### 项目 Doxyfile 配置
```doxyfile
# Doxyfile - 项目根目录

# 基本配置
PROJECT_NAME           = "Radar MVP System"
PROJECT_VERSION        = "1.0"
PROJECT_BRIEF          = "GPU加速的相控阵雷达数据处理系统"

# 输入配置
INPUT                  = include/ src/ docs/
FILE_PATTERNS          = *.h *.hpp *.cpp *.cu *.md
RECURSIVE              = YES
EXCLUDE_PATTERNS       = */third_party/* */build/* */temp/*

# 输出配置
OUTPUT_DIRECTORY       = docs/api/
GENERATE_HTML          = YES
GENERATE_LATEX         = NO
HTML_OUTPUT            = html
HTML_THEME             = modern

# 代码提取
EXTRACT_ALL            = NO
EXTRACT_PRIVATE        = NO
EXTRACT_STATIC         = YES
EXTRACT_LOCAL_CLASSES  = YES

# 图表生成
HAVE_DOT               = YES
DOT_GRAPH_MAX_NODES    = 100
UML_LOOK               = YES
TEMPLATE_RELATIONS     = YES
INCLUDE_GRAPH          = YES
COLLABORATION_GRAPH    = YES

# 源码浏览
SOURCE_BROWSER         = YES
INLINE_SOURCES         = NO
VERBATIM_HEADERS       = YES

# 警告和错误
QUIET                  = NO
WARNINGS               = YES
WARN_IF_UNDOCUMENTED   = YES
WARN_NO_PARAMDOC       = YES
```

#### 自动化构建集成
```cmake
# CMakeLists.txt - 文档生成目标

find_package(Doxygen REQUIRED)

if(DOXYGEN_FOUND)
    # 配置 Doxygen 输入文件
    set(DOXYGEN_INPUT_DIR ${CMAKE_SOURCE_DIR}/include ${CMAKE_SOURCE_DIR}/src)
    set(DOXYGEN_OUTPUT_DIR ${CMAKE_BINARY_DIR}/docs)

    # 生成 Doxyfile
    configure_file(
        ${CMAKE_SOURCE_DIR}/docs/Doxyfile.in
        ${CMAKE_BINARY_DIR}/Doxyfile
        @ONLY
    )

    # 添加文档生成目标
    add_custom_target(docs
        COMMAND ${DOXYGEN_EXECUTABLE} ${CMAKE_BINARY_DIR}/Doxyfile
        WORKING_DIRECTORY ${CMAKE_BINARY_DIR}
        COMMENT "Generating API documentation with Doxygen"
        VERBATIM
    )

    # 清理文档目标
    add_custom_target(clean-docs
        COMMAND ${CMAKE_COMMAND} -E remove_directory ${DOXYGEN_OUTPUT_DIR}
        COMMENT "Cleaning generated documentation"
    )
endif()
```

### 📊 文档质量检查

#### 注释覆盖率检查
```bash
#!/bin/bash
# scripts/check_doc_coverage.sh

echo "检查文档覆盖率..."

# 统计公共接口数量
public_interfaces=$(grep -r "class.*{" include/ | grep -v "private:" | wc -l)
public_methods=$(grep -r "virtual.*=" include/ | wc -l)

# 统计有文档的接口数量
documented_interfaces=$(grep -r "/\*\*" include/ -A 5 | grep "class" | wc -l)
documented_methods=$(grep -r "/\*\*" include/ -A 5 | grep "virtual.*=" | wc -l)

# 计算覆盖率
interface_coverage=$((documented_interfaces * 100 / public_interfaces))
method_coverage=$((documented_methods * 100 / public_methods))

echo "接口文档覆盖率: $interface_coverage%"
echo "方法文档覆盖率: $method_coverage%"

# 检查覆盖率要求
if [ $interface_coverage -lt 90 ] || [ $method_coverage -lt 85 ]; then
    echo "警告：文档覆盖率不足！"
    echo "要求：接口覆盖率 ≥ 90%，方法覆盖率 ≥ 85%"
    exit 1
fi

echo "文档覆盖率检查通过"
```

#### 注释质量验证
```python
#!/usr/bin/env python3
# scripts/validate_comments.py

import re
import sys
from pathlib import Path

def check_doxygen_format(file_path):
    """检查 Doxygen 注释格式的正确性"""
    issues = []

    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # 检查文件头注释
    if not re.search(r'/\*\*\s*\n\s*\*\s*@file', content):
        issues.append("缺少文件头注释")

    # 检查类注释
    class_matches = re.findall(r'class\s+(\w+)', content)
    for class_name in class_matches:
        if not re.search(rf'/\*\*.*?@brief.*?class\s+{class_name}', content, re.DOTALL):
            issues.append(f"类 {class_name} 缺少 @brief 注释")

    # 检查公共方法注释
    method_matches = re.findall(r'virtual\s+\w+.*?(\w+)\s*\([^)]*\)\s*[=;]', content)
    for method_name in method_matches:
        if not re.search(rf'/\*\*.*?@brief.*?{method_name}', content, re.DOTALL):
            issues.append(f"方法 {method_name} 缺少 @brief 注释")

    return issues

def main():
    """主函数：检查所有头文件的注释质量"""
    include_dir = Path("include")
    total_issues = 0

    for header_file in include_dir.rglob("*.h"):
        issues = check_doxygen_format(header_file)
        if issues:
            print(f"\n{header_file}:")
            for issue in issues:
                print(f"  - {issue}")
            total_issues += len(issues)

    if total_issues > 0:
        print(f"\n发现 {total_issues} 个注释问题")
        sys.exit(1)
    else:
        print("所有注释格式检查通过")

if __name__ == "__main__":
    main()
```

---

## 变更记录

| 版本 | 日期       | 修改人 | 变更摘要           |
| :--- | :--------- | :----- | :----------------- |
| v1.0 | 2025-09-10 | Kelin  | 创建注释和文档规范 |
