# 代码审查要点

- **标题**: AI协作开发代码审查标准指南
- **当前版本**: v1.0
- **最后更新**: 2025-09-10
- **负责人**: Kelin

---

## 审查流程规范

### 📋 审查前准备

#### 作者自检清单
```markdown
## 代码提交前自检清单

### 🔍 基础检查
- [ ] 代码编译通过，无编译错误和警告
- [ ] 所有单元测试通过
- [ ] 代码符合项目编码标准
- [ ] 添加了必要的注释和文档
- [ ] 移除了调试代码和临时注释

### 🏗️ 架构和设计
- [ ] 新代码符合现有架构模式
- [ ] 接口设计合理，职责单一
- [ ] 依赖关系清晰，避免循环依赖
- [ ] 异常处理策略一致
- [ ] 资源管理符合RAII原则

### ⚡ 性能考虑
- [ ] 算法复杂度合理
- [ ] 内存使用效率高
- [ ] 避免了不必要的拷贝和分配
- [ ] CUDA代码利用了GPU并行特性
- [ ] 关键路径已优化

### 🔒 安全和稳定性
- [ ] 输入参数验证充分
- [ ] 边界条件处理正确
- [ ] 线程安全考虑周全
- [ ] 错误处理覆盖完整
- [ ] 资源泄漏检查通过

### 📚 文档和测试
- [ ] API文档完整准确
- [ ] 复杂算法有详细说明
- [ ] 测试覆盖率满足要求
- [ ] 性能基准测试完成
- [ ] 集成测试验证通过
```

#### 审查材料准备
```markdown
## 审查提交材料

### 📄 必须提供
1. **代码变更**: 完整的差分文件
2. **设计文档**: 新功能的设计说明
3. **测试报告**: 单元测试和集成测试结果
4. **性能数据**: 关键路径的性能测试结果
5. **API文档**: 新增或修改的接口文档

### 🔍 额外材料（根据需要）
- 算法复杂度分析
- 内存使用分析
- GPU利用率测试
- 并发安全验证
- 向后兼容性分析

### 📝 变更说明模板
```cpp
/**
 * 变更编号: CR-2025-001
 * 变更类型: [新功能/Bug修复/性能优化/重构]
 * 影响范围: [模块列表]
 *
 * ## 变更摘要
 * 简要描述本次变更的目的和内容
 *
 * ## 详细说明
 * - 修改的主要功能点
 * - 算法或架构的重要变化
 * - 性能影响评估
 *
 * ## 测试验证
 * - 单元测试: [通过/失败 + 详情]
 * - 集成测试: [通过/失败 + 详情]
 * - 性能测试: [结果描述]
 *
 * ## 风险评估
 * - 可能的副作用
 * - 回滚方案
 * - 影响的下游模块
 */
```

### 👥 审查参与者

#### 审查角色定义
```markdown
## 代码审查角色

### 🖋️ 作者 (Author)
**职责**:
- 提供完整准确的审查材料
- 响应审查意见和问题
- 修复发现的问题
- 确保最终代码质量

**技能要求**:
- 熟悉项目架构和编码标准
- 理解所修改模块的业务逻辑
- 具备基本的性能优化意识

### 🔍 主要审查者 (Primary Reviewer)
**职责**:
- 全面审查代码质量和设计
- 评估架构影响和兼容性
- 确认测试覆盖率和质量
- 做出最终审查决定

**技能要求**:
- 项目架构专家级理解
- 丰富的代码审查经验
- 深入的性能优化知识
- 全面的安全意识

### 🎯 专项审查者 (Specialist Reviewer)
**职责**:
- GPU/CUDA代码专项审查
- 算法正确性验证
- 性能优化建议
- 特定领域问题识别

**分类**:
- **CUDA专家**: 审查GPU代码、内存管理、并行算法
- **算法专家**: 审查信号处理算法、数学实现
- **性能专家**: 审查性能关键路径、瓶颈分析
- **安全专家**: 审查安全漏洞、异常处理
```

---

## 审查重点分类

### 🏗️ 架构和设计审查

#### 接口设计评估
```cpp
// ✅ 好的接口设计示例
class IDataProcessor {
public:
    /**
     * @brief 处理数据包
     *
     * 设计要点:
     * 1. 单一职责: 只负责数据处理
     * 2. 明确的输入输出: const输入，引用输出
     * 3. 错误处理: 返回状态码而非抛异常
     * 4. 性能考虑: 避免不必要的数据拷贝
     */
    virtual ProcessingResult process(
        const RawDataPacket& input,    // const引用：明确输入语义
        ProcessedData& output          // 引用：避免拷贝开销
    ) = 0;

    // 状态查询接口：const成员，线程安全
    virtual ProcessorState getState() const = 0;
    virtual bool isReady() const = 0;

    // 配置接口：明确的配置类型
    virtual bool configure(const ProcessorConfig& config) = 0;

    // 资源管理：明确的生命周期
    virtual bool initialize() = 0;
    virtual void cleanup() = 0;
};

// ❌ 需要改进的接口设计
class BadDataProcessor {
public:
    // 问题1: 返回原始指针，所有权不明确
    RawData* getData();

    // 问题2: 参数过多，职责不清
    bool processData(int type, float* input, size_t size,
                    float threshold, bool enableFilter,
                    float* output, size_t* outputSize);

    // 问题3: 异常作为正常控制流
    void setConfig(Config config) throw(InvalidConfigException);

    // 问题4: 全局状态，线程不安全
    static bool isProcessing;
};
```

#### 依赖关系审查
```cpp
/**
 * 依赖关系审查要点:
 * 1. 避免循环依赖
 * 2. 依赖注入而非硬编码依赖
 * 3. 接口依赖而非实现依赖
 * 4. 最小依赖原则
 */

// ✅ 好的依赖设计
class RadarDataProcessor {
private:
    // 依赖注入：通过构造函数传入
    std::shared_ptr<IDataValidator> validator_;
    std::shared_ptr<ILogger> logger_;
    std::shared_ptr<IPerformanceMonitor> perfMonitor_;

public:
    // 构造函数注入依赖
    RadarDataProcessor(
        std::shared_ptr<IDataValidator> validator,
        std::shared_ptr<ILogger> logger,
        std::shared_ptr<IPerformanceMonitor> perfMonitor
    ) : validator_(std::move(validator)),
        logger_(std::move(logger)),
        perfMonitor_(std::move(perfMonitor)) {

        if (!validator_ || !logger_ || !perfMonitor_) {
            throw std::invalid_argument("All dependencies must be provided");
        }
    }

    ProcessingResult process(const RawDataPacket& input) {
        // 使用注入的依赖
        if (!validator_->isValid(input)) {
            logger_->error("Invalid input data packet");
            return ProcessingResult::InvalidInput;
        }

        auto timer = perfMonitor_->createTimer("data_processing");
        // 处理逻辑...

        return ProcessingResult::Success;
    }
};

// ❌ 有问题的依赖设计
class BadRadarProcessor {
public:
    ProcessingResult process(const RawDataPacket& input) {
        // 问题1: 硬编码依赖，难以测试和扩展
        GlobalValidator validator;
        if (!validator.isValid(input)) {
            // 问题2: 直接使用全局日志，耦合严重
            GlobalLogger::getInstance().error("Invalid input");
            return ProcessingResult::InvalidInput;
        }

        // 问题3: 创建昂贵对象，性能问题
        PerformanceMonitor monitor;
        monitor.startTiming();

        // 处理逻辑...

        monitor.endTiming();
        return ProcessingResult::Success;
    }
};
```

### 🔧 实现质量审查

#### 算法实现审查
```cpp
/**
 * 算法实现审查重点:
 * 1. 算法正确性
 * 2. 边界条件处理
 * 3. 数值稳定性
 * 4. 性能优化
 */

// ✅ 优秀的FFT实现示例
class OptimizedFFT {
public:
    /**
     * @brief Cooley-Tukey FFT算法实现
     *
     * 审查要点:
     * 1. 输入验证完整
     * 2. 边界条件处理
     * 3. 数值精度考虑
     * 4. 内存访问优化
     */
    std::vector<std::complex<float>> compute(
        const std::vector<std::complex<float>>& input
    ) {
        // 输入验证
        if (input.empty()) {
            throw std::invalid_argument("Input cannot be empty");
        }

        size_t N = input.size();

        // 检查是否为2的幂
        if ((N & (N - 1)) != 0) {
            throw std::invalid_argument("Input size must be power of 2");
        }

        // 预分配输出空间，避免动态内存分配
        std::vector<std::complex<float>> output = input;

        // 位反转置换 - 优化的查表法
        for (size_t i = 0; i < N; ++i) {
            size_t j = bitReverse(i, log2(N));
            if (i < j) {
                std::swap(output[i], output[j]);
            }
        }

        // Cooley-Tukey递归FFT
        for (size_t length = 2; length <= N; length <<= 1) {
            float angle = -2.0f * M_PI / length;
            std::complex<float> wlen(cosf(angle), sinf(angle));

            for (size_t i = 0; i < N; i += length) {
                std::complex<float> w(1.0f, 0.0f);

                for (size_t j = 0; j < length / 2; ++j) {
                    std::complex<float> u = output[i + j];
                    std::complex<float> v = output[i + j + length / 2] * w;

                    output[i + j] = u + v;
                    output[i + j + length / 2] = u - v;

                    w *= wlen;
                }
            }
        }

        return output;
    }

private:
    /**
     * @brief 优化的位反转函数
     * 使用查表法提高性能
     */
    size_t bitReverse(size_t num, size_t bits) const {
        static std::unordered_map<std::pair<size_t, size_t>, size_t> cache;

        auto key = std::make_pair(num, bits);
        auto it = cache.find(key);
        if (it != cache.end()) {
            return it->second;
        }

        size_t result = 0;
        for (size_t i = 0; i < bits; ++i) {
            result = (result << 1) | (num & 1);
            num >>= 1;
        }

        cache[key] = result;
        return result;
    }
};

// ❌ 需要改进的实现
class ImprovedFFT {
public:
    std::vector<std::complex<float>> compute(
        const std::vector<std::complex<float>>& input
    ) {
        // 问题1: 缺少输入验证
        size_t N = input.size();

        // 问题2: 没有检查大小限制，可能导致内存溢出
        std::vector<std::complex<float>> output(N);

        // 问题3: 使用递归实现，对大数据可能栈溢出
        return recursiveFFT(input);
    }

private:
    std::vector<std::complex<float>> recursiveFFT(
        const std::vector<std::complex<float>>& x
    ) {
        size_t N = x.size();

        // 问题4: 基础情况处理不完整
        if (N <= 1) return x;

        // 问题5: 频繁的内存分配，性能差
        std::vector<std::complex<float>> even, odd;
        for (size_t i = 0; i < N; i += 2) {
            even.push_back(x[i]);
            if (i + 1 < N) odd.push_back(x[i + 1]);
        }

        // 问题6: 重复计算旋转因子
        auto evenFFT = recursiveFFT(even);
        auto oddFFT = recursiveFFT(odd);

        std::vector<std::complex<float>> result(N);
        for (size_t k = 0; k < N / 2; ++k) {
            // 问题7: 数值精度问题，应使用更精确的三角函数
            auto t = std::polar(1.0f, -2.0f * M_PI * k / N) * oddFFT[k];
            result[k] = evenFFT[k] + t;
            result[k + N / 2] = evenFFT[k] - t;
        }

        return result;
    }
};
```

#### 错误处理审查
```cpp
/**
 * 错误处理审查要点:
 * 1. 异常安全保证
 * 2. 资源清理完整性
 * 3. 错误信息的有用性
 * 4. 错误恢复策略
 */

// ✅ 优秀的错误处理示例
class RobustDataProcessor {
private:
    std::unique_ptr<GPUMemory> gpuMemory_;
    std::unique_ptr<CUDAStream> computeStream_;
    std::shared_ptr<ILogger> logger_;

public:
    /**
     * @brief 异常安全的数据处理
     *
     * 提供强异常安全保证：
     * - 要么完全成功
     * - 要么完全失败且对象状态不变
     */
    ProcessingResult processData(const DataPacket& input) noexcept {
        try {
            // 输入验证
            auto validationResult = validateInput(input);
            if (validationResult != ValidationResult::Valid) {
                return createErrorResult(
                    ProcessingError::InvalidInput,
                    "Input validation failed: " + toString(validationResult)
                );
            }

            // 资源准备 - 使用RAII确保异常安全
            auto gpuBuffer = prepareGPUResources(input.size());
            if (!gpuBuffer) {
                return createErrorResult(
                    ProcessingError::ResourceAllocation,
                    "Failed to allocate GPU memory"
                );
            }

            // 数据传输 - 有超时保护
            auto transferResult = transferDataWithTimeout(input, *gpuBuffer);
            if (!transferResult) {
                return createErrorResult(
                    ProcessingError::DataTransfer,
                    "GPU data transfer failed: " + transferResult.error()
                );
            }

            // 核心处理 - 有性能监控
            auto processingTimer = logger_->createTimer("gpu_processing");
            auto result = performGPUProcessing(*gpuBuffer);

            if (!result.success) {
                logger_->error("GPU processing failed", {
                    {"error_code", std::to_string(static_cast<int>(result.errorCode))},
                    {"processing_time_ms", std::to_string(processingTimer.elapsedMs())},
                    {"input_size_bytes", std::to_string(input.size())}
                });

                return createErrorResult(result.errorCode, result.errorMessage);
            }

            // 成功返回
            logger_->debug("Processing completed successfully", {
                {"processing_time_ms", std::to_string(processingTimer.elapsedMs())},
                {"output_targets", std::to_string(result.targets.size())}
            });

            return ProcessingResult::success(std::move(result.targets));

        } catch (const CudaException& e) {
            // CUDA特定异常处理
            logger_->error("CUDA error during processing", {
                {"error_code", std::to_string(e.getCudaError())},
                {"error_message", e.what()},
                {"function", __FUNCTION__},
                {"line", std::to_string(__LINE__)}
            });

            return createErrorResult(
                ProcessingError::GPUError,
                "CUDA error: " + std::string(e.what())
            );

        } catch (const std::bad_alloc& e) {
            // 内存分配失败
            logger_->error("Memory allocation failed", {
                {"requested_size", std::to_string(input.size())},
                {"available_memory", std::to_string(getAvailableMemory())}
            });

            return createErrorResult(
                ProcessingError::OutOfMemory,
                "Insufficient memory for processing"
            );

        } catch (const std::exception& e) {
            // 其他标准异常
            logger_->error("Unexpected error during processing", {
                {"exception_type", typeid(e).name()},
                {"exception_message", e.what()}
            });

            return createErrorResult(
                ProcessingError::UnknownError,
                "Unexpected error: " + std::string(e.what())
            );

        } catch (...) {
            // 未知异常
            logger_->error("Unknown exception caught during processing");

            return createErrorResult(
                ProcessingError::UnknownError,
                "Unknown exception occurred"
            );
        }
    }

private:
    /**
     * @brief 创建错误结果
     * 确保错误信息完整且有用
     */
    ProcessingResult createErrorResult(
        ProcessingError errorCode,
        const std::string& message
    ) noexcept {
        ProcessingResult result;
        result.success = false;
        result.errorCode = errorCode;
        result.errorMessage = message;
        result.timestamp = std::chrono::system_clock::now();

        // 添加诊断信息
        result.diagnostics = {
            {"processor_state", toString(getCurrentState())},
            {"available_gpu_memory", std::to_string(getAvailableGPUMemory())},
            {"system_load", std::to_string(getSystemLoad())}
        };

        return result;
    }

    /**
     * @brief 输入验证
     * 全面的数据有效性检查
     */
    ValidationResult validateInput(const DataPacket& input) const {
        if (input.empty()) {
            return ValidationResult::EmptyInput;
        }

        if (input.size() > MAX_PACKET_SIZE) {
            return ValidationResult::TooLarge;
        }

        if (!input.hasValidChecksum()) {
            return ValidationResult::CorruptedData;
        }

        if (!input.hasRequiredMetadata()) {
            return ValidationResult::MissingMetadata;
        }

        return ValidationResult::Valid;
    }
};
```

### 🚀 CUDA代码审查

#### GPU内存管理审查
```cuda
/**
 * CUDA代码审查重点:
 * 1. 内存分配和释放配对
 * 2. 异步操作的同步
 * 3. 错误检查完整性
 * 4. 性能优化技术
 */

// ✅ 优秀的CUDA内存管理示例
class CUDAMemoryManager {
private:
    struct GPUBuffer {
        void* devicePtr;
        size_t size;
        cudaStream_t stream;
        bool isAllocated;

        GPUBuffer() : devicePtr(nullptr), size(0),
                     stream(0), isAllocated(false) {}

        ~GPUBuffer() {
            if (isAllocated && devicePtr) {
                // 异步释放，避免阻塞
                cudaFreeAsync(devicePtr, stream);
            }
        }
    };

    std::vector<std::unique_ptr<GPUBuffer>> buffers_;
    cudaStream_t memoryStream_;

public:
    /**
     * @brief 构造函数，创建专用内存流
     */
    CUDAMemoryManager() {
        cudaError_t result = cudaStreamCreate(&memoryStream_);
        if (result != cudaSuccess) {
            throw CudaException("Failed to create memory stream", result);
        }
    }

    /**
     * @brief 析构函数，确保资源清理
     */
    ~CUDAMemoryManager() {
        // 等待所有异步操作完成
        if (memoryStream_) {
            cudaStreamSynchronize(memoryStream_);
            cudaStreamDestroy(memoryStream_);
        }

        // buffers_的析构函数会自动清理GPU内存
    }

    /**
     * @brief 分配GPU内存
     *
     * 审查要点:
     * 1. 完整的错误检查
     * 2. 异常安全保证
     * 3. 内存对齐优化
     * 4. 资源跟踪
     */
    std::unique_ptr<GPUBuffer> allocateBuffer(size_t sizeBytes) {
        if (sizeBytes == 0) {
            throw std::invalid_argument("Cannot allocate zero-sized buffer");
        }

        // 内存对齐到256字节边界，优化GPU访问
        size_t alignedSize = ((sizeBytes + 255) / 256) * 256;

        auto buffer = std::make_unique<GPUBuffer>();
        buffer->size = alignedSize;
        buffer->stream = memoryStream_;

        // 使用异步分配提高性能
        cudaError_t result = cudaMallocAsync(
            &buffer->devicePtr,
            alignedSize,
            memoryStream_
        );

        if (result != cudaSuccess) {
            // 尝试垃圾回收后重试
            tryGarbageCollection();

            result = cudaMallocAsync(
                &buffer->devicePtr,
                alignedSize,
                memoryStream_
            );

            if (result != cudaSuccess) {
                throw CudaException(
                    "Failed to allocate GPU memory after GC", result);
            }
        }

        buffer->isAllocated = true;

        // 初始化内存为零（可选，用于调试）
        #ifdef DEBUG
        cudaMemsetAsync(buffer->devicePtr, 0, alignedSize, memoryStream_);
        #endif

        // 跟踪分配的缓冲区
        buffers_.push_back(std::unique_ptr<GPUBuffer>(buffer.get()));

        return buffer;
    }

    /**
     * @brief 异步数据传输
     *
     * 审查要点:
     * 1. 异步操作的错误处理
     * 2. 内存边界检查
     * 3. 流同步管理
     */
    cudaError_t copyHostToDeviceAsync(
        void* devicePtr,
        const void* hostPtr,
        size_t sizeBytes,
        cudaStream_t stream = 0
    ) {
        // 参数验证
        if (!devicePtr || !hostPtr || sizeBytes == 0) {
            return cudaErrorInvalidValue;
        }

        // 检查设备指针有效性
        cudaPointerAttributes attributes;
        cudaError_t result = cudaPointerGetAttributes(&attributes, devicePtr);
        if (result != cudaSuccess) {
            return result;
        }

        if (attributes.type != cudaMemoryTypeDevice) {
            return cudaErrorInvalidDevicePointer;
        }

        // 异步拷贝
        cudaStream_t targetStream = (stream != 0) ? stream : memoryStream_;
        return cudaMemcpyAsync(
            devicePtr, hostPtr, sizeBytes,
            cudaMemcpyHostToDevice, targetStream
        );
    }

private:
    /**
     * @brief 垃圾回收，释放未使用的内存
     */
    void tryGarbageCollection() {
        // 移除已释放的缓冲区
        buffers_.erase(
            std::remove_if(buffers_.begin(), buffers_.end(),
                [](const std::unique_ptr<GPUBuffer>& buffer) {
                    return !buffer->isAllocated;
                }),
            buffers_.end()
        );

        // 强制CUDA上下文同步，清理内部缓存
        cudaDeviceSynchronize();
    }
};

// ❌ 需要改进的CUDA代码
class ImprovedCUDACode {
public:
    void processData(float* hostData, size_t dataSize) {
        float* deviceData;

        // 问题1: 没有错误检查
        cudaMalloc(&deviceData, dataSize * sizeof(float));

        // 问题2: 同步拷贝，性能差
        cudaMemcpy(deviceData, hostData, dataSize * sizeof(float),
                  cudaMemcpyHostToDevice);

        // 问题3: 硬编码的核函数配置
        processKernel<<<256, 256>>>(deviceData, dataSize);

        // 问题4: 没有同步检查核函数执行

        // 问题5: 同步拷贝回主机
        cudaMemcpy(hostData, deviceData, dataSize * sizeof(float),
                  cudaMemcpyDeviceToHost);

        // 问题6: 可能存在内存泄漏，如果前面操作失败
        cudaFree(deviceData);
    }
};
```

#### 核函数性能审查
```cuda
/**
 * 核函数性能审查要点:
 * 1. 线程块和网格配置
 * 2. 共享内存使用
 * 3. 内存合并访问
 * 4. 银行冲突避免
 */

// ✅ 优化的矩阵乘法核函数
__global__ void optimizedMatrixMultiply(
    const float* __restrict__ A,  // __restrict__ 告诉编译器指针不重叠
    const float* __restrict__ B,
    float* __restrict__ C,
    int M, int N, int K
) {
    // 分块大小经过调优确定
    const int TILE_SIZE = 16;

    // 共享内存：减少全局内存访问
    __shared__ float sharedA[TILE_SIZE][TILE_SIZE];
    __shared__ float sharedB[TILE_SIZE][TILE_SIZE];

    // 线程索引计算
    int tx = threadIdx.x;
    int ty = threadIdx.y;
    int row = blockIdx.y * TILE_SIZE + ty;
    int col = blockIdx.x * TILE_SIZE + tx;

    float sum = 0.0f;

    // 分块计算，提高缓存命中率
    for (int tile = 0; tile < (K + TILE_SIZE - 1) / TILE_SIZE; ++tile) {
        // 协作加载数据到共享内存
        // 确保内存合并访问
        int aCol = tile * TILE_SIZE + tx;
        int bRow = tile * TILE_SIZE + ty;

        // 边界检查，避免越界访问
        sharedA[ty][tx] = (row < M && aCol < K) ? A[row * K + aCol] : 0.0f;
        sharedB[ty][tx] = (bRow < K && col < N) ? B[bRow * N + col] : 0.0f;

        // 同步：确保所有线程完成数据加载
        __syncthreads();

        // 计算部分乘积
        #pragma unroll  // 循环展开优化
        for (int k = 0; k < TILE_SIZE; ++k) {
            sum += sharedA[ty][k] * sharedB[k][tx];
        }

        // 同步：准备下一轮加载
        __syncthreads();
    }

    // 写回结果，边界检查
    if (row < M && col < N) {
        C[row * N + col] = sum;
    }
}

/**
 * 核函数启动配置审查
 */
class OptimizedKernelLauncher {
public:
    /**
     * @brief 计算最优启动配置
     *
     * 审查要点:
     * 1. 占用率优化
     * 2. 共享内存限制考虑
     * 3. 寄存器使用评估
     */
    dim3 calculateOptimalConfig(int M, int N, int K) {
        // 查询设备属性
        cudaDeviceProp prop;
        cudaGetDeviceProperties(&prop, 0);

        // 基础块大小
        const int TILE_SIZE = 16;

        // 计算网格维度
        dim3 blockDim(TILE_SIZE, TILE_SIZE);
        dim3 gridDim(
            (N + TILE_SIZE - 1) / TILE_SIZE,
            (M + TILE_SIZE - 1) / TILE_SIZE
        );

        // 检查资源限制
        size_t sharedMemPerBlock = 2 * TILE_SIZE * TILE_SIZE * sizeof(float);
        if (sharedMemPerBlock > prop.sharedMemPerBlock) {
            throw std::runtime_error("Shared memory requirements exceed device limits");
        }

        // 检查网格限制
        if (gridDim.x > prop.maxGridSize[0] || gridDim.y > prop.maxGridSize[1]) {
            throw std::runtime_error("Grid dimensions exceed device limits");
        }

        return gridDim;
    }

    /**
     * @brief 启动优化的矩阵乘法
     */
    void launchMatrixMultiply(
        const float* A, const float* B, float* C,
        int M, int N, int K,
        cudaStream_t stream = 0
    ) {
        auto gridDim = calculateOptimalConfig(M, N, K);
        dim3 blockDim(16, 16);

        // 动态共享内存大小
        size_t sharedMemSize = 2 * 16 * 16 * sizeof(float);

        // 启动核函数
        optimizedMatrixMultiply<<<gridDim, blockDim, sharedMemSize, stream>>>(
            A, B, C, M, N, K
        );

        // 检查启动错误
        cudaError_t launchError = cudaGetLastError();
        if (launchError != cudaSuccess) {
            throw CudaException("Kernel launch failed", launchError);
        }

        // 异步检查执行错误（可选）
        #ifdef DEBUG
        cudaStreamSynchronize(stream);
        cudaError_t execError = cudaGetLastError();
        if (execError != cudaSuccess) {
            throw CudaException("Kernel execution failed", execError);
        }
        #endif
    }
};
```

---

## 审查决策和跟踪

### ✅ 审查结果分类

#### 审查结论定义
```markdown
## 审查结果分类

### 🟢 通过 (Approved)
**条件**:
- 代码质量达到项目标准
- 所有必要测试通过
- 文档完整准确
- 无重大设计问题

**后续动作**:
- 可以直接合并到主分支
- 更新相关文档
- 通知相关团队成员

### 🟡 有条件通过 (Approved with Minor Changes)
**条件**:
- 整体设计和实现正确
- 存在少量非关键问题
- 问题可快速修复

**后续动作**:
- 作者修复指出的问题
- 主要审查者确认修复
- 修复后可合并

### 🟠 需要修改 (Changes Requested)
**条件**:
- 存在重要的设计或实现问题
- 测试覆盖不足
- 性能问题需要解决

**后续动作**:
- 作者进行重大修改
- 需要重新提交审查
- 可能需要设计讨论

### 🔴 拒绝 (Rejected)
**条件**:
- 严重的架构问题
- 不符合项目要求
- 安全漏洞

**后续动作**:
- 需要重新设计
- 必须提供新的实现方案
- 可能需要架构评审
```

#### 问题分级系统
```markdown
## 问题严重性分级

### 🚨 阻塞性问题 (Blocker)
**定义**: 必须修复才能合并的问题
**示例**:
- 内存泄漏
- 安全漏洞
- 核心功能错误
- 性能回归 >20%

### ⚠️ 重要问题 (Major)
**定义**: 应该修复的重要问题
**示例**:
- 设计不一致
- 错误处理不完整
- 测试覆盖不足
- 文档缺失

### 💡 一般问题 (Minor)
**定义**: 建议修复的改进点
**示例**:
- 代码风格不一致
- 变量命名不清晰
- 注释可以更详细
- 小的性能优化机会

### 📝 建议 (Suggestion)
**定义**: 可选的改进建议
**示例**:
- 更好的算法实现
- 代码结构优化
- 额外的测试用例
- 未来扩展考虑
```

### 📊 审查跟踪模板

#### 审查记录模板
```markdown
# 代码审查记录

## 基本信息
- **审查编号**: CR-2025-001
- **提交者**: 张三
- **审查者**: 李四（主要），王五（CUDA专家）
- **审查日期**: 2025-09-10
- **代码分支**: feature/new-algorithm
- **影响模块**: data_processor, gpu_kernels

## 变更摘要
简要描述本次代码变更的目的和内容...

## 审查发现

### 🚨 阻塞性问题
1. **内存泄漏** [文件: gpu_processor.cpp, 行: 145]
   - **问题描述**: CUDA内存分配后未正确释放
   - **影响**: 长时间运行会导致GPU内存耗尽
   - **建议**: 使用RAII包装器管理GPU内存
   - **状态**: 🔴 待修复

### ⚠️ 重要问题
2. **错误处理不完整** [文件: data_receiver.h, 行: 67]
   - **问题描述**: 网络错误时缺少适当的重试机制
   - **影响**: 网络故障时系统可能停止工作
   - **建议**: 添加指数退避重试策略
   - **状态**: 🔴 待修复

3. **性能问题** [文件: fft_kernels.cu, 行: 234]
   - **问题描述**: 未使用共享内存优化，性能损失约15%
   - **影响**: 实时处理性能不达标
   - **建议**: 实现分块FFT算法
   - **状态**: 🔴 待修复

### 💡 一般问题
4. **代码风格** [文件: 多个文件]
   - **问题描述**: 变量命名不符合项目标准
   - **影响**: 代码可读性降低
   - **建议**: 统一使用camelCase命名
   - **状态**: 🟡 建议修复

### 📝 建议
5. **算法优化** [文件: signal_processor.cpp, 行: 156]
   - **问题描述**: 可以使用更高效的Wiener滤波算法
   - **影响**: 无直接影响，但可提升性能
   - **建议**: 考虑在后续版本中实现
   - **状态**: 🟢 可选

## 审查总结
- **总问题数**: 5个
- **阻塞性问题**: 1个
- **重要问题**: 2个
- **一般问题**: 1个
- **建议**: 1个

## 审查决策
🟠 **需要修改** - 必须修复所有阻塞性和重要问题

## 后续动作
1. 作者修复问题1-3
2. 重新提交代码审查
3. 主要审查者确认修复质量
4. 通过后可合并到主分支

## 审查者签名
- 李四 (主要审查者): ✅ 审查完成
- 王五 (CUDA专家): ✅ GPU代码审查完成
```

#### 问题跟踪表
```markdown
| 问题ID  | 类型   | 文件                 | 行号 | 描述           | 状态     | 分配给 | 预计完成   |
| ------- | ------ | -------------------- | ---- | -------------- | -------- | ------ | ---------- |
| CR001-1 | 🚨 阻塞 | gpu_processor.cpp    | 145  | CUDA内存泄漏   | 🔴 待修复 | 张三   | 2025-09-12 |
| CR001-2 | ⚠️ 重要 | data_receiver.h      | 67   | 错误处理不完整 | 🔴 待修复 | 张三   | 2025-09-13 |
| CR001-3 | ⚠️ 重要 | fft_kernels.cu       | 234  | 性能优化       | 🔴 待修复 | 张三   | 2025-09-15 |
| CR001-4 | 💡 一般 | 多个                 | -    | 命名规范       | 🟡 建议   | 张三   | 2025-09-16 |
| CR001-5 | 📝 建议 | signal_processor.cpp | 156  | 算法优化       | 🟢 可选   | -      | 待定       |
```

---

## 变更记录

| 版本 | 日期       | 修改人 | 变更摘要                       |
| :--- | :--------- | :----- | :----------------------------- |
| v1.0 | 2025-09-10 | Kelin  | 创建AI协作开发代码审查标准指南 |
