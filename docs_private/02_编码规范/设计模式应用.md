# è®¾è®¡æ¨¡å¼åº”ç”¨

- **æ ‡é¢˜**: AIåä½œå¼€å‘è®¾è®¡æ¨¡å¼å®è·µæŒ‡å—
- **å½“å‰ç‰ˆæœ¬**: v1.0
- **æœ€åæ›´æ–°**: 2025-09-10
- **è´Ÿè´£äºº**: Kelin

---

## æ¥å£è®¾è®¡æ¨¡å¼

### ğŸ¯ ç­–ç•¥æ¨¡å¼ (Strategy Pattern)

#### æ•°æ®å¤„ç†ç­–ç•¥æŠ½è±¡
```cpp
/**
 * @brief æ•°æ®å¤„ç†ç­–ç•¥æ¥å£
 *
 * å®šä¹‰äº†æ•°æ®å¤„ç†çš„ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒè¿è¡Œæ—¶åˆ‡æ¢ä¸åŒçš„å¤„ç†ç®—æ³•ã€‚
 * é€‚ç”¨åœºæ™¯ï¼šGPU/CPUå¤„ç†åˆ‡æ¢ã€ä¸åŒç®—æ³•é€‰æ‹©ã€æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ã€‚
 */
class IProcessingStrategy {
public:
    virtual ~IProcessingStrategy() = default;

    /**
     * @brief å¤„ç†è¾“å…¥æ•°æ®
     * @param input åŸå§‹è¾“å…¥æ•°æ®
     * @param output å¤„ç†ç»“æœè¾“å‡º
     * @return å¤„ç†çŠ¶æ€ç 
     */
    virtual ProcessingResult process(
        const RawDataPacket& input,
        ProcessedData& output
    ) = 0;

    /**
     * @brief è·å–ç­–ç•¥åç§°
     * @return ç­–ç•¥çš„æè¿°æ€§åç§°
     */
    virtual std::string getStrategyName() const = 0;

    /**
     * @brief è·å–ç­–ç•¥æ€§èƒ½ç‰¹å¾
     * @return å»¶è¿Ÿã€ååé‡ç­‰æ€§èƒ½æŒ‡æ ‡
     */
    virtual PerformanceCharacteristics getPerformanceProfile() const = 0;
};

/**
 * @brief GPUåŠ é€Ÿå¤„ç†ç­–ç•¥
 *
 * åˆ©ç”¨CUDAå®ç°é«˜æ€§èƒ½å¹¶è¡Œå¤„ç†ï¼Œé€‚åˆå¤§æ•°æ®é‡ã€è®¡ç®—å¯†é›†çš„åœºæ™¯ã€‚
 */
class GPUProcessingStrategy : public IProcessingStrategy {
private:
    std::unique_ptr<CUDAProcessor> cudaProcessor_;
    cudaStream_t processingStream_;

public:
    explicit GPUProcessingStrategy(const CUDAConfig& config);

    ProcessingResult process(
        const RawDataPacket& input,
        ProcessedData& output
    ) override;

    std::string getStrategyName() const override {
        return "High-Performance GPU Processing";
    }

    PerformanceCharacteristics getPerformanceProfile() const override {
        return {
            .latency = std::chrono::microseconds(50),      // è¶…ä½å»¶è¿Ÿ
            .throughput = 10e9,                            // 10GB/sååé‡
            .powerConsumption = PowerLevel::High,          // é«˜åŠŸè€—
            .memoryRequirement = MemorySize::Large         // å¤§å†…å­˜éœ€æ±‚
        };
    }
};

/**
 * @brief CPUä¼˜åŒ–å¤„ç†ç­–ç•¥
 *
 * åŸºäºå¤šæ ¸CPUçš„å¹¶è¡Œå¤„ç†ï¼Œå¹³è¡¡æ€§èƒ½å’Œèµ„æºæ¶ˆè€—ã€‚
 */
class CPUProcessingStrategy : public IProcessingStrategy {
private:
    std::unique_ptr<ThreadPool> threadPool_;
    std::vector<std::unique_ptr<ProcessingWorker>> workers_;

public:
    explicit CPUProcessingStrategy(int threadCount);

    ProcessingResult process(
        const RawDataPacket& input,
        ProcessedData& output
    ) override;

    std::string getStrategyName() const override {
        return "Multi-threaded CPU Processing";
    }

    PerformanceCharacteristics getPerformanceProfile() const override {
        return {
            .latency = std::chrono::microseconds(200),     // ä¸­ç­‰å»¶è¿Ÿ
            .throughput = 2e9,                             // 2GB/sååé‡
            .powerConsumption = PowerLevel::Medium,        // ä¸­ç­‰åŠŸè€—
            .memoryRequirement = MemorySize::Medium        // ä¸­ç­‰å†…å­˜éœ€æ±‚
        };
    }
};
```

#### ç­–ç•¥ç®¡ç†å™¨å®ç°
```cpp
/**
 * @brief å¤„ç†ç­–ç•¥ç®¡ç†å™¨
 *
 * è´Ÿè´£ç­–ç•¥çš„æ³¨å†Œã€é€‰æ‹©å’ŒåŠ¨æ€åˆ‡æ¢ã€‚æ”¯æŒåŸºäºæ€§èƒ½è¦æ±‚ã€
 * ç³»ç»Ÿèµ„æºçŠ¶å†µçš„è‡ªåŠ¨ç­–ç•¥é€‰æ‹©ã€‚
 */
class ProcessingStrategyManager {
private:
    std::map<std::string, std::unique_ptr<IProcessingStrategy>> strategies_;
    std::string currentStrategyName_;
    std::unique_ptr<PerformanceMonitor> performanceMonitor_;

public:
    /**
     * @brief æ³¨å†Œå¤„ç†ç­–ç•¥
     * @param name ç­–ç•¥åç§°
     * @param strategy ç­–ç•¥å®ç°
     */
    void registerStrategy(
        const std::string& name,
        std::unique_ptr<IProcessingStrategy> strategy
    ) {
        strategies_[name] = std::move(strategy);
    }

    /**
     * @brief è®¾ç½®å½“å‰æ´»åŠ¨ç­–ç•¥
     * @param strategyName è¦æ¿€æ´»çš„ç­–ç•¥åç§°
     * @return æ˜¯å¦æˆåŠŸåˆ‡æ¢
     */
    bool setActiveStrategy(const std::string& strategyName) {
        auto it = strategies_.find(strategyName);
        if (it != strategies_.end()) {
            currentStrategyName_ = strategyName;
            LOG_INFO("Switched to strategy: " + strategyName);
            return true;
        }
        return false;
    }

    /**
     * @brief åŸºäºæ€§èƒ½è¦æ±‚è‡ªåŠ¨é€‰æ‹©ç­–ç•¥
     * @param requirements æ€§èƒ½éœ€æ±‚
     * @return é€‰ä¸­çš„ç­–ç•¥åç§°
     */
    std::string selectOptimalStrategy(const PerformanceRequirements& requirements) {
        std::string bestStrategy;
        double bestScore = 0.0;

        for (const auto& [name, strategy] : strategies_) {
            auto profile = strategy->getPerformanceProfile();
            double score = calculateStrategyScore(profile, requirements);

            if (score > bestScore) {
                bestScore = score;
                bestStrategy = name;
            }
        }

        if (!bestStrategy.empty()) {
            setActiveStrategy(bestStrategy);
        }

        return bestStrategy;
    }

    /**
     * @brief ä½¿ç”¨å½“å‰ç­–ç•¥å¤„ç†æ•°æ®
     */
    ProcessingResult processWithCurrentStrategy(
        const RawDataPacket& input,
        ProcessedData& output
    ) {
        if (currentStrategyName_.empty() ||
            strategies_.find(currentStrategyName_) == strategies_.end()) {
            throw std::runtime_error("No active processing strategy");
        }

        auto& currentStrategy = strategies_[currentStrategyName_];

        // æ€§èƒ½ç›‘æ§
        auto startTime = std::chrono::high_resolution_clock::now();
        auto result = currentStrategy->process(input, output);
        auto endTime = std::chrono::high_resolution_clock::now();

        // è®°å½•æ€§èƒ½æ•°æ®
        performanceMonitor_->recordProcessingTime(
            currentStrategyName_,
            std::chrono::duration_cast<std::chrono::microseconds>(endTime - startTime)
        );

        return result;
    }

private:
    /**
     * @brief è®¡ç®—ç­–ç•¥è¯„åˆ†
     * @param profile ç­–ç•¥æ€§èƒ½ç‰¹å¾
     * @param requirements æ€§èƒ½éœ€æ±‚
     * @return ç­–ç•¥é€‚åˆåº¦è¯„åˆ†
     */
    double calculateStrategyScore(
        const PerformanceCharacteristics& profile,
        const PerformanceRequirements& requirements
    ) {
        double score = 0.0;

        // å»¶è¿Ÿæƒé‡è¯„åˆ†
        if (profile.latency <= requirements.maxLatency) {
            score += 0.4 * (1.0 - static_cast<double>(profile.latency.count()) /
                                   requirements.maxLatency.count());
        }

        // ååé‡æƒé‡è¯„åˆ†
        if (profile.throughput >= requirements.minThroughput) {
            score += 0.4 * (profile.throughput / requirements.minThroughput);
        }

        // èµ„æºæ¶ˆè€—æƒé‡è¯„åˆ†
        score += 0.2 * calculateResourceScore(profile, requirements);

        return std::min(score, 1.0);  // é™åˆ¶æœ€å¤§è¯„åˆ†ä¸º1.0
    }
};
```

### ğŸ­ å·¥å‚æ¨¡å¼ (Factory Pattern)

#### æŠ½è±¡å·¥å‚è®¾è®¡
```cpp
/**
 * @brief é›·è¾¾ç»„ä»¶æŠ½è±¡å·¥å‚
 *
 * å®šä¹‰åˆ›å»ºç›¸å…³é›·è¾¾ç»„ä»¶æ—çš„æ¥å£ã€‚ç¡®ä¿åˆ›å»ºçš„ç»„ä»¶ä¹‹é—´
 * å…¼å®¹å’Œåè°ƒå·¥ä½œã€‚
 */
class IRadarComponentFactory {
public:
    virtual ~IRadarComponentFactory() = default;

    // æ ¸å¿ƒç»„ä»¶åˆ›å»ºæ¥å£
    virtual std::unique_ptr<IDataReceiver> createDataReceiver() = 0;
    virtual std::unique_ptr<IDataProcessor> createDataProcessor() = 0;
    virtual std::unique_ptr<IDisplayController> createDisplayController() = 0;
    virtual std::unique_ptr<ITaskScheduler> createTaskScheduler() = 0;

    // è¾…åŠ©ç»„ä»¶åˆ›å»ºæ¥å£
    virtual std::unique_ptr<IConfigurationManager> createConfigManager() = 0;
    virtual std::unique_ptr<IPerformanceMonitor> createPerformanceMonitor() = 0;
    virtual std::unique_ptr<ILogger> createLogger() = 0;

    // å·¥å‚å…ƒä¿¡æ¯
    virtual std::string getFactoryType() const = 0;
    virtual std::vector<std::string> getSupportedConfigurations() const = 0;
};

/**
 * @brief é«˜æ€§èƒ½GPUå·¥å‚
 *
 * åˆ›å»ºåŸºäºGPUåŠ é€Ÿçš„é«˜æ€§èƒ½é›·è¾¾ç»„ä»¶æ—ã€‚
 * é€‚ç”¨äºå®æ—¶é«˜ååé‡å¤„ç†åœºæ™¯ã€‚
 */
class HighPerformanceGPUFactory : public IRadarComponentFactory {
private:
    CUDADeviceInfo deviceInfo_;
    GPUFactoryConfig config_;

public:
    explicit HighPerformanceGPUFactory(const GPUFactoryConfig& config)
        : config_(config) {
        // åˆå§‹åŒ–CUDAè®¾å¤‡ä¿¡æ¯
        initializeCUDADevice();
    }

    std::unique_ptr<IDataReceiver> createDataReceiver() override {
        return std::make_unique<HighSpeedEthernetReceiver>(
            config_.networkConfig,
            config_.bufferSize
        );
    }

    std::unique_ptr<IDataProcessor> createDataProcessor() override {
        return std::make_unique<CUDAGPUProcessor>(
            deviceInfo_,
            config_.processingConfig
        );
    }

    std::unique_ptr<IDisplayController> createDisplayController() override {
        return std::make_unique<OpenGLDisplayController>(
            config_.displayConfig,
            deviceInfo_.deviceId  // ä½¿ç”¨åŒä¸€GPUè®¾å¤‡
        );
    }

    std::unique_ptr<ITaskScheduler> createTaskScheduler() override {
        return std::make_unique<GPUOptimizedScheduler>(
            config_.schedulingConfig,
            deviceInfo_.maxConcurrentKernels
        );
    }

    std::string getFactoryType() const override {
        return "High-Performance GPU Factory";
    }

    std::vector<std::string> getSupportedConfigurations() const override {
        return {
            "real-time-processing",
            "high-throughput-batch",
            "low-latency-streaming",
            "gpu-memory-optimized"
        };
    }
};

/**
 * @brief åµŒå…¥å¼ä½åŠŸè€—å·¥å‚
 *
 * åˆ›å»ºé€‚ç”¨äºåµŒå…¥å¼ç³»ç»Ÿçš„ä½åŠŸè€—ç»„ä»¶æ—ã€‚
 * å¹³è¡¡æ€§èƒ½å’ŒåŠŸè€—ï¼Œé€‚ç”¨äºèµ„æºå—é™ç¯å¢ƒã€‚
 */
class EmbeddedLowPowerFactory : public IRadarComponentFactory {
private:
    EmbeddedSystemInfo systemInfo_;
    PowerManagementConfig powerConfig_;

public:
    explicit EmbeddedLowPowerFactory(const EmbeddedFactoryConfig& config)
        : powerConfig_(config.powerConfig) {
        systemInfo_ = getEmbeddedSystemInfo();
    }

    std::unique_ptr<IDataReceiver> createDataReceiver() override {
        return std::make_unique<LowPowerSerialReceiver>(
            powerConfig_.receiverConfig,
            systemInfo_.maxBaudRate
        );
    }

    std::unique_ptr<IDataProcessor> createDataProcessor() override {
        return std::make_unique<ARMOptimizedProcessor>(
            systemInfo_.cpuInfo,
            powerConfig_.processingConfig
        );
    }

    std::unique_ptr<IDisplayController> createDisplayController() override {
        return std::make_unique<FrameBufferDisplayController>(
            powerConfig_.displayConfig,
            systemInfo_.displayCapabilities
        );
    }

    std::unique_ptr<ITaskScheduler> createTaskScheduler() override {
        return std::make_unique<PowerAwareScheduler>(
            powerConfig_.schedulingConfig,
            systemInfo_.thermalConstraints
        );
    }

    std::string getFactoryType() const override {
        return "Embedded Low-Power Factory";
    }
};
```

#### å·¥å‚æ³¨å†Œå’Œç®¡ç†
```cpp
/**
 * @brief å·¥å‚ç®¡ç†å™¨
 *
 * ç®¡ç†å„ç§ç»„ä»¶å·¥å‚çš„æ³¨å†Œã€æŸ¥æ‰¾å’Œå®ä¾‹åŒ–ã€‚
 * æ”¯æŒåŸºäºé…ç½®çš„è‡ªåŠ¨å·¥å‚é€‰æ‹©ã€‚
 */
class ComponentFactoryManager {
private:
    using FactoryCreator = std::function<std::unique_ptr<IRadarComponentFactory>()>;
    std::map<std::string, FactoryCreator> factoryCreators_;
    std::unique_ptr<IRadarComponentFactory> activeFactory_;

public:
    /**
     * @brief æ³¨å†Œå·¥å‚åˆ›å»ºå™¨
     */
    template<typename FactoryType, typename... Args>
    void registerFactory(const std::string& name, Args&&... args) {
        factoryCreators_[name] = [args...]() {
            return std::make_unique<FactoryType>(args...);
        };
    }

    /**
     * @brief åŸºäºç³»ç»Ÿé…ç½®é€‰æ‹©æœ€ä¼˜å·¥å‚
     */
    std::string selectOptimalFactory(const SystemConfiguration& config) {
        // åŸºäºç¡¬ä»¶èƒ½åŠ›è¯„ä¼°
        if (hasHighEndGPU() && config.performanceLevel == PerformanceLevel::High) {
            return "high-performance-gpu";
        }

        // åŸºäºåŠŸè€—é™åˆ¶è¯„ä¼°
        if (config.powerConstraints.maxPowerConsumption < 50.0) {  // 50Wé™åˆ¶
            return "embedded-low-power";
        }

        // åŸºäºå®æ—¶æ€§è¦æ±‚è¯„ä¼°
        if (config.latencyRequirements.maxLatency < std::chrono::microseconds(100)) {
            return "real-time-optimized";
        }

        // é»˜è®¤é€‰æ‹©é€šç”¨å·¥å‚
        return "general-purpose";
    }

    /**
     * @brief åˆ›å»ºå¹¶æ¿€æ´»å·¥å‚
     */
    bool activateFactory(const std::string& factoryName) {
        auto it = factoryCreators_.find(factoryName);
        if (it != factoryCreators_.end()) {
            activeFactory_ = it->second();
            LOG_INFO("Activated factory: " + factoryName);
            return true;
        }
        return false;
    }

    /**
     * @brief åˆ›å»ºå®Œæ•´çš„é›·è¾¾ç³»ç»Ÿç»„ä»¶
     */
    std::unique_ptr<RadarSystem> createRadarSystem(const SystemConfiguration& config) {
        if (!activeFactory_) {
            throw std::runtime_error("No active factory");
        }

        auto system = std::make_unique<RadarSystem>(config);

        // åˆ›å»ºæ ¸å¿ƒç»„ä»¶
        system->setDataReceiver(activeFactory_->createDataReceiver());
        system->setDataProcessor(activeFactory_->createDataProcessor());
        system->setDisplayController(activeFactory_->createDisplayController());
        system->setTaskScheduler(activeFactory_->createTaskScheduler());

        // åˆ›å»ºè¾…åŠ©ç»„ä»¶
        system->setConfigManager(activeFactory_->createConfigManager());
        system->setPerformanceMonitor(activeFactory_->createPerformanceMonitor());
        system->setLogger(activeFactory_->createLogger());

        return system;
    }
};
```

### ğŸ­ è§‚å¯Ÿè€…æ¨¡å¼ (Observer Pattern)

#### äº‹ä»¶é©±åŠ¨æ¶æ„
```cpp
/**
 * @brief é›·è¾¾ç³»ç»Ÿäº‹ä»¶åŸºç±»
 *
 * å®šä¹‰æ‰€æœ‰é›·è¾¾ç³»ç»Ÿäº‹ä»¶çš„å…¬å…±æ¥å£ã€‚æ”¯æŒäº‹ä»¶æ—¶é—´æˆ³ã€
 * ä¼˜å…ˆçº§å’Œä¼ æ’­æ§åˆ¶ã€‚
 */
class RadarSystemEvent {
public:
    enum class Priority { Low, Normal, High, Critical };
    enum class Type {
        DataReceived,
        ProcessingCompleted,
        ErrorOccurred,
        StateChanged,
        PerformanceAlert,
        ConfigurationUpdated
    };

private:
    Type type_;
    Priority priority_;
    std::chrono::system_clock::time_point timestamp_;
    std::string source_;
    bool propagationStopped_;

public:
    explicit RadarSystemEvent(Type type, Priority priority = Priority::Normal)
        : type_(type), priority_(priority),
          timestamp_(std::chrono::system_clock::now()),
          propagationStopped_(false) {}

    virtual ~RadarSystemEvent() = default;

    // è®¿é—®å™¨
    Type getType() const { return type_; }
    Priority getPriority() const { return priority_; }
    auto getTimestamp() const { return timestamp_; }
    const std::string& getSource() const { return source_; }

    // äº‹ä»¶æ§åˆ¶
    void setSource(const std::string& source) { source_ = source; }
    void stopPropagation() { propagationStopped_ = true; }
    bool isPropagationStopped() const { return propagationStopped_; }

    // è™šæ‹Ÿæ–¹æ³•ä¾›å­ç±»å®ç°
    virtual std::string getDescription() const = 0;
    virtual std::map<std::string, std::string> getDetails() const = 0;
};

/**
 * @brief æ•°æ®å¤„ç†å®Œæˆäº‹ä»¶
 */
class ProcessingCompletedEvent : public RadarSystemEvent {
private:
    ProcessingResult result_;
    std::chrono::microseconds processingTime_;
    size_t dataSize_;

public:
    ProcessingCompletedEvent(
        const ProcessingResult& result,
        std::chrono::microseconds processingTime,
        size_t dataSize
    ) : RadarSystemEvent(Type::ProcessingCompleted),
        result_(result), processingTime_(processingTime), dataSize_(dataSize) {}

    const ProcessingResult& getResult() const { return result_; }
    auto getProcessingTime() const { return processingTime_; }
    size_t getDataSize() const { return dataSize_; }

    std::string getDescription() const override {
        return "Data processing completed with " +
               std::to_string(result_.detectedTargets.size()) + " targets detected";
    }

    std::map<std::string, std::string> getDetails() const override {
        return {
            {"processing_time_us", std::to_string(processingTime_.count())},
            {"data_size_bytes", std::to_string(dataSize_)},
            {"targets_detected", std::to_string(result_.detectedTargets.size())},
            {"snr_db", std::to_string(result_.averageSNR)},
            {"processing_status", result_.success ? "success" : "failed"}
        };
    }
};
```

#### è§‚å¯Ÿè€…æ¥å£å’Œå®ç°
```cpp
/**
 * @brief é›·è¾¾ç³»ç»Ÿäº‹ä»¶è§‚å¯Ÿè€…æ¥å£
 */
class IRadarEventObserver {
public:
    virtual ~IRadarEventObserver() = default;

    /**
     * @brief å¤„ç†é›·è¾¾ç³»ç»Ÿäº‹ä»¶
     * @param event æ¥æ”¶åˆ°çš„äº‹ä»¶
     */
    virtual void onRadarEvent(const std::shared_ptr<RadarSystemEvent>& event) = 0;

    /**
     * @brief è·å–è§‚å¯Ÿè€…åç§°
     */
    virtual std::string getObserverName() const = 0;

    /**
     * @brief è·å–æ„Ÿå…´è¶£çš„äº‹ä»¶ç±»å‹
     * @return äº‹ä»¶ç±»å‹åˆ—è¡¨ï¼Œç©ºè¡¨ç¤ºå¯¹æ‰€æœ‰äº‹ä»¶æ„Ÿå…´è¶£
     */
    virtual std::vector<RadarSystemEvent::Type> getInterestedEventTypes() const {
        return {};  // é»˜è®¤å¯¹æ‰€æœ‰äº‹ä»¶æ„Ÿå…´è¶£
    }

    /**
     * @brief è·å–æœ€ä½å…³æ³¨ä¼˜å…ˆçº§
     */
    virtual RadarSystemEvent::Priority getMinimumPriority() const {
        return RadarSystemEvent::Priority::Low;
    }
};

/**
 * @brief æ€§èƒ½ç›‘æ§è§‚å¯Ÿè€…
 *
 * ä¸“é—¨ç›‘æ§ç³»ç»Ÿæ€§èƒ½äº‹ä»¶ï¼Œç»Ÿè®¡å¤„ç†æ—¶é—´ã€ååé‡ç­‰æŒ‡æ ‡ã€‚
 */
class PerformanceMonitorObserver : public IRadarEventObserver {
private:
    struct PerformanceStatistics {
        double averageProcessingTime = 0.0;
        double maxProcessingTime = 0.0;
        double totalThroughput = 0.0;
        size_t totalProcessedPackets = 0;
        std::chrono::system_clock::time_point startTime;
    };

    PerformanceStatistics stats_;
    std::mutex statsMutex_;
    std::shared_ptr<ILogger> logger_;

public:
    explicit PerformanceMonitorObserver(std::shared_ptr<ILogger> logger)
        : logger_(std::move(logger)) {
        stats_.startTime = std::chrono::system_clock::now();
    }

    void onRadarEvent(const std::shared_ptr<RadarSystemEvent>& event) override {
        if (event->getType() == RadarSystemEvent::Type::ProcessingCompleted) {
            auto processingEvent = std::dynamic_pointer_cast<ProcessingCompletedEvent>(event);
            if (processingEvent) {
                updatePerformanceStatistics(*processingEvent);
            }
        }
    }

    std::string getObserverName() const override {
        return "Performance Monitor";
    }

    std::vector<RadarSystemEvent::Type> getInterestedEventTypes() const override {
        return {RadarSystemEvent::Type::ProcessingCompleted};
    }

    PerformanceStatistics getStatistics() const {
        std::lock_guard<std::mutex> lock(statsMutex_);
        return stats_;
    }

private:
    void updatePerformanceStatistics(const ProcessingCompletedEvent& event) {
        std::lock_guard<std::mutex> lock(statsMutex_);

        double processingTimeMs = event.getProcessingTime().count() / 1000.0;

        // æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
        stats_.averageProcessingTime =
            (stats_.averageProcessingTime * stats_.totalProcessedPackets + processingTimeMs) /
            (stats_.totalProcessedPackets + 1);

        // æ›´æ–°æœ€å¤§å¤„ç†æ—¶é—´
        stats_.maxProcessingTime = std::max(stats_.maxProcessingTime, processingTimeMs);

        // æ›´æ–°ååé‡
        stats_.totalThroughput += static_cast<double>(event.getDataSize()) / 1024.0 / 1024.0; // MB

        stats_.totalProcessedPackets++;

        // è®°å½•æ€§èƒ½æ—¥å¿—
        if (stats_.totalProcessedPackets % 1000 == 0) {
            logger_->info("Performance Update: Avg=" + std::to_string(stats_.averageProcessingTime) +
                         "ms, Max=" + std::to_string(stats_.maxProcessingTime) +
                         "ms, Packets=" + std::to_string(stats_.totalProcessedPackets));
        }
    }
};
```

#### äº‹ä»¶å‘å¸ƒå™¨
```cpp
/**
 * @brief é›·è¾¾ç³»ç»Ÿäº‹ä»¶å‘å¸ƒå™¨
 *
 * ç®¡ç†è§‚å¯Ÿè€…çš„æ³¨å†Œ/æ³¨é”€ï¼Œè´Ÿè´£äº‹ä»¶çš„åˆ†å‘å’Œè¿‡æ»¤ã€‚
 * æ”¯æŒå¼‚æ­¥äº‹ä»¶å¤„ç†å’Œä¼˜å…ˆçº§é˜Ÿåˆ—ã€‚
 */
class RadarEventPublisher {
private:
    struct ObserverInfo {
        std::weak_ptr<IRadarEventObserver> observer;
        std::vector<RadarSystemEvent::Type> interestedTypes;
        RadarSystemEvent::Priority minimumPriority;
        std::string name;
    };

    std::vector<ObserverInfo> observers_;
    std::mutex observersMutex_;

    // å¼‚æ­¥äº‹ä»¶å¤„ç†
    std::queue<std::shared_ptr<RadarSystemEvent>> eventQueue_;
    std::mutex queueMutex_;
    std::condition_variable queueCondition_;
    std::thread eventProcessingThread_;
    std::atomic<bool> shouldStop_;

public:
    RadarEventPublisher() : shouldStop_(false) {
        eventProcessingThread_ = std::thread(&RadarEventPublisher::processEvents, this);
    }

    ~RadarEventPublisher() {
        shouldStop_ = true;
        queueCondition_.notify_all();
        if (eventProcessingThread_.joinable()) {
            eventProcessingThread_.join();
        }
    }

    /**
     * @brief æ³¨å†Œäº‹ä»¶è§‚å¯Ÿè€…
     */
    void registerObserver(std::shared_ptr<IRadarEventObserver> observer) {
        std::lock_guard<std::mutex> lock(observersMutex_);

        ObserverInfo info;
        info.observer = observer;
        info.interestedTypes = observer->getInterestedEventTypes();
        info.minimumPriority = observer->getMinimumPriority();
        info.name = observer->getObserverName();

        observers_.push_back(info);

        LOG_INFO("Registered observer: " + info.name);
    }

    /**
     * @brief æ³¨é”€äº‹ä»¶è§‚å¯Ÿè€…
     */
    void unregisterObserver(std::shared_ptr<IRadarEventObserver> observer) {
        std::lock_guard<std::mutex> lock(observersMutex_);

        auto it = std::remove_if(observers_.begin(), observers_.end(),
            [&observer](const ObserverInfo& info) {
                return info.observer.lock() == observer;
            });

        if (it != observers_.end()) {
            LOG_INFO("Unregistered observer: " + it->name);
            observers_.erase(it, observers_.end());
        }
    }

    /**
     * @brief å‘å¸ƒäº‹ä»¶ï¼ˆå¼‚æ­¥ï¼‰
     */
    void publishEvent(std::shared_ptr<RadarSystemEvent> event) {
        {
            std::lock_guard<std::mutex> lock(queueMutex_);
            eventQueue_.push(event);
        }
        queueCondition_.notify_one();
    }

    /**
     * @brief å‘å¸ƒäº‹ä»¶ï¼ˆåŒæ­¥ï¼‰
     */
    void publishEventSync(std::shared_ptr<RadarSystemEvent> event) {
        std::lock_guard<std::mutex> lock(observersMutex_);

        for (auto it = observers_.begin(); it != observers_.end();) {
            auto observer = it->observer.lock();
            if (!observer) {
                // è§‚å¯Ÿè€…å·²è¢«é”€æ¯ï¼Œä»åˆ—è¡¨ä¸­ç§»é™¤
                it = observers_.erase(it);
                continue;
            }

            // æ£€æŸ¥äº‹ä»¶ç±»å‹è¿‡æ»¤
            if (!it->interestedTypes.empty()) {
                bool typeMatches = std::find(it->interestedTypes.begin(),
                                           it->interestedTypes.end(),
                                           event->getType()) != it->interestedTypes.end();
                if (!typeMatches) {
                    ++it;
                    continue;
                }
            }

            // æ£€æŸ¥ä¼˜å…ˆçº§è¿‡æ»¤
            if (event->getPriority() < it->minimumPriority) {
                ++it;
                continue;
            }

            // é€šçŸ¥è§‚å¯Ÿè€…
            try {
                observer->onRadarEvent(event);
            } catch (const std::exception& e) {
                LOG_ERROR("Observer " + it->name + " threw exception: " + e.what());
            }

            // æ£€æŸ¥äº‹ä»¶ä¼ æ’­æ˜¯å¦è¢«åœæ­¢
            if (event->isPropagationStopped()) {
                break;
            }

            ++it;
        }
    }

private:
    /**
     * @brief å¼‚æ­¥äº‹ä»¶å¤„ç†çº¿ç¨‹
     */
    void processEvents() {
        while (!shouldStop_) {
            std::unique_lock<std::mutex> lock(queueMutex_);
            queueCondition_.wait(lock, [this] {
                return !eventQueue_.empty() || shouldStop_;
            });

            while (!eventQueue_.empty() && !shouldStop_) {
                auto event = eventQueue_.front();
                eventQueue_.pop();
                lock.unlock();

                publishEventSync(event);

                lock.lock();
            }
        }
    }
};
```

---

## èµ„æºç®¡ç†æ¨¡å¼

### ğŸ’ RAIIæ¨¡å¼ (Resource Acquisition Is Initialization)

#### GPUèµ„æºç®¡ç†
```cpp
/**
 * @brief CUDAè®¾å¤‡å†…å­˜RAIIåŒ…è£…å™¨
 *
 * è‡ªåŠ¨ç®¡ç†GPUå†…å­˜çš„åˆ†é…å’Œé‡Šæ”¾ï¼Œç¡®ä¿å¼‚å¸¸å®‰å…¨ã€‚
 * æ”¯æŒå†…å­˜å¯¹é½ã€é›¶æ‹·è´ç­‰é«˜çº§ç‰¹æ€§ã€‚
 */
template<typename T>
class CUDADeviceMemory {
private:
    T* devicePtr_;
    size_t sizeInElements_;
    size_t alignment_;
    bool isOwner_;

public:
    /**
     * @brief åˆ†é…è®¾å¤‡å†…å­˜æ„é€ å‡½æ•°
     * @param count å…ƒç´ æ•°é‡
     * @param alignment å†…å­˜å¯¹é½å­—èŠ‚æ•°ï¼ˆé»˜è®¤256å­—èŠ‚ï¼Œé€‚åˆGPUï¼‰
     */
    explicit CUDADeviceMemory(size_t count, size_t alignment = 256)
        : devicePtr_(nullptr), sizeInElements_(count),
          alignment_(alignment), isOwner_(true) {

        size_t sizeInBytes = count * sizeof(T);

        // è®¡ç®—å¯¹é½åçš„å¤§å°
        size_t alignedSize = ((sizeInBytes + alignment - 1) / alignment) * alignment;

        cudaError_t result = cudaMalloc(reinterpret_cast<void**>(&devicePtr_), alignedSize);
        if (result != cudaSuccess) {
            throw std::runtime_error("Failed to allocate CUDA device memory: " +
                                   std::string(cudaGetErrorString(result)));
        }

        // åˆå§‹åŒ–å†…å­˜ä¸ºé›¶ï¼ˆå¯é€‰ï¼‰
        cudaMemset(devicePtr_, 0, alignedSize);
    }

    /**
     * @brief ä»ç°æœ‰æŒ‡é’ˆæ„é€ ï¼ˆéæ‹¥æœ‰ï¼‰
     * @param ptr ç°æœ‰è®¾å¤‡æŒ‡é’ˆ
     * @param count å…ƒç´ æ•°é‡
     */
    CUDADeviceMemory(T* ptr, size_t count)
        : devicePtr_(ptr), sizeInElements_(count),
          alignment_(0), isOwner_(false) {}

    // ç¦ç”¨æ‹·è´æ„é€ å’Œèµ‹å€¼
    CUDADeviceMemory(const CUDADeviceMemory&) = delete;
    CUDADeviceMemory& operator=(const CUDADeviceMemory&) = delete;

    // æ”¯æŒç§»åŠ¨è¯­ä¹‰
    CUDADeviceMemory(CUDADeviceMemory&& other) noexcept
        : devicePtr_(other.devicePtr_), sizeInElements_(other.sizeInElements_),
          alignment_(other.alignment_), isOwner_(other.isOwner_) {
        other.devicePtr_ = nullptr;
        other.isOwner_ = false;
    }

    CUDADeviceMemory& operator=(CUDADeviceMemory&& other) noexcept {
        if (this != &other) {
            reset();
            devicePtr_ = other.devicePtr_;
            sizeInElements_ = other.sizeInElements_;
            alignment_ = other.alignment_;
            isOwner_ = other.isOwner_;
            other.devicePtr_ = nullptr;
            other.isOwner_ = false;
        }
        return *this;
    }

    /**
     * @brief ææ„å‡½æ•°ï¼Œè‡ªåŠ¨é‡Šæ”¾å†…å­˜
     */
    ~CUDADeviceMemory() {
        reset();
    }

    /**
     * @brief è·å–è®¾å¤‡æŒ‡é’ˆ
     */
    T* get() const noexcept { return devicePtr_; }

    /**
     * @brief è·å–å…ƒç´ æ•°é‡
     */
    size_t size() const noexcept { return sizeInElements_; }

    /**
     * @brief è·å–å­—èŠ‚å¤§å°
     */
    size_t sizeInBytes() const noexcept { return sizeInElements_ * sizeof(T); }

    /**
     * @brief æ£€æŸ¥æ˜¯å¦æœ‰æ•ˆ
     */
    bool isValid() const noexcept { return devicePtr_ != nullptr; }

    /**
     * @brief ä»ä¸»æœºæ‹·è´æ•°æ®åˆ°è®¾å¤‡
     */
    void copyFromHost(const T* hostPtr, size_t count = 0, cudaStream_t stream = 0) {
        if (!hostPtr || !devicePtr_) {
            throw std::invalid_argument("Invalid pointer for memory copy");
        }

        size_t copyCount = (count == 0) ? sizeInElements_ : std::min(count, sizeInElements_);
        size_t copySize = copyCount * sizeof(T);

        cudaError_t result;
        if (stream == 0) {
            result = cudaMemcpy(devicePtr_, hostPtr, copySize, cudaMemcpyHostToDevice);
        } else {
            result = cudaMemcpyAsync(devicePtr_, hostPtr, copySize,
                                   cudaMemcpyHostToDevice, stream);
        }

        if (result != cudaSuccess) {
            throw std::runtime_error("Failed to copy from host to device: " +
                                   std::string(cudaGetErrorString(result)));
        }
    }

    /**
     * @brief ä»è®¾å¤‡æ‹·è´æ•°æ®åˆ°ä¸»æœº
     */
    void copyToHost(T* hostPtr, size_t count = 0, cudaStream_t stream = 0) const {
        if (!hostPtr || !devicePtr_) {
            throw std::invalid_argument("Invalid pointer for memory copy");
        }

        size_t copyCount = (count == 0) ? sizeInElements_ : std::min(count, sizeInElements_);
        size_t copySize = copyCount * sizeof(T);

        cudaError_t result;
        if (stream == 0) {
            result = cudaMemcpy(hostPtr, devicePtr_, copySize, cudaMemcpyDeviceToHost);
        } else {
            result = cudaMemcpyAsync(hostPtr, devicePtr_, copySize,
                                   cudaMemcpyDeviceToHost, stream);
        }

        if (result != cudaSuccess) {
            throw std::runtime_error("Failed to copy from device to host: " +
                                   std::string(cudaGetErrorString(result)));
        }
    }

    /**
     * @brief æ‰‹åŠ¨é‡Šæ”¾èµ„æº
     */
    void reset() {
        if (devicePtr_ && isOwner_) {
            cudaFree(devicePtr_);
        }
        devicePtr_ = nullptr;
        isOwner_ = false;
    }
};

/**
 * @brief CUDAæµRAIIåŒ…è£…å™¨
 */
class CUDAStream {
private:
    cudaStream_t stream_;
    bool isOwner_;

public:
    /**
     * @brief åˆ›å»ºæ–°çš„CUDAæµ
     */
    explicit CUDAStream(unsigned int flags = cudaStreamDefault)
        : stream_(nullptr), isOwner_(true) {
        cudaError_t result = cudaStreamCreateWithFlags(&stream_, flags);
        if (result != cudaSuccess) {
            throw std::runtime_error("Failed to create CUDA stream: " +
                                   std::string(cudaGetErrorString(result)));
        }
    }

    /**
     * @brief ä»ç°æœ‰æµæ„é€ ï¼ˆéæ‹¥æœ‰ï¼‰
     */
    explicit CUDAStream(cudaStream_t stream)
        : stream_(stream), isOwner_(false) {}

    // ç¦ç”¨æ‹·è´
    CUDAStream(const CUDAStream&) = delete;
    CUDAStream& operator=(const CUDAStream&) = delete;

    // æ”¯æŒç§»åŠ¨
    CUDAStream(CUDAStream&& other) noexcept
        : stream_(other.stream_), isOwner_(other.isOwner_) {
        other.stream_ = nullptr;
        other.isOwner_ = false;
    }

    /**
     * @brief ææ„å‡½æ•°ï¼Œè‡ªåŠ¨é”€æ¯æµ
     */
    ~CUDAStream() {
        if (stream_ && isOwner_) {
            cudaStreamDestroy(stream_);
        }
    }

    /**
     * @brief è·å–åŸç”Ÿæµå¥æŸ„
     */
    cudaStream_t get() const noexcept { return stream_; }

    /**
     * @brief ç­‰å¾…æµä¸­æ‰€æœ‰æ“ä½œå®Œæˆ
     */
    void synchronize() const {
        cudaError_t result = cudaStreamSynchronize(stream_);
        if (result != cudaSuccess) {
            throw std::runtime_error("Failed to synchronize CUDA stream: " +
                                   std::string(cudaGetErrorString(result)));
        }
    }

    /**
     * @brief æ£€æŸ¥æµæ˜¯å¦ç©ºé—²
     */
    bool isIdle() const {
        cudaError_t result = cudaStreamQuery(stream_);
        return (result == cudaSuccess);
    }
};
```

#### èµ„æºæ± æ¨¡å¼
```cpp
/**
 * @brief é€šç”¨èµ„æºæ± æ¨¡æ¿
 *
 * ç®¡ç†æ˜‚è´µèµ„æºçš„åˆ›å»ºã€é‡ç”¨å’Œé”€æ¯ã€‚æ”¯æŒè‡ªåŠ¨æ‰©å®¹ã€
 * èµ„æºå¥åº·æ£€æŸ¥å’Œç»Ÿè®¡ä¿¡æ¯æ”¶é›†ã€‚
 */
template<typename ResourceType, typename ResourceKey = std::string>
class ResourcePool {
public:
    using ResourcePtr = std::shared_ptr<ResourceType>;
    using ResourceFactory = std::function<ResourcePtr(const ResourceKey&)>;
    using ResourceValidator = std::function<bool(const ResourcePtr&)>;

private:
    struct PooledResource {
        ResourcePtr resource;
        std::chrono::steady_clock::time_point lastUsed;
        std::chrono::steady_clock::time_point created;
        size_t useCount;
        bool inUse;

        PooledResource(ResourcePtr res)
            : resource(std::move(res)),
              lastUsed(std::chrono::steady_clock::now()),
              created(std::chrono::steady_clock::now()),
              useCount(0), inUse(false) {}
    };

    mutable std::mutex poolMutex_;
    std::map<ResourceKey, std::vector<std::unique_ptr<PooledResource>>> pool_;
    ResourceFactory factory_;
    ResourceValidator validator_;

    // é…ç½®å‚æ•°
    size_t maxPoolSize_;
    size_t maxIdleCount_;
    std::chrono::minutes maxIdleTime_;
    std::chrono::minutes maxResourceAge_;

    // ç»Ÿè®¡ä¿¡æ¯
    mutable std::atomic<size_t> totalRequests_{0};
    mutable std::atomic<size_t> cacheHits_{0};
    mutable std::atomic<size_t> cacheMisses_{0};

    // æ¸…ç†çº¿ç¨‹
    std::thread cleanupThread_;
    std::atomic<bool> shouldStop_{false};

public:
    /**
     * @brief æ„é€ èµ„æºæ± 
     */
    ResourcePool(
        ResourceFactory factory,
        ResourceValidator validator = nullptr,
        size_t maxPoolSize = 100,
        size_t maxIdleCount = 10,
        std::chrono::minutes maxIdleTime = std::chrono::minutes(30),
        std::chrono::minutes maxResourceAge = std::chrono::hours(24)
    ) : factory_(std::move(factory)), validator_(std::move(validator)),
        maxPoolSize_(maxPoolSize), maxIdleCount_(maxIdleCount),
        maxIdleTime_(maxIdleTime), maxResourceAge_(maxResourceAge) {

        // å¯åŠ¨æ¸…ç†çº¿ç¨‹
        cleanupThread_ = std::thread(&ResourcePool::cleanupLoop, this);
    }

    /**
     * @brief ææ„å‡½æ•°
     */
    ~ResourcePool() {
        shouldStop_ = true;
        if (cleanupThread_.joinable()) {
            cleanupThread_.join();
        }
    }

    /**
     * @brief è·å–èµ„æº
     */
    ResourcePtr acquire(const ResourceKey& key) {
        totalRequests_++;

        std::lock_guard<std::mutex> lock(poolMutex_);

        auto& resources = pool_[key];

        // æŸ¥æ‰¾å¯ç”¨èµ„æº
        for (auto& pooledRes : resources) {
            if (!pooledRes->inUse) {
                // éªŒè¯èµ„æºæ˜¯å¦ä»ç„¶æœ‰æ•ˆ
                if (validator_ && !validator_(pooledRes->resource)) {
                    continue;
                }

                // æ£€æŸ¥èµ„æºå¹´é¾„
                auto now = std::chrono::steady_clock::now();
                if (now - pooledRes->created > maxResourceAge_) {
                    continue;
                }

                // æ ‡è®°ä¸ºä½¿ç”¨ä¸­
                pooledRes->inUse = true;
                pooledRes->lastUsed = now;
                pooledRes->useCount++;

                cacheHits_++;
                return pooledRes->resource;
            }
        }

        // æ²¡æœ‰å¯ç”¨èµ„æºï¼Œåˆ›å»ºæ–°èµ„æº
        if (resources.size() < maxPoolSize_) {
            auto newResource = factory_(key);
            if (newResource) {
                auto pooledRes = std::make_unique<PooledResource>(newResource);
                pooledRes->inUse = true;
                pooledRes->useCount = 1;

                auto result = pooledRes->resource;
                resources.push_back(std::move(pooledRes));

                cacheMisses_++;
                return result;
            }
        }

        cacheMisses_++;
        throw std::runtime_error("Failed to acquire resource from pool");
    }

    /**
     * @brief é‡Šæ”¾èµ„æº
     */
    void release(const ResourceKey& key, const ResourcePtr& resource) {
        std::lock_guard<std::mutex> lock(poolMutex_);

        auto it = pool_.find(key);
        if (it != pool_.end()) {
            for (auto& pooledRes : it->second) {
                if (pooledRes->resource == resource && pooledRes->inUse) {
                    pooledRes->inUse = false;
                    pooledRes->lastUsed = std::chrono::steady_clock::now();
                    return;
                }
            }
        }
    }

    /**
     * @brief è·å–æ± ç»Ÿè®¡ä¿¡æ¯
     */
    struct PoolStatistics {
        size_t totalRequests;
        size_t cacheHits;
        size_t cacheMisses;
        double hitRate;
        size_t totalResources;
        size_t activeResources;
        size_t idleResources;
    };

    PoolStatistics getStatistics() const {
        std::lock_guard<std::mutex> lock(poolMutex_);

        PoolStatistics stats;
        stats.totalRequests = totalRequests_;
        stats.cacheHits = cacheHits_;
        stats.cacheMisses = cacheMisses_;
        stats.hitRate = (stats.totalRequests > 0) ?
                       static_cast<double>(stats.cacheHits) / stats.totalRequests : 0.0;

        stats.totalResources = 0;
        stats.activeResources = 0;
        stats.idleResources = 0;

        for (const auto& [key, resources] : pool_) {
            stats.totalResources += resources.size();
            for (const auto& pooledRes : resources) {
                if (pooledRes->inUse) {
                    stats.activeResources++;
                } else {
                    stats.idleResources++;
                }
            }
        }

        return stats;
    }

private:
    /**
     * @brief æ¸…ç†å¾ªç¯ï¼Œå®šæœŸæ¸…ç†è¿‡æœŸèµ„æº
     */
    void cleanupLoop() {
        while (!shouldStop_) {
            std::this_thread::sleep_for(std::chrono::minutes(5));

            if (shouldStop_) break;

            cleanupExpiredResources();
        }
    }

    /**
     * @brief æ¸…ç†è¿‡æœŸèµ„æº
     */
    void cleanupExpiredResources() {
        std::lock_guard<std::mutex> lock(poolMutex_);

        auto now = std::chrono::steady_clock::now();

        for (auto& [key, resources] : pool_) {
            // è®¡ç®—ç©ºé—²èµ„æºæ•°é‡
            size_t idleCount = 0;
            for (const auto& pooledRes : resources) {
                if (!pooledRes->inUse) {
                    idleCount++;
                }
            }

            // ç§»é™¤è¿‡æœŸæˆ–å¤šä½™çš„ç©ºé—²èµ„æº
            resources.erase(
                std::remove_if(resources.begin(), resources.end(),
                    [&](const std::unique_ptr<PooledResource>& pooledRes) {
                        if (pooledRes->inUse) {
                            return false;  // æ­£åœ¨ä½¿ç”¨çš„èµ„æºä¸æ¸…ç†
                        }

                        // æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                        bool tooOld = (now - pooledRes->created) > maxResourceAge_;
                        bool idleTooLong = (now - pooledRes->lastUsed) > maxIdleTime_;
                        bool tooManyIdle = idleCount > maxIdleCount_;

                        if (tooManyIdle && idleCount > 0) {
                            idleCount--;
                            return true;
                        }

                        return tooOld || idleTooLong;
                    }),
                resources.end()
            );
        }
    }
};
```

---

## å˜æ›´è®°å½•

| ç‰ˆæœ¬ | æ—¥æœŸ       | ä¿®æ”¹äºº | å˜æ›´æ‘˜è¦                       |
| :--- | :--------- | :----- | :----------------------------- |
| v1.0 | 2025-09-10 | Kelin  | åˆ›å»ºAIåä½œå¼€å‘è®¾è®¡æ¨¡å¼å®è·µæŒ‡å— |
