# 日志监控模块设计

**文档版本**: v2.0.0
**最后更新**: 2025-09-25
**负责人**: GitHub Copilot
**适用阶段**: MVP及向 V2.0 性能优化过渡阶段
**重构说明**: 基于《07_日志监控问题汇总.md》全面重构，拆分职责、统一架构、采用依赖注入

---

## 1 文档职责

本文件设计分离的日志服务与监控模块，遵循项目统一的架构原则：
1) 基于依赖注入的`LoggingService`：提供高性能异步日志记录
2) 基于`IModule`的`MonitoringModule`：独立的系统监控与告警
3) 与`ConfigManager`集成的配置管理
4) 基于事件总线的解耦告警机制
5) 完整的`Trace ID`传递与端到端追踪支持

**重构要点**：
- **职责分离**：将日志记录与监控拆分为独立的服务和模块
- **架构统一**：采用项目标准的`ExecutionEngine`模式和`IModule`接口
- **依赖注入**：彻底移除全局单例，改为构造函数注入
- **事件驱动**：告警通过事件总线发布，实现完全解耦

### 1.1 目录

- [日志监控模块设计](#日志监控模块设计)
  - [1 文档职责](#1-文档职责)
    - [1.1 目录](#11-目录)
  - [2 架构总览与职责分离](#2-架构总览与职责分离)
    - [2.1 双服务架构设计](#21-双服务架构设计)
    - [2.2 职责边界定义](#22-职责边界定义)
    - [2.3 集成与协作模式](#23-集成与协作模式)
  - [3 LoggingService设计](#3-loggingservice设计)
    - [3.1 服务架构与接口](#31-服务架构与接口)
    - [3.2 高性能日志宏](#32-高性能日志宏)
    - [3.3 异步日志机制](#33-异步日志机制)
    - [3.4 TraceContext与追踪](#34-tracecontext与追踪)
  - [4 MonitoringModule设计](#4-monitoringmodule设计)
    - [4.1 模块架构与组件](#41-模块架构与组件)
    - [4.2 ExecutionEngine驱动](#42-executionengine驱动)
    - [4.3 性能指标收集](#43-性能指标收集)
    - [4.4 系统状态监控](#44-系统状态监控)
  - [5 事件驱动告警机制](#5-事件驱动告警机制)
    - [5.1 告警事件定义](#51-告警事件定义)
    - [5.2 告警策略引擎](#52-告警策略引擎)
    - [5.3 事件总线集成](#53-事件总线集成)
  - [6 配置管理集成](#6-配置管理集成)
    - [6.1 ConfigManager集成](#61-configmanager集成)
    - [6.2 配置热更新支持](#62-配置热更新支持)
  - [7 依赖注入与生命周期](#7-依赖注入与生命周期)
    - [7.1 依赖关系设计](#71-依赖关系设计)
    - [7.2 初始化与启动序列](#72-初始化与启动序列)
  - [8 性能优化策略](#8-性能优化策略)
  - [9 实现约束与限制](#9-实现约束与限制)
    - [9.1 技术约束](#91-技术约束)
    - [9.2 架构约束](#92-架构约束)
    - [9.3 性能约束](#93-性能约束)
    - [9.4 MVP功能范围](#94-mvp功能范围)
  - [10 相关文档](#10-相关文档)
  - [11 变更历史](#11-变更历史)

---

## 2 架构总览与职责分离

### 2.1 双服务架构设计

基于职责分离原则，将原"日志监控模块"拆分为两个独立的组件：

```mermaid
graph LR
    subgraph "系统基础设施 (System Infrastructure)"
        direction LR
        CONFIG_MGR[ConfigManager<br/>配置管理器]
        EVENT_BUS[EventBus<br/>事件总线]
        TASK_SCHEDULER[TaskScheduler<br/>任务调度器]
    end

    subgraph "核心服务 (Core Services)"
        direction TB

        subgraph "日志服务 (Logging Service)"
            LOG_IF[ILogger 接口]
            LOG_IMPL[LoggingService 实现]
            LOG_IMPL --> LOG_IF
        end

        subgraph "监控模块 (Monitoring Module)"
            MON_MODULE[MonitoringModule<br/>(实现 IModule)]
        end
    end

    subgraph "外部消费者 (Consumers)"
        BusinessModules[业务模块<br/>DataReceiver, etc.]
    end

    %% 依赖关系
    BusinessModules -- "依赖注入" --> LOG_IF
    TASK_SCHEDULER -- "管理生命周期" --> MON_MODULE
    MON_MODULE -- "依赖注入" --> LOG_IF
    MON_MODULE -- "读取配置" --> CONFIG_MGR
    MON_MODULE -- "发布事件" --> EVENT_BUS
    LOG_IMPL -- "读取配置" --> CONFIG_MGR

    %% 样式定义
    classDef service fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px;
    classDef module fill:#e3f2fd,stroke:#1565c0,stroke-width:2px;
    classDef infra fill:#fff3e0,stroke:#ef6c00,stroke-width:2px;

    class LOG_IF,LOG_IMPL service;
    class MON_MODULE,BusinessModules module;
    class CONFIG_MGR,EVENT_BUS,TASK_SCHEDULER infra;
```

### 2.2 职责边界定义

**LoggingService职责**：
- **日志记录服务**：提供高性能的结构化日志记录能力
- **Trace ID管理**：维护线程局部的追踪上下文
- **日志格式化**：标准化的日志格式与元数据管理
- **异步写入**：基于spdlog的高性能异步日志写入

**职责边界**：LoggingService是一个**被动服务**，只响应其他模块的日志记录请求，不具备主动行为。

**MonitoringModule职责**：
- **系统监控**：主动收集系统资源使用情况
- **性能指标聚合**：汇聚各模块报告的性能数据
- **告警评估**：基于策略检测系统异常状态
- **事件发布**：向事件总线发布告警事件

**职责边界**：MonitoringModule是一个**主动模块**，拥有自己的执行引擎和生命周期，独立运行监控流程。

### 2.3 集成与协作模式

**依赖注入模式**：
- 所有需要日志功能的模块通过构造函数注入`std::shared_ptr<ILogger>`
- `MonitoringModule`通过构造函数注入`ConfigManager`、`EventBus`和`ILogger`
- 彻底消除全局单例，所有依赖关系显式化

**生命周期协调**：
- `LoggingService`由`main`函数在最早期创建，最晚期销毁
- `MonitoringModule`通过`TaskScheduler`统一管理生命周期，实现`IModule`接口
- 两者生命周期完全解耦，`MonitoringModule`依赖`LoggingService`但不控制其生命周期

**配置管理协调**：
- 两个组件都从`ConfigManager`获取配置，支持热更新
- `LoggingService`订阅`logging.*`配置变更事件
- `MonitoringModule`订阅`monitoring.*`配置变更事件

---

## 3 LoggingService设计

### 3.1 服务架构与接口

基于依赖注入的日志服务架构，提供高性能异步日志记录：

```mermaid
graph LR
    subgraph "应用层 (Application Layer)"
        LOG_MACROS[RADAR_... 日志宏]
        ILOGGER[ILogger 接口]
        LOG_MACROS --> ILOGGER
    end

    subgraph "服务层 (Service Layer)"
        LOGGING_SVC[LoggingService 实现]
        TRACE_MGR[TraceContext 管理]
        CONFIG_HANDLER[配置处理器]
        ILOGGER <|-- LOGGING_SVC
        LOGGING_SVC --> TRACE_MGR
        LOGGING_SVC --> CONFIG_HANDLER
    end

    subgraph "后端/依赖 (Backend/Dependencies)"
        ASYNC_LOGGER[spdlog<br/>异步日志核心]
        SINKS[Sinks<br/>(Console, File)]
        LOGGING_SVC --> ASYNC_LOGGER
        ASYNC_LOGGER --> SINKS
    end

    %% 样式定义
    classDef interface fill:#e3f2fd,stroke:#1565c0,stroke-width:2px;
    classDef service fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px;
    classDef spdlog fill:#fff3e0,stroke:#ef6c00,stroke-width:2px;

    class ILOGGER,LOG_MACROS interface;
    class LOGGING_SVC,TRACE_MGR,CONFIG_HANDLER service;
    class ASYNC_LOGGER,SINKS spdlog;
```

**核心接口定义**：
```cpp
namespace radar::logging {

/**
 * @brief 日志记录接口
 * @details 所有模块通过此接口进行日志记录，支持依赖注入
 */
class ILogger {
public:
    virtual ~ILogger() = default;

    /**
     * @brief 检查指定级别是否启用
     * @param level 日志级别
     * @return true如果该级别启用
     */
    virtual bool shouldLog(LogLevel level) const = 0;

    /**
     * @brief 记录日志消息
     * @tparam Args 可变参数类型
     * @param level 日志级别
     * @param format 格式字符串
     * @param args 格式参数
     */
    template<typename... Args>
    void log(LogLevel level, const std::string& format, Args&&... args);

    /**
     * @brief 立即刷新日志缓冲区
     */
    virtual void flush() = 0;

    /**
     * @brief 动态设置日志级别
     * @param level 新的日志级别
     */
    virtual void setLevel(LogLevel level) = 0;
};

/**
 * @brief LoggingService具体实现
 * @details 基于spdlog的高性能异步日志服务
 */
class LoggingService : public ILogger {
public:
    /**
     * @brief 构造函数
     * @param config_manager 配置管理器，用于获取日志配置
     */
    explicit LoggingService(std::shared_ptr<IConfigManager> config_manager);

    /**
     * @brief 初始化日志服务
     * @return ErrorCode 初始化结果
     */
    ErrorCode initialize();

    /**
     * @brief 清理资源
     */
    void cleanup();

    // ILogger接口实现
    bool shouldLog(LogLevel level) const override;
    void flush() override;
    void setLevel(LogLevel level) override;

private:
    std::shared_ptr<IConfigManager> config_manager_;
    std::shared_ptr<spdlog::async_logger> logger_;
    std::atomic<spdlog::level::level_enum> current_level_;

    void onConfigChanged(const std::string& key, const YAML::Node& value);
};

} // namespace radar::logging
```

### 3.2 高性能日志宏

采用零开销的高性能日志宏设计，避免不必要的函数调用和参数求值：

**高性能宏定义**：
```cpp
namespace radar::logging {

/**
 * @brief 日志级别枚举
 */
enum class LogLevel {
    TRACE = 0,  ///< 详细跟踪信息
    DEBUG = 1,  ///< 调试信息
    INFO  = 2,  ///< 一般信息
    WARN  = 3,  ///< 警告信息
    ERROR = 4   ///< 错误信息
};

/**
 * @brief 高性能日志宏 - 级别检查优先
 * @details 在参数求值前先检查日志级别，实现真正的零开销
 */
#define RADAR_TRACE(logger, ...) \
    do { \
        if ((logger) && (logger)->shouldLog(radar::logging::LogLevel::TRACE)) { \
            (logger)->log(radar::logging::LogLevel::TRACE, __VA_ARGS__); \
        } \
    } while(0)

#define RADAR_DEBUG(logger, ...) \
    do { \
        if ((logger) && (logger)->shouldLog(radar::logging::LogLevel::DEBUG)) { \
            (logger)->log(radar::logging::LogLevel::DEBUG, __VA_ARGS__); \
        } \
    } while(0)

#define RADAR_INFO(logger, ...) \
    do { \
        if ((logger) && (logger)->shouldLog(radar::logging::LogLevel::INFO)) { \
            (logger)->log(radar::logging::LogLevel::INFO, __VA_ARGS__); \
        } \
    } while(0)

#define RADAR_WARN(logger, ...) \
    do { \
        if ((logger) && (logger)->shouldLog(radar::logging::LogLevel::WARN)) { \
            (logger)->log(radar::logging::LogLevel::WARN, __VA_ARGS__); \
        } \
    } while(0)

#define RADAR_ERROR(logger, ...) \
    do { \
        if ((logger) && (logger)->shouldLog(radar::logging::LogLevel::ERROR)) { \
            (logger)->log(radar::logging::LogLevel::ERROR, __VA_ARGS__); \
        } \
    } while(0)

} // namespace radar::logging
```

**使用示例**：
```cpp
// 在模块构造函数中注入logger
class DataProcessor : public IModule {
public:
    DataProcessor(std::shared_ptr<ILogger> logger) : logger_(logger) {}

    void processData(const DataObject& data) {
        // 高性能日志记录 - 当DEBUG级别禁用时完全零开销
        RADAR_DEBUG(logger_, "Processing data with trace_id: {}", data.trace_id);

        // 耗时操作的日志记录 - 只有在级别启用时才会执行toString()
        RADAR_TRACE(logger_, "Data details: {}", data.toString());

        // 结构化日志记录
        RADAR_INFO(logger_, "Processing completed - {duration_ms={}, size={}}",
                   duration, data.size());
    }

private:
    std::shared_ptr<ILogger> logger_;
};
```

**日志格式规范**：
```
[2025-09-25T10:30:05.123456Z] [INFO] [DataProc] [a1b2c3d4] [14073] Processing completed - {duration_ms=12.5, size=4096}
[2025-09-25T10:30:05.125000Z] [WARN] [Monitor] [N/A] [14071] CPU usage high: 89%
[2025-09-25T10:30:05.126000Z] [ERROR] [DataProc] [a1b2c3d4] [14074] Processing failed: timeout
```

**格式组成**：`[时间戳] [级别] [模块] [TraceID] [线程] 消息 - {结构化数据}`

- **时间戳**: 高精度UTC时间，格式`YYYY-MM-DDTHH:MM:SS.ffffffZ`
- **级别**: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`
- **模块**: 记录日志的模块名称（如`DataProc`, `Monitor`）
- **TraceID**: 全链路追踪ID，无追踪时显示`N/A`
- **线程**: 线程ID，用于多线程调试
- **消息**: 日志主要内容
- **结构化数据**: 可选的`key=value`格式元数据

### 3.3 异步日志机制

基于spdlog的高性能异步日志实现，支持配置热更新：

```mermaid
sequenceDiagram
    actor App as 业务模块
    participant Logger as ILogger
    participant SpdlogQueue as spdlog 异步队列
    participant Worker as spdlog 后台线程
    participant Sink as 输出目标 (文件/控制台)

    App->>Logger: RADAR_INFO("Message: {}", 42)
    activate Logger
    Logger->>Logger: 1. shouldLog() 级别检查
    alt 日志级别启用
        Logger->>SpdlogQueue: 2. 构造日志消息并入队 (无锁)
        activate SpdlogQueue
        SpdlogQueue-->>Logger:
        deactivate SpdlogQueue
        Logger-->>App: 3. 立即返回 (业务线程无阻塞)
        deactivate Logger

        participant SpdlogQueue
        SpdlogQueue->>Worker: 4. 通知后台线程
        activate Worker
        Worker->>Worker: 5. 从队列取出消息<br/>格式化并注入TraceID
        Worker->>Sink: 6. 批量写入到目标
        activate Sink
        Sink-->>Worker:
        deactivate Sink
        deactivate Worker
    else 日志级别禁用
        Logger-->>App: 3. 直接返回 (零开销)
        deactivate Logger
    end
```

**LoggingService完整实现**：
```cpp
namespace radar::logging {

/**
 * @brief LoggingService实现类
 * @details 基于依赖注入的高性能异步日志服务
 */
class LoggingService : public ILogger {
public:
    /**
     * @brief 构造函数
     * @param config_manager 配置管理器，用于获取配置和监听热更新
     */
    explicit LoggingService(std::shared_ptr<IConfigManager> config_manager);

    /**
     * @brief 初始化日志服务
     * @return ErrorCode 初始化结果
     */
    ErrorCode initialize();

    /**
     * @brief 清理资源
     */
    void cleanup();

    // ILogger接口实现
    bool shouldLog(LogLevel level) const override {
        return level >= static_cast<LogLevel>(current_level_.load());
    }

    template<typename... Args>
    void log(LogLevel level, const std::string& format, Args&&... args) {
        if (!shouldLog(level)) return;

        // 获取当前线程的Trace ID
        auto trace_id = TraceContext::getCurrentTraceId();

        // 构造格式化的消息（包含Trace ID）
        auto formatted_msg = fmt::format("[{}] {}", trace_id,
                                         fmt::format(format, std::forward<Args>(args)...));

        // 异步记录到spdlog
        logger_->log(toSpdlogLevel(level), formatted_msg);
    }

    void flush() override {
        if (logger_) {
            logger_->flush();
        }
    }

    void setLevel(LogLevel level) override {
        current_level_.store(static_cast<int>(level));
        if (logger_) {
            logger_->set_level(toSpdlogLevel(level));
        }
    }

private:
    std::shared_ptr<IConfigManager> config_manager_;
    std::shared_ptr<spdlog::async_logger> logger_;
    std::atomic<int> current_level_{static_cast<int>(LogLevel::INFO)};

    // 配置热更新处理
    void onConfigChanged(const std::string& key, const YAML::Node& value);

    // 创建spdlog sinks
    std::vector<spdlog::sink_ptr> createSinks(const YAML::Node& config);

    // 级别转换
    spdlog::level::level_enum toSpdlogLevel(LogLevel level) const;
};

} // namespace radar::logging
```

**性能特性**：
- **零开销级别检查**: 禁用级别的日志调用编译器优化为空操作
- **无锁队列**: spdlog内部使用无锁队列，避免线程竞争
- **批量I/O**: 后台线程批量刷新，减少系统调用开销
- **内存池**: 预分配消息缓冲区，避免频繁内存分配
- **格式化延迟**: 消息格式化在后台线程执行，不阻塞业务线程

### 3.4 TraceContext与追踪

基于线程局部存储(TLS)的全链路追踪机制，支持端到端的请求追踪：

**TraceContext设计**：
```cpp
namespace radar::common {

/**
 * @brief 追踪ID类型定义
 */
using TraceId = std::string;

/**
 * @brief 全链路追踪上下文管理
 * @details 基于thread_local存储，提供线程安全的Trace ID管理
 */
class TraceContext {
public:
    /**
     * @brief 设置当前线程的Trace ID
     * @param trace_id 追踪ID
     */
    static void setCurrentTraceId(const TraceId& trace_id);

    /**
     * @brief 获取当前线程的Trace ID
     * @return 当前追踪ID，无追踪时返回"N/A"
     */
    static TraceId getCurrentTraceId();

    /**
     * @brief 生成新的Trace ID
     * @return 唯一的追踪ID字符串（格式：时间戳+随机数）
     */
    static TraceId generateTraceId();

    /**
     * @brief 清除当前线程的Trace ID
     */
    static void clearCurrentTraceId();

private:
    static thread_local TraceId current_trace_id_;
};

/**
 * @brief RAII风格的追踪上下文管理器
 * @details 自动管理Trace ID的设置和恢复，防止上下文污染
 */
class TraceContextGuard {
public:
    explicit TraceContextGuard(const TraceId& trace_id)
        : previous_trace_id_(TraceContext::getCurrentTraceId()) {
        TraceContext::setCurrentTraceId(trace_id);
    }

    ~TraceContextGuard() {
        TraceContext::setCurrentTraceId(previous_trace_id_);
    }

    // 禁止复制和移动
    TraceContextGuard(const TraceContextGuard&) = delete;
    TraceContextGuard& operator=(const TraceContextGuard&) = delete;

private:
    TraceId previous_trace_id_;
};

} // namespace radar::common
```

**使用模式**：

1. **数据流追踪**：
```cpp
// 数据接收模块 - 追踪起点
void DataReceiver::onPacketReceived(const RawPacket& packet) {
    // 为新数据生成Trace ID
    auto trace_id = TraceContext::generateTraceId();
    TraceContextGuard guard(trace_id);

    RADAR_INFO(logger_, "Packet received: size={}", packet.size);

    // 创建DataObject，将trace_id作为元数据
    auto data_obj = createDataObject(packet, trace_id);
    sendToNextModule(data_obj);
}

// 信号处理模块 - 追踪传递
void SignalProcessor::processData(const DataObject& data) {
    // 从DataObject恢复Trace ID上下文
    TraceContextGuard guard(data.trace_id);

    RADAR_DEBUG(logger_, "Starting FFT processing");
    // ... 处理逻辑
    RADAR_INFO(logger_, "FFT completed: points={}", fft_points);

    // 传递trace_id到下一个模块
    auto result = createProcessedData(processed_data, data.trace_id);
    sendToNextModule(result);
}
```

2. **事件流追踪**：
```cpp
// 事件处理 - 追踪起点
void TaskScheduler::handleConfigChangeRequest(const ConfigChangeEvent& event) {
    // 为配置变更流程生成追踪
    auto trace_id = TraceContext::generateTraceId();
    TraceContextGuard guard(trace_id);

    RADAR_INFO(logger_, "Config change requested: key={}", event.key);

    // 后续所有相关日志都会自动带上这个trace_id
    validateConfigChange(event);
    applyConfigChange(event);
}
```

3. **跨线程追踪**：
```cpp
// 主线程
void dispatchTask(const Task& task) {
    auto trace_id = TraceContext::getCurrentTraceId();

    // 提交到线程池时传递trace_id
    thread_pool_.submit([trace_id, task, this]() {
        TraceContextGuard guard(trace_id); // 在工作线程中恢复上下文
        executeTask(task);
    });
}
```

**追踪机制优势**：
- **线程安全**: `thread_local`确保多线程环境下的追踪隔离
- **零侵入**: 日志记录代码无需显式传递`trace_id`参数
- **RAII管理**: 自动处理上下文设置和恢复，防止污染
- **跨模块**: 支持数据在不同模块间流转时的完整追踪链

---

## 4 MonitoringModule设计

### 4.1 模块架构与组件

基于`IModule`接口的标准监控模块，采用`ExecutionEngine`驱动模式：

```mermaid
graph LR
    subgraph "驱动与配置 (Driver & Config)"
        direction TB
        EXEC_ENGINE[ExecutionEngine<br/>事件循环驱动器]
        TIMER[定时器<br/>收集触发器]
        CONFIG_HANDLER[ConfigHandler<br/>配置热更新]
    end

    subgraph "数据流 (Data Flow)"
        direction TB
        COLLECT_STRATEGY[ICollectionStrategy<br/>收集策略接口]
        SYSTEM_COLLECTOR[SystemResourceCollector]
        METRICS_STORE[MetricsStore<br/>指标存储与聚合]

        SYSTEM_COLLECTOR -.-> |"实现"| COLLECT_STRATEGY
        SYSTEM_COLLECTOR -- "写入" --> METRICS_STORE
    end

    subgraph "告警流 (Alerting Flow)"
        direction TB
        ALERT_STRATEGY[IAlertingStrategy<br/>告警策略接口]
        THRESHOLD_CHECKER[ThresholdChecker]
        ALERT_PUBLISHER[AlertEventPublisher<br/>告警事件发布器]

        THRESHOLD_CHECKER -.-> |"实现"| ALERT_STRATEGY
        METRICS_STORE -- "提供数据" --> THRESHOLD_CHECKER
        THRESHOLD_CHECKER -- "触发" --> ALERT_PUBLISHER
    end

    %% 依赖关系
    EXEC_ENGINE -- "驱动" --> TIMER
    TIMER -- "触发" --> SYSTEM_COLLECTOR
    CONFIG_HANDLER -- "更新" --> COLLECT_STRATEGY
    CONFIG_HANDLER -- "更新" --> ALERT_STRATEGY

    %% 样式定义
    classDef execution fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px;
    classDef strategy fill:#e3f2fd,stroke:#1565c0,stroke-width:2px;
    classDef resource fill:#fff3e0,stroke:#ef6c00,stroke-width:2px;

    class EXEC_ENGINE,TIMER,CONFIG_HANDLER execution;
    class COLLECT_STRATEGY,ALERT_STRATEGY,SYSTEM_COLLECTOR,THRESHOLD_CHECKER strategy;
    class METRICS_STORE,ALERT_PUBLISHER resource;
```

**核心接口定义**：
```cpp
namespace radar::monitoring {

/**
 * @brief 监控模块主类
 * @details 实现IModule接口，提供系统监控和告警功能
 */
class MonitoringModule : public IModule {
public:
    /**
     * @brief 构造函数 - 依赖注入
     * @param config_manager 配置管理器
     * @param event_bus 事件总线
     * @param logger 日志服务
     */
    MonitoringModule(
        std::shared_ptr<IConfigManager> config_manager,
        std::shared_ptr<IEventBus> event_bus,
        std::shared_ptr<ILogger> logger);

    // IModule接口实现
    ErrorCode initialize() override;
    ErrorCode start() override;
    ErrorCode stop() override;
    ErrorCode pause() override;
    ErrorCode resume() override;
    ErrorCode cleanup() override;

    ModuleState getState() const override;
    const std::string& getModuleName() const override;

    void setStateChangeCallback(StateChangeCallback callback) override;
    void setErrorCallback(ErrorCallback callback) override;
    PerformanceMetricsPtr getPerformanceMetrics() const override;

    /**
     * @brief 获取当前系统指标快照
     * @return 系统性能指标
     */
    SystemMetrics getCurrentMetrics() const;

    /**
     * @brief 获取系统健康状态
     * @return 健康状态枚举
     */
    SystemHealthStatus getHealthStatus() const;

private:
    std::shared_ptr<IConfigManager> config_manager_;
    std::shared_ptr<IEventBus> event_bus_;
    std::shared_ptr<ILogger> logger_;

    std::unique_ptr<ExecutionEngine> execution_engine_;
    std::unique_ptr<ICollectionStrategy> collection_strategy_;
    std::unique_ptr<IAlertingStrategy> alerting_strategy_;
    std::unique_ptr<MetricsStore> metrics_store_;

    ModuleState current_state_{ModuleState::UNINITIALIZED};
    mutable std::mutex state_mutex_;

    void onCollectionTimer();
    void onConfigChanged(const std::string& key, const YAML::Node& value);
    void publishAlert(const AlertEvent& alert);
};

} // namespace radar::monitoring
```

### 4.2 ExecutionEngine驱动

采用标准的`ExecutionEngine`模式，通过定时器驱动监控数据收集和处理：

```mermaid
sequenceDiagram
    participant Engine as ExecutionEngine
    participant Timer as 定时器
    participant Collector as 收集策略
    participant Store as 指标存储
    participant Checker as 阈值检查器
    participant EventBus as 事件总线

    Note over Engine, EventBus: 监控主循环
    Engine->>Timer: 1. 启动定时器 (e.g., 1Hz)
    activate Timer
    loop 每个监控周期
        Timer-->>Engine: 2. 定时器触发
        Engine->>Collector: 3. collect()
        activate Collector
        Collector-->>Engine: 返回 SystemMetrics
        deactivate Collector

        Engine->>Store: 4. storeSnapshot(metrics)
        activate Store
        Store-->>Engine:
        deactivate Store

        Engine->>Checker: 5. checkThresholds(metrics)
        activate Checker
        alt 指标触发告警
            Checker->>EventBus: 6. publish(AlertTriggeredEvent)
            activate EventBus
            EventBus-->>Checker:
            deactivate EventBus
        else 指标正常
            Note over Checker: 无操作
        end
        Checker-->>Engine:
        deactivate Checker
    end
```

**ExecutionEngine实现**：
```cpp
namespace radar::monitoring {

/**
 * @brief 监控模块执行引擎
 * @details 驱动监控数据收集和告警检查的主循环
 */
class ExecutionEngine {
public:
    ExecutionEngine(
        std::shared_ptr<ICollectionStrategy> collector,
        std::shared_ptr<IAlertingStrategy> alerter,
        std::shared_ptr<MetricsStore> store,
        std::shared_ptr<ILogger> logger);

    /**
     * @brief 启动执行引擎
     * @param interval 收集间隔（默认1秒）
     */
    void start(std::chrono::milliseconds interval = std::chrono::milliseconds(1000));

    /**
     * @brief 停止执行引擎
     */
    void stop();

    /**
     * @brief 暂停监控
     */
    void pause();

    /**
     * @brief 恢复监控
     */
    void resume();

    /**
     * @brief 获取引擎状态
     */
    bool isRunning() const;

private:
    std::shared_ptr<ICollectionStrategy> collector_;
    std::shared_ptr<IAlertingStrategy> alerter_;
    std::shared_ptr<MetricsStore> store_;
    std::shared_ptr<ILogger> logger_;

    std::unique_ptr<std::thread> worker_thread_;
    std::atomic<bool> running_{false};
    std::atomic<bool> paused_{false};
    std::condition_variable cv_;
    std::mutex mutex_;

    void workerLoop(std::chrono::milliseconds interval);
    void collectAndProcess();
};

/**
 * @brief 收集策略接口
 */
class ICollectionStrategy {
public:
    virtual ~ICollectionStrategy() = default;

    /**
     * @brief 收集系统指标
     * @return 收集到的指标数据
     */
    virtual SystemMetrics collect() = 0;

    /**
     * @brief 配置更新通知
     * @param config 新的配置
     */
    virtual void updateConfig(const YAML::Node& config) = 0;
};

/**
 * @brief 系统资源收集器
 */
class SystemResourceCollector : public ICollectionStrategy {
public:
    SystemMetrics collect() override;
    void updateConfig(const YAML::Node& config) override;

private:
    float getCpuUsage();
    float getMemoryUsage();
    float getGpuUsage();
    uint64_t getProcessingLatency();
};

} // namespace radar::monitoring
```

### 4.3 性能指标收集

基于线程局部存储的高性能指标收集机制，避免锁竞争：

**指标数据结构**：
```cpp
namespace radar::monitoring {

/**
 * @brief 系统性能指标
 */
struct SystemMetrics {
    // 系统资源指标
    float cpu_usage_percent{0.0f};
    float memory_usage_percent{0.0f};
    float gpu_usage_percent{0.0f};

    // 业务性能指标
    uint64_t packets_received{0};
    uint64_t packets_processed{0};
    uint64_t packets_dropped{0};
    double avg_processing_latency_ms{0.0};

    // 错误统计
    uint32_t error_count{0};
    uint32_t warning_count{0};

    std::chrono::steady_clock::time_point timestamp;
};

/**
 * @brief 线程局部指标收集器
 * @details 每个线程独立收集指标，避免锁竞争
 */
class ThreadLocalMetrics {
public:
    /**
     * @brief 更新指标值
     * @param name 指标名称
     * @param value 指标值
     */
    static void updateMetric(const std::string& name, double value);

    /**
     * @brief 增加计数器
     * @param name 计数器名称
     * @param delta 增量（默认1）
     */
    static void incrementCounter(const std::string& name, uint64_t delta = 1);

    /**
     * @brief 记录延迟
     * @param name 延迟指标名称
     * @param latency_ms 延迟值（毫秒）
     */
    static void recordLatency(const std::string& name, double latency_ms);

    /**
     * @brief 获取线程本地指标快照
     * @return 当前线程的指标数据
     */
    static std::unordered_map<std::string, double> getThreadMetrics();

private:
    static thread_local std::unordered_map<std::string, double> local_metrics_;
};

/**
 * @brief 指标存储和聚合器
 */
class MetricsStore {
public:
    /**
     * @brief 聚合所有线程的指标
     * @return 聚合后的系统指标
     */
    SystemMetrics aggregateMetrics();

    /**
     * @brief 存储指标快照
     * @param metrics 要存储的指标
     */
    void storeSnapshot(const SystemMetrics& metrics);

    /**
     * @brief 获取历史指标
     * @param duration 查询时间范围
     * @return 指定时间范围内的指标历史
     */
    std::vector<SystemMetrics> getHistoricalMetrics(
        std::chrono::minutes duration) const;

private:
    mutable std::shared_mutex metrics_mutex_;
    SystemMetrics current_snapshot_;
    std::deque<SystemMetrics> historical_data_;
    static constexpr size_t MAX_HISTORY_SIZE = 3600; // 1小时历史

    void collectFromAllThreads();
    SystemMetrics calculateAggregates(
        const std::vector<std::unordered_map<std::string, double>>& thread_data);
};

} // namespace radar::monitoring
```

**使用示例**：
```cpp
// 在业务模块中更新指标 - 零锁开销
void DataProcessor::processPacket(const Packet& packet) {
    auto start_time = std::chrono::steady_clock::now();

    // 处理逻辑...

    auto end_time = std::chrono::steady_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(
        end_time - start_time).count();

    // 更新线程本地指标
    ThreadLocalMetrics::incrementCounter("packets_processed");
    ThreadLocalMetrics::recordLatency("processing_latency_ms", duration);
}

// 监控模块定期聚合
void MonitoringModule::onCollectionTimer() {
    TraceContextGuard guard(TraceContext::generateTraceId());

    RADAR_DEBUG(logger_, "Starting metrics collection cycle");

    // 从所有线程聚合指标
    auto metrics = metrics_store_->aggregateMetrics();

    RADAR_INFO(logger_, "Metrics collected - {cpu_usage={:.1f}%, memory_usage={:.1f}%, packets_processed={}}",
               metrics.cpu_usage_percent, metrics.memory_usage_percent, metrics.packets_processed);

    // 存储快照
    metrics_store_->storeSnapshot(metrics);

    // 检查告警
    alerting_strategy_->checkThresholds(metrics);
}
```

### 4.4 系统状态监控

基于健康评分的系统状态评估机制：

```cpp
namespace radar::monitoring {

/**
 * @brief 系统健康状态枚举
 */
enum class SystemHealthStatus {
    HEALTHY = 0,    // 系统健康：所有指标正常
    WARNING = 1,    // 系统警告：部分指标超出正常范围
    CRITICAL = 2,   // 系统严重：关键指标达到危险水平
    UNKNOWN = 3     // 状态未知：无法获取足够的监控数据
};

/**
 * @brief 系统状态报告
 */
struct SystemStatusReport {
    SystemHealthStatus overall_health;

    // 各子系统健康评分 (0.0 - 1.0)
    float cpu_health_score{1.0f};
    float memory_health_score{1.0f};
    float gpu_health_score{1.0f};
    float network_health_score{1.0f};

    // 业务健康评分
    float processing_health_score{1.0f};
    float throughput_health_score{1.0f};

    std::string status_message;
    std::chrono::steady_clock::time_point last_update;
    std::vector<std::string> active_issues; // 当前活跃的问题列表
};

/**
 * @brief 健康状态评估器
 */
class SystemHealthEvaluator {
public:
    /**
     * @brief 评估系统健康状态
     * @param metrics 当前系统指标
     * @return 系统状态报告
     */
    SystemStatusReport evaluateHealth(const SystemMetrics& metrics);

    /**
     * @brief 更新健康评估配置
     * @param config 健康评估配置
     */
    void updateConfig(const YAML::Node& config);

private:
    struct HealthThresholds {
        float warning_threshold{0.8f};    // 警告阈值
        float critical_threshold{0.95f};  // 严重阈值
        float recovery_threshold{0.7f};   // 恢复阈值
    };

    std::unordered_map<std::string, HealthThresholds> thresholds_;

    float calculateCpuHealth(float cpu_usage);
    float calculateMemoryHealth(float memory_usage);
    float calculateGpuHealth(float gpu_usage);
    float calculateProcessingHealth(const SystemMetrics& metrics);

    SystemHealthStatus determineOverallHealth(
        const std::vector<float>& health_scores);
    std::string generateStatusMessage(const SystemStatusReport& report);
};

} // namespace radar::monitoring
```

---

## 5 事件驱动告警机制

### 5.1 告警事件定义

基于事件总线的完全解耦告警机制，替代直接模块间调用：

```mermaid
graph TB
    subgraph "事件驱动告警架构"
        direction TB

        subgraph "告警检测层"
            THRESHOLD_CHECKER[ThresholdChecker<br/>阈值检查器]
            PATTERN_DETECTOR[PatternDetector<br/>模式检测器]
            ANOMALY_DETECTOR[AnomalyDetector<br/>异常检测器]
        end

        subgraph "事件发布层"
            ALERT_PUBLISHER[AlertEventPublisher<br/>告警事件发布器]
            EVENT_BUS[EventBus<br/>系统事件总线]
        end

        subgraph "事件消费层"
            LOG_HANDLER[LoggingHandler<br/>日志记录处理器]
            UI_HANDLER[UINotificationHandler<br/>界面通知处理器]
            ACTION_HANDLER[ActionHandler<br/>自动响应处理器]
        end

        %% 事件流
        THRESHOLD_CHECKER --> ALERT_PUBLISHER
        PATTERN_DETECTOR --> ALERT_PUBLISHER
        ANOMALY_DETECTOR --> ALERT_PUBLISHER

        ALERT_PUBLISHER --> EVENT_BUS

        EVENT_BUS --> LOG_HANDLER
        EVENT_BUS --> UI_HANDLER
        EVENT_BUS --> ACTION_HANDLER
    end

    classDef detector fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef publisher fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    classDef handler fill:#fff3e0,stroke:#ef6c00,stroke-width:2px

    class THRESHOLD_CHECKER,PATTERN_DETECTOR,ANOMALY_DETECTOR detector
    class ALERT_PUBLISHER,EVENT_BUS publisher
    class LOG_HANDLER,UI_HANDLER,ACTION_HANDLER handler
```

**告警事件结构定义**：
```cpp
namespace radar::events {

/**
 * @brief 告警级别枚举
 */
enum class AlertLevel {
    INFO = 0,       // 信息级别：一般性通知
    WARNING = 1,    // 警告级别：需要关注的问题
    CRITICAL = 2,   // 严重级别：需要立即处理的问题
    FATAL = 3       // 致命级别：系统可能无法继续运行
};

/**
 * @brief 告警事件
 * @details 所有告警通过此事件在系统中传递
 */
struct AlertTriggeredEvent : public SystemEvent {
    AlertLevel level;                    // 告警级别
    std::string source_module;          // 告警来源模块
    std::string metric_name;            // 相关指标名称
    double current_value;               // 当前值
    double threshold_value;             // 阈值
    std::string message;                // 告警描述
    std::chrono::steady_clock::time_point trigger_time; // 触发时间
    std::unordered_map<std::string, std::string> context; // 上下文信息

    // 继承自SystemEvent
    TraceId trace_id;                   // 追踪ID
    EventPriority priority{EventPriority::NORMAL}; // 事件优先级

    static constexpr const char* EVENT_TYPE = "AlertTriggered";

    const char* getEventType() const override { return EVENT_TYPE; }
};

/**
 * @brief 告警恢复事件
 * @details 当问题解决时发布此事件
 */
struct AlertResolvedEvent : public SystemEvent {
    std::string source_module;
    std::string metric_name;
    double resolved_value;
    std::chrono::steady_clock::time_point resolve_time;
    std::chrono::milliseconds duration; // 告警持续时间

    TraceId trace_id;

    static constexpr const char* EVENT_TYPE = "AlertResolved";
    const char* getEventType() const override { return EVENT_TYPE; }
};

} // namespace radar::events
```

### 5.2 告警策略引擎

基于可扩展策略的告警检测机制：

```cpp
namespace radar::monitoring {

/**
 * @brief 告警策略接口
 */
class IAlertingStrategy {
public:
    virtual ~IAlertingStrategy() = default;

    /**
     * @brief 检查指标并触发告警
     * @param metrics 当前系统指标
     * @return 生成的告警事件列表
     */
    virtual std::vector<AlertTriggeredEvent> checkThresholds(
        const SystemMetrics& metrics) = 0;

    /**
     * @brief 更新告警配置
     * @param config 新的告警配置
     */
    virtual void updateConfig(const YAML::Node& config) = 0;
};

/**
 * @brief 阈值检查策略
 * @details 基于配置阈值的告警检查实现
 */
class ThresholdAlertingStrategy : public IAlertingStrategy {
public:
    ThresholdAlertingStrategy(
        std::shared_ptr<IEventBus> event_bus,
        std::shared_ptr<ILogger> logger);

    std::vector<AlertTriggeredEvent> checkThresholds(
        const SystemMetrics& metrics) override;

    void updateConfig(const YAML::Node& config) override;

private:
    struct AlertRule {
        std::string metric_name;
        double warning_threshold;
        double critical_threshold;
        uint32_t consecutive_count{1};
        std::chrono::seconds cooldown{std::chrono::seconds(60)};

        // 状态跟踪
        uint32_t current_violations{0};
        AlertLevel current_level{AlertLevel::INFO};
        std::chrono::steady_clock::time_point last_alert_time;
    };

    std::shared_ptr<IEventBus> event_bus_;
    std::shared_ptr<ILogger> logger_;

    std::vector<AlertRule> alert_rules_;
    mutable std::mutex rules_mutex_;

    bool checkSingleRule(AlertRule& rule, double current_value);
    AlertTriggeredEvent createAlertEvent(
        const AlertRule& rule, double current_value, AlertLevel level);
    bool isInCooldown(const AlertRule& rule) const;
};

} // namespace radar::monitoring
```

### 5.3 事件总线集成

告警事件通过统一的事件总线发布，实现完全解耦：

```cpp
namespace radar::monitoring {

/**
 * @brief 告警事件发布器
 * @details 负责将检测到的告警转换为事件并发布
 */
class AlertEventPublisher {
public:
    AlertEventPublisher(
        std::shared_ptr<IEventBus> event_bus,
        std::shared_ptr<ILogger> logger);

    /**
     * @brief 发布告警事件
     * @param alert 告警事件
     */
    void publishAlert(const AlertTriggeredEvent& alert);

    /**
     * @brief 发布告警恢复事件
     * @param resolved 恢复事件
     */
    void publishResolved(const AlertResolvedEvent& resolved);

private:
    std::shared_ptr<IEventBus> event_bus_;
    std::shared_ptr<ILogger> logger_;

    void logAlertPublication(const AlertTriggeredEvent& alert);
};

// 在MonitoringModule中的使用
void MonitoringModule::onCollectionTimer() {
    TraceContextGuard guard(TraceContext::generateTraceId());

    // 收集指标
    auto metrics = metrics_store_->aggregateMetrics();

    // 检查告警 - 策略模式
    auto alerts = alerting_strategy_->checkThresholds(metrics);

    // 发布告警事件 - 事件驱动
    for (const auto& alert : alerts) {
        alert_publisher_->publishAlert(alert);

        RADAR_WARN(logger_, "Alert triggered: {} - {metric={}, current={:.2f}, threshold={:.2f}}",
                   alert.message, alert.metric_name, alert.current_value, alert.threshold_value);
    }
}

} // namespace radar::monitoring
```

**事件消费示例**：
```cpp
// 显控模块 - 订阅告警事件进行UI通知
class DisplayController : public IModule {
public:
    void initialize() override {
        // 订阅告警事件
        event_bus_->subscribe<AlertTriggeredEvent>(
            [this](const AlertTriggeredEvent& alert) {
                this->onAlertReceived(alert);
            });
    }

private:
    void onAlertReceived(const AlertTriggeredEvent& alert) {
        TraceContextGuard guard(alert.trace_id);

        RADAR_INFO(logger_, "Received alert notification: {}", alert.message);

        // 更新UI显示
        updateAlertIndicator(alert.level, alert.message);

        // 播放告警声音（如果是严重告警）
        if (alert.level >= AlertLevel::CRITICAL) {
            playAlertSound();
        }
    }
};
```

---

## 6 配置管理集成

### 6.1 ConfigManager集成

两个组件都通过`ConfigManager`获取配置，支持热更新：

**配置结构设计**：
```yaml
# configs/config.yaml - 统一配置文件
logging:
  level: "INFO"                    # 日志级别
  async_mode: true                 # 异步模式
  queue_size: 8192                 # 队列大小
  thread_count: 1                  # 后台线程数

  console:
    enabled: true                  # 控制台输出
    pattern: "[%Y-%m-%d %H:%M:%S.%e] [%l] [%n] [%t] %v"

  file:
    enabled: true                  # 文件输出
    path: "logs/radar.log"
    max_size: "100MB"
    max_files: 5
    pattern: "[%Y-%m-%d %H:%M:%S.%e] [%l] [%n] [%t] %v"

monitoring:
  enabled: true                    # 启用监控
  collection_interval: 1000        # 收集间隔(ms)

  thresholds:
    cpu_usage:
      warning: 80.0                # CPU警告阈值(%)
      critical: 95.0               # CPU严重阈值(%)
      consecutive_count: 3         # 连续违规次数
      cooldown: 60                 # 冷却时间(秒)

    memory_usage:
      warning: 85.0
      critical: 95.0
      consecutive_count: 3
      cooldown: 60

    gpu_usage:
      warning: 90.0
      critical: 98.0
      consecutive_count: 2
      cooldown: 30

  storage:
    enabled: false                 # 历史数据存储
    max_history_hours: 24          # 最大历史记录时间
```

### 6.2 配置热更新支持

两个组件都支持配置的实时热更新：

```cpp
namespace radar::logging {

/**
 * @brief LoggingService配置热更新
 */
class LoggingService : public ILogger {
public:
    ErrorCode initialize() override {
        // 获取初始配置
        auto config = config_manager_->getSection("logging");
        applyConfig(config);

        // 订阅配置变更事件
        config_manager_->subscribeToChanges("logging",
            [this](const std::string& key, const YAML::Node& value) {
                this->onConfigChanged(key, value);
            });

        return SystemErrors::SUCCESS;
    }

private:
    void onConfigChanged(const std::string& key, const YAML::Node& value) {
        TraceContextGuard guard(TraceContext::generateTraceId());

        RADAR_INFO(logger_, "Logging configuration changed: {}", key);

        if (key == "logging.level") {
            auto new_level = value.as<std::string>();
            setLevel(parseLogLevel(new_level));
        }
        else if (key == "logging.file.max_size") {
            // 动态调整文件大小限制
            auto new_size = value.as<std::string>();
            updateFileSizeLimit(new_size);
        }
        // ... 其他配置项的热更新处理
    }
};

} // namespace radar::logging

namespace radar::monitoring {

/**
 * @brief MonitoringModule配置热更新
 */
class MonitoringModule : public IModule {
private:
    void onConfigChanged(const std::string& key, const YAML::Node& value) {
        TraceContextGuard guard(TraceContext::generateTraceId());

        RADAR_INFO(logger_, "Monitoring configuration changed: {}", key);

        if (key.starts_with("monitoring.collection_interval")) {
            auto new_interval = value.as<int>();
            execution_engine_->updateInterval(std::chrono::milliseconds(new_interval));
        }
        else if (key.starts_with("monitoring.thresholds")) {
            // 更新告警阈值
            auto threshold_config = config_manager_->getSection("monitoring.thresholds");
            alerting_strategy_->updateConfig(threshold_config);
        }
    }
};

} // namespace radar::monitoring
```

---

## 7 依赖注入与生命周期

### 7.1 依赖关系设计

基于依赖注入的清晰依赖关系图：

```mermaid
graph TB
    subgraph "依赖注入架构"
        direction TB

        subgraph "main函数创建层"
            MAIN[main函数]
            CONFIG_MGR[ConfigManager]
            EVENT_BUS[EventBus]
            LOG_SVC[LoggingService]
        end

        subgraph "模块创建层"
            MON_MODULE[MonitoringModule]
            DATA_PROC[DataProcessor]
            SIGNAL_PROC[SignalProcessor]
        end

        subgraph "任务调度层"
            TASK_SCHEDULER[TaskScheduler]
        end

        %% 创建和注入关系
        MAIN --> CONFIG_MGR
        MAIN --> EVENT_BUS
        MAIN --> LOG_SVC

        CONFIG_MGR -.->|注入| LOG_SVC

        CONFIG_MGR -.->|注入| MON_MODULE
        EVENT_BUS -.->|注入| MON_MODULE
        LOG_SVC -.->|注入| MON_MODULE
        LOG_SVC -.->|注入| DATA_PROC
        LOG_SVC -.->|注入| SIGNAL_PROC

        MON_MODULE -.->|注册| TASK_SCHEDULER
        DATA_PROC -.->|注册| TASK_SCHEDULER
        SIGNAL_PROC -.->|注册| TASK_SCHEDULER
    end

    classDef main fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef module fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    claseDef scheduler fill:#fff3e0,stroke:#ef6c00,stroke-width:2px

    class MAIN,CONFIG_MGR,EVENT_BUS,LOG_SVC main
    class MON_MODULE,DATA_PROC,SIGNAL_PROC module
    class TASK_SCHEDULER scheduler
```

### 7.2 初始化与启动序列

清晰的组件创建和启动顺序：

```cpp
// main.cpp - 系统入口点
int main(int argc, char* argv[]) {
    try {
        // 第1步：创建核心基础设施
        auto config_manager = std::make_shared<ConfigManager>();
        config_manager->initialize("configs/config.yaml");

        auto event_bus = std::make_shared<EventBus>();
        event_bus->initialize();

        // 第2步：创建日志服务（最早创建，最晚销毁）
        auto logging_service = std::make_shared<LoggingService>(config_manager);
        logging_service->initialize();

        // 第3步：创建任务调度器
        auto task_scheduler = std::make_shared<TaskScheduler>(
            config_manager, event_bus, logging_service);
        task_scheduler->initialize();

        // 第4步：创建业务模块（注入日志服务）
        auto data_receiver = std::make_shared<DataReceiver>(
            config_manager, event_bus, logging_service);

        auto signal_processor = std::make_shared<SignalProcessor>(
            config_manager, event_bus, logging_service);

        auto data_processor = std::make_shared<DataProcessor>(
            config_manager, event_bus, logging_service);

        // 第5步：创建监控模块（依赖日志服务）
        auto monitoring_module = std::make_shared<MonitoringModule>(
            config_manager, event_bus, logging_service);

        // 第6步：注册所有模块到任务调度器
        task_scheduler->registerModule(data_receiver);
        task_scheduler->registerModule(signal_processor);
        task_scheduler->registerModule(data_processor);
        task_scheduler->registerModule(monitoring_module);

        // 第7步：启动系统
        task_scheduler->start();

        // 第8步：等待系统运行
        waitForShutdownSignal();

        // 第9步：优雅关闭（顺序与创建相反）
        task_scheduler->stop();
        task_scheduler->cleanup();

        monitoring_module->cleanup();
        data_processor->cleanup();
        signal_processor->cleanup();
        data_receiver->cleanup();

        event_bus->cleanup();
        logging_service->cleanup(); // 最后清理日志服务
        config_manager->cleanup();

        return 0;
    }
    catch (const std::exception& e) {
        std::cerr << "System initialization failed: " << e.what() << std::endl;
        return 1;
    }
}
```

**生命周期管理原则**：
1. **日志服务最早创建，最晚销毁**：确保所有组件都能记录日志
2. **配置管理器紧随其后**：为所有组件提供配置支持
3. **事件总线早期创建**：支持模块间通信
4. **业务模块按依赖顺序创建**：避免初始化时的依赖问题
5. **任务调度器统一管理模块生命周期**：标准化启动/停止流程

---

## 8 性能优化策略

**关键性能优化技术**：

| 优化技术       | 实现方式         | 性能提升     | 适用场景       |
| -------------- | ---------------- | ------------ | -------------- |
| **零开销日志** | 宏级别检查       | 禁用时零开销 | 调试/跟踪日志  |
| **异步写入**   | spdlog异步队列   | 延迟降低90%  | 高频日志记录   |
| **TLS指标**    | 线程局部存储     | 消除锁竞争   | 多线程指标更新 |
| **批量聚合**   | 定时批量处理     | 减少系统调用 | 指标收集和存储 |
| **事件异步**   | 事件总线异步分发 | 解耦处理延迟 | 告警通知       |
| **内存预分配** | 预分配缓冲区     | 减少动态分配 | 频繁对象创建   |

**具体优化实现**：
```cpp
// 1. 零开销日志宏
#define RADAR_DEBUG(logger, ...) \
    do { \
        if (LIKELY((logger) && (logger)->shouldLog(LogLevel::DEBUG))) { \
            (logger)->log(LogLevel::DEBUG, __VA_ARGS__); \
        } \
    } while(0)

// 2. 高性能指标更新
class ThreadLocalMetrics {
    static thread_local std::unordered_map<std::string, double> local_cache_;
    static thread_local uint32_t batch_counter_;

public:
    static void updateMetric(const std::string& name, double value) {
        local_cache_[name] = value;

        // 每100次更新批量刷新一次
        if (++batch_counter_ % 100 == 0) {
            MetricsAggregator::flushThreadMetrics(local_cache_);
            local_cache_.clear();
        }
    }
};

// 3. 事件异步发布
class AlertEventPublisher {
    void publishAlert(const AlertTriggeredEvent& alert) {
        // 异步发布，不阻塞监控主循环
        event_bus_->publishAsync(alert);
    }
};

// 4. 预分配内存池
class LogMessagePool {
    static constexpr size_t POOL_SIZE = 1000;
    std::array<LogMessage, POOL_SIZE> message_pool_;
    std::atomic<size_t> next_index_{0};

public:
    LogMessage* acquireMessage() {
        size_t index = next_index_.fetch_add(1) % POOL_SIZE;
        return &message_pool_[index];
    }
};
```

**性能目标与测量**：
- **日志写入延迟**: < 10ns (级别检查) + < 100ns (消息入队)
- **监控CPU开销**: < 0.5% (在1Hz收集频率下)
- **内存占用**: LoggingService < 10MB, MonitoringModule < 20MB
- **事件发布延迟**: < 1ms (异步发布到事件总线)

---

## 9 实现约束与限制

### 9.1 技术约束

**依赖库版本**：
- `spdlog`: >= 1.9.0 (支持异步日志和自定义格式)
- `yaml-cpp`: >= 0.7.0 (ConfigManager依赖)
- `fmt`: >= 8.0.0 (现代C++格式化支持)

**编译器要求**：
- C++17标准 (thread_local, structured binding等特性)
- GCC >= 9.0 或 MSVC >= 19.20
- 支持原子操作和线程安全特性

**平台支持**：
- Linux: 完全支持，包括系统资源监控
- Windows: 完全支持，包括Performance Counter集成
- 其他平台: 日志功能全支持，监控功能有限

### 9.2 架构约束

**接口一致性**：
- `LoggingService`必须实现`ILogger`接口
- `MonitoringModule`必须继承`IModule`接口
- 所有策略类必须实现对应的策略接口

**依赖关系**：
- 严禁全局单例和静态依赖
- 所有依赖必须通过构造函数注入
- 模块间通信只能通过事件总线

**生命周期管理**：
- `LoggingService`生命周期由`main`函数管理
- `MonitoringModule`生命周期由`TaskScheduler`管理
- 组件销毁顺序必须与创建顺序相反

### 9.3 性能约束

**实时性要求**：
- 日志记录不得阻塞业务线程超过1ms
- 监控数据收集不得影响数据处理性能
- 告警事件发布必须异步进行

**资源使用限制**：
- 日志服务总内存占用 < 50MB
- 监控模块CPU使用率 < 1%
- 事件队列长度 < 10000个事件

**可扩展性要求**：
- 支持运行时添加新的监控指标
- 支持热插拔告警策略
- 预留外部监控系统集成接口

### 9.4 MVP功能范围

**包含功能**：
- 基础的5级日志记录
- 系统资源监控（CPU、内存、GPU）
- 阈值基础告警
- 配置热更新
- Trace ID全链路追踪

**暂不包含**：
- 复杂的机器学习异常检测
- 分布式日志聚合
- 外部监控系统集成（Prometheus等）
- 日志内容分析和统计
- 高级可视化界面

---

## 10 相关文档

- [项目设计文档目录](../../README.md) - 完整设计文档索引

**注意**: 本文档为旧版本设计文档，部分引用的模块设计文档可能已迁移或重构。请参考最新的项目文档结构获取当前有效的设计文档。

---

## 11 变更历史

| 版本   | 日期       | 作者           | 变更描述                                                                                                                               |
| ------ | ---------- | -------------- | -------------------------------------------------------------------------------------------------------------------------------------- |
| v2.0.0 | 2025-09-25 | GitHub Copilot | **重大重构**：基于问题汇总全面重构。拆分日志/监控职责，移除全局单例，采用依赖注入，集成ConfigManager，实现事件驱动告警，完善追踪机制。 |
| v1.0.1 | 2025-09-23 | Kelin          | 去掉了接口设计部分的内容，简化了文档结构。                                                                                             |
| v1.0.0 | 2025-09-23 | Kelin          | 基于MVP设计文档创建日志监控模块设计，采用spdlog实现简化的异步日志和基础监控告警功能。                                                  |

**v2.0.0重构要点**：
1. **职责分离**：拆分为`LoggingService`和`MonitoringModule`两个独立组件
2. **架构统一**：采用项目标准的`IModule`接口和`ExecutionEngine`模式
3. **依赖注入**：完全移除`getInstance()`全局单例，改为构造函数注入
4. **配置集成**：与`ConfigManager`深度集成，支持热更新
5. **事件驱动**：告警通过事件总线发布，实现完全解耦
6. **性能优化**：引入TLS指标收集、零开销日志宏等高性能机制
7. **追踪完善**：基于`TraceContext`的完整全链路追踪支持

---

*本设计完全符合项目架构原则，提供高性能的日志记录服务和独立的系统监控模块，支持完整的可观测性和端到端追踪能力。*
