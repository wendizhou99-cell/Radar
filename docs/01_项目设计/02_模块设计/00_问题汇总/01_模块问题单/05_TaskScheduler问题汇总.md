
# 任务调度器模块 - 问题汇总

- **标题**: 任务调度器模块问题汇总
- **当前版本**: v2.0.0
- **最后更新**: 2025-09-25
- **负责人**: Kelin

---

## 演进摘要 (Evolution Summary)

本文档记录了任务调度器模块设计在历次架构审查中发现的关键问题。该模块作为系统的"神经中枢"，负责统一管理所有模块的生命周期、协调模块间通信和处理系统级异常。主要审查阶段包括：

- **v1.0.0 审查 (2025-09-25)**: 初始架构审查，发现5个关键问题，涉及轮询模型与事件驱动冲突、依赖管理不当、错误恢复策略粗糙等核心架构问题

---

## 快速导航

- [审查 v1.0.0 (2025-09-25)](#审查-v100-2025-09-25)

---

## 审查 v1.0.0 (2025-09-25)

### 问题1：【架构硬伤】采用"拉"模型（轮询）监控模块状态，与全系统事件驱动（"推"模型）架构完全相悖块设计 - 问题汇总

**文档版本**: v1.0.0
**创建日期**: 2025年9月25日
**负责人**: GitHub Copilot
**分析依据**: 基于已修复的《数据接收模块设计 (v1.2.0)》、《信号处理模块设计 (v1.1.0)》、《数据处理模块设计 (v1.2.0)》、《显控接口模块设计 (v2.0.0)》以及《核心设计原则》等项目核心文档，对《任务调度器设计 (v1.0.0)》进行全面审查。

---

### 问题1：【架构硬伤】采用“拉”模型（轮询）监控模块状态，与全系统事件驱动（“推”模型）架构完全相悖

- **问题描述**:
  文档在 `2.2 模块边界和约束` 中明确指出，任务调度器的输入包括“**通过接口调用获取的模块状态**”。`3.3 组件协作机制` 的序列图也显示调度器主动调用 `module.getStatus()`。这是一种典型的“拉”模型（Polling）。然而，所有已修复的核心模块（数据接收、信号处理、数据处理）都已重构为在发生关键状态变化或错误时，通过**系统事件总线**主动“推”送事件的模式。

- **深度分析**:
  1.  **架构不一致性**: 这是最严重的架构冲突。调度器作为系统的“神经中枢”，其信息获取方式与所有“末梢神经”（业务模块）的信息上报方式完全不匹配。这导致整个系统的通信模式混乱，一半是现代的事件驱动，一半是过时的轮询。
  2.  **性能与延迟问题**: 轮询模型存在固有缺陷。为了及时发现问题，调度器需要高频轮询所有模块，这会带来不必要的CPU开销和线程上下文切换。如果降低轮询频率，又会导致对模块故障的响应延迟增高，违反了系统对高可靠性和快速恢复的要求。
  3.  **紧耦合**: `getStatus()` 的接口调用方式，意味着调度器必须持有所有被管理模块的实例引用，并了解其具体的接口。这造成了调度器与业务模块之间的紧耦合。而事件总线模型则实现了完美的解耦，调度器只关心事件本身，不关心事件的来源。
  4.  **违反“决策者”角色**: “决策者”应该被动地接收信息并做出反应，而不是主动地四处“打探”消息。轮询模型让调度器承担了不必要的“信息采集”职责。

- **结论**:
  轮询模型是当前设计中最根本的架构缺陷。它不仅性能低下、响应迟缓，更重要的是，它与整个项目已经确立的、基于事件总线的异步通信架构背道而驰，必须彻底修正。

- **解决方案建议**:
  **将任务调度器彻底重构为基于系统事件总线的、被动的事件消费者。**
  1.  **移除轮询逻辑**:
      - 从 `任务调度器` 的主循环或定时器中，完全移除调用 `module.getStatus()` 的代码。
  2.  **成为事件监听者**:
      - `任务调度器` 在初始化时，向**系统事件总线**注册，订阅它关心的所有事件，例如：
          - `MODULE_FATAL_ERROR` (来自任何模块)
          - `MODULE_STATUS_UPDATE` (如模块进入 `Degraded` 状态)
          - `ALARM_TRIGGERED` (如错误率超阈值)
          - `USER_COMMAND` (来自显控模块)
          - `CONFIG_CHANGE_REQUEST` (来自显控模块)
  3.  **实现事件处理器**:
      - 在 `任务调度器` 中实现一个或多个事件处理器方法（如 `onModuleFailed(const ModuleFailedEvent& event)`）。
      - 所有的决策逻辑都应在这些事件处理器中被触发。例如，收到 `MODULE_FATAL_ERROR` 事件后，才开始执行相应的恢复策略。
  4.  **维护内部状态视图**:
      - 调度器内部可以维护一个 `std::map<ModuleID, ModuleStatus>` 来缓存它所知道的各模块的最新状态。
      - 这个状态视图**仅通过监听到的事件来更新**，而不是通过轮询。

  **优势**:
  - **架构统一**: 与所有已修复模块采用完全一致的事件驱动模型，降低了系统复杂度和认知负荷。
  - **高性能与低延迟**: 零CPU开销的等待，事件发生时立即响应，无轮询延迟。
  - **完全解耦**: 调度器与业务模块之间通过事件总线解耦，模块的增删不影响调度器核心代码。

---

### 问题2：【职责不清】“策略管理器”定义空泛，与算法模块的策略模式存在功能重叠

- **问题描述**:
  文档 `3.1 组件组织结构` 中定义了一个 `策略管理器 (Policy Manager)`，其职责是“管理和选择调度策略、恢复策略”。然而，已修复的 `信号处理` 和 `数据处理` 模块已经实现了基于配置和工厂的**算法策略**选择机制。这造成了职责上的混淆和潜在冲突。

- **深度分析**:
  1.  **职责重叠**: “选择算法策略”的职责到底归谁？是 `数据处理模块` 根据自己的配置选择关联算法，还是 `任务调度器` 的 `策略管理器` 来命令它选择？当前设计对此描述不清。
  2.  **违反分层原则**: 根据单一职责原则，`数据处理模块` 应该自主管理其内部的算法流水线。`任务调度器` 作为更高层次的协调者，不应深入到“应该用JPDA还是GNN”这种微观的算法选择细节中。它应该只在需要时，下达一个更宏观的指令，如“切换到高精度模式”。
  3.  **设计空泛**: `策略管理器` 管理的“调度策略”和“恢复策略”是什么？是硬编码的 `if-else` 逻辑，还是可配置的规则？文档完全没有展开，使其成为一个无法实现的概念。

- **结论**:
  `策略管理器` 的定义模糊不清，且其潜在职责与下层模块已经明确的策略模式存在冲突和重叠，破坏了系统的分层和职责划分。

- **解决方案建议**:
  **撤销 `策略管理器` 组件，将其职责分解并重新分配到更合适的组件中。**
  1.  **算法策略选择 -> 由业务模块自行负责**:
      - `信号处理`、`数据处理` 等模块在初始化时，根据自己的配置文件（通过 `ConfigManager` 读取）构建自己的 `AlgorithmPipeline`。这是模块的内部事务。
  2.  **恢复策略 -> 重构为 `RecoveryEngine`**:
      - 创建一个新的、职责明确的组件 `恢复引擎 (RecoveryEngine)`。
      - `RecoveryEngine` 内部持有一系列**恢复预案 (Recovery Plans)**。这些预案可以硬编码，或更好地，通过配置文件定义。
      - **示例配置**:
        ```yaml
        # configs/recovery_plans.yaml
        plans:
          - event: MODULE_FATAL_ERROR
            source_module: DataReceiver
            error_code: NET_BIND_ERROR
            actions:
              - type: restart_module
                delay_ms: 5000
                max_retries: 3
              - type: system_shutdown
                if_retries_failed: true
          - event: ALARM_TRIGGERED
            source_module: SignalProcessor
            alarm_type: GPU_TEMP_HIGH
            actions:
              - type: issue_command
                target_module: SignalProcessor
                command: "SWITCH_TO_LOW_POWER_MODE"
        ```
      - 当 `任务调度器` 的事件处理器收到错误事件时，它将事件传递给 `RecoveryEngine`。`RecoveryEngine` 匹配预案并执行相应的动作序列。
  3.  **调度策略 -> 融入 `SchedulerCore`**:
      - 核心的调度逻辑（如线程优先级分配、任务分发）应直接在 `调度核心 (SchedulerCore)` 中实现。

  **优势**:
  - **职责清晰**: `RecoveryEngine` 专职负责错误恢复，`SchedulerCore` 专职负责任务调度，业务模块专职负责算法选择。
  - **配置驱动**: 将复杂的恢复逻辑外部化到配置文件中，使其更易于理解、修改和扩展。
  - **架构简化**: 移除了一个模糊的“管理器”，代之以职责明确的组件和配置。

---

### 问题3：【耦合与性能】与下游模块的控制接口设计不当，存在同步调用风险

- **问题描述**:
  文档 `3.3 组件协作机制` 的序列图中，`任务调度器` 通过直接调用 `module.start()`、`module.stop()` 等方法来管理模块生命周期。

- **深度分析**:
  1.  **同步阻塞风险**: `module.start()` 或 `module.stop()` 方法的执行可能是耗时的。例如，`信号处理模块`的 `start()` 可能需要加载CUDA上下文、预分配GPU内存，耗时数百毫秒。`数据接收模块`的 `stop()` 可能需要等待网络缓冲区排空。如果 `任务调度器` 的主线程同步调用这些方法，将导致调度器自身被**长时间阻塞**，无法响应其他事件或命令。
  2.  **紧耦合**: 这种直接调用的方式，要求 `任务调度器` 必须持有所有模块的实例指针，形成了紧耦合。
  3.  **缺乏状态反馈**: `start()` 调用返回后，模块真的就进入 `Running` 状态了吗？可能它还在初始化的某个阶段。同步调用无法优雅地处理这种异步的状态转换过程。

- **结论**:
  同步的、直接的接口调用方式是一种简单但脆弱的设计。它会阻塞调度器，并使其与被调度模块紧密耦合，不符合高性能、高可用系统的设计要求。

- **解决方案建议**:
  **采用基于事件的、异步的命令分发和状态反馈机制。**
  1.  **命令通过事件总线分发**:
      - `任务调度器` 不再直接调用 `module.start()`。
      - 当需要启动一个模块时，调度器向**系统事件总线**发布一个 `START_MODULE_COMMAND` 事件，事件负载中包含目标模块的ID。
  2.  **模块监听并执行命令**:
      - 每个模块都实现了 `IModule` 接口，并在内部监听发给自己的命令事件。
      - 收到 `START_MODULE_COMMAND` 后，模块开始执行其启动流程。这个启动流程应该是**异步的**。
  3.  **异步状态上报**:
      - 模块在启动过程中，会经历多个内部状态（如 `Initializing`, `WaitingForNetwork`, `LoadingResources`）。每当状态发生变化，它都应通过事件总线发布一个 `MODULE_STATUS_UPDATE` 事件。
      - 当启动流程**完全成功**后，模块发布 `MODULE_STATUS_UPDATE(Running)` 事件。
      - 如果启动过程中**发生失败**，模块发布 `MODULE_FATAL_ERROR` 事件。
  4.  **调度器监听状态反馈**:
      - `任务调度器` 监听所有模块的状态更新事件，并据此更新其内部的系统状态视图。
      - 它可以设置一个超时定时器。如果在发出 `START_MODULE_COMMAND` 后的指定时间内没有收到 `Running` 或 `Failed` 的状态反馈，就认为该模块启动超时，并触发相应的恢复策略。

  **优势**:
  - **完全异步**: 调度器线程在发出命令后立即返回，绝不阻塞。
  - **完全解耦**: 调度器与模块之间通过事件总线通信，无需直接引用。
  - **精确的状态追踪**: 通过监听状态更新事件，调度器可以精确地了解每个模块的实时状态，而不是依赖于一个同步调用的返回值。

---

### 问题4：【设计缺陷】“资源管理器”职责过窄，未能管理系统级关键资源

- **问题描述**:
  文档 `3.2 组件职责分工` 中，`资源管理器 (Resource Manager)` 的职责被描述为“**CPU和内存资源的分配与监控**”。这一定义过于狭隘，忽略了本系统中更关键、更需要协调的资源。

- **深度分析**:
  1.  **忽略了GPU资源**: 在本系统中，GPU是比CPU更稀缺、更需要精细管理的计算资源。`信号处理模块` 需要大量GPU资源，`显控模块` 也需要GPU进行渲染。如果调度器不参与GPU资源的宏观协调（例如，在GPU负载过高时，命令显控模块降级渲染质量），就可能发生资源争抢，导致关键的信号处理任务性能下降。
  2.  **忽略了共享内存资源**: `数据接收模块` 和 `信号处理模块` 之间通过大型的页锁定内存池进行零拷贝通信。这个内存池是一个跨模块的**共享资源**。其大小、分配策略直接影响系统性能和稳定性。将这个关键资源的配置和监控排除在调度器的管理范围之外，是一个严重的设计疏忽。
  3.  **CPU/内存管理不切实际**: 现代操作系统已经有非常成熟的CPU调度器和内存管理器。一个应用层面的“资源管理器”去“分配CPU资源”通常是不切实际的，除非涉及到绑核（CPU Affinity）等高级操作。其更现实的职责应该是**监控**而非**分配**。

- **结论**:
  `资源管理器` 的设计与其名称不符，抓小放大。它关注于难以管理的通用资源（CPU/内存），却忽略了最需要系统级协调的关键资源（GPU、共享内存池）。

- **解决方案建议**:
  **重构 `资源管理器`，使其专注于系统级的、跨模块的关键资源协调。**
  1.  **更名为 `SystemResourceCoordinator`**: 新名称更准确地反映其“协调者”而非“分配者”的角色。
  2.  **明确核心职责**:
      - **GPU资源协调**:
          - 监控全局GPU利用率、显存使用率、温度（通过监听各模块上报的性能指标事件）。
          - 根据系统运行模式（如“最大性能模式”、“低功耗模式”）或实时负载，向 `信号处理模块` 和 `显控模块` 发送命令，调整它们的资源使用策略（例如，`显控模块` 切换到低质量渲染，`信号处理模块` 限制并行流的数量）。
      - **共享内存池监控**:
          - 在系统启动时，根据配置决定关键共享内存池（如 `DataReceiver` 和 `SignalProcessor` 之间的缓冲区）的大小。
          - 监控这些内存池的使用情况（如高水位线触发频率），并在资源紧张时发出告警。
      - **CPU亲和性配置**:
          - 在系统启动时，根据配置文件中的策略，向关键模块（如 `I/O线程`、`计算工作线程`）下达绑核指令，以减少上下文切换和提高缓存效率。

  **优势**:
  - **职责明确**: 专注于真正需要系统级协调的关键资源。
  - **系统级优化**: 能够从全局视角进行资源权衡，避免模块间的资源冲突，确保关键任务的性能。
  - **设计可行**: 将职责从不切实际的“分配”转变为可行的“监控”和“协调”。

---

### 问题5：【设计模糊】“生命周期管理器”与模块自身的生命周期管理混淆

- **问题描述**:
  文档 `3.1` 和 `3.2` 中定义了 `生命周期管理器 (Lifecycle Manager)`，负责“模块的启动、停止、重启”。然而，每个模块自身都实现了 `IModule` 接口，该接口已经包含了 `initialize`, `start`, `stop` 等生命周期方法。这造成了逻辑上的冗余和混淆。

- **深度分析**:
  1.  **逻辑冗余**: “管理模块生命周期”的逻辑应该在哪里？是在调度器的一个专用组件里，还是在调度器的主逻辑（`SchedulerCore`）里？单独设立一个 `Lifecycle Manager` 似乎是多余的，因为调度器的核心职责之一就是管理模块的生命周期。
  2.  **与异步命令模型冲突**: 在问题 #3 提出的异步命令模型下，调度器只是发布 `START_MODULE_COMMAND` 等事件。真正的生命周期状态转换发生在模块内部。调度器需要的是一个**状态机**来追踪它所了解的系统状态，而不是一个“管理器”去“执行”生命周期动作。
  3.  **命名混淆**: `数据处理模块` 中有一个 `TrackLifecycleManager`，负责管理**航迹**的生命周期。`任务调度器` 中又有一个 `Lifecycle Manager`，负责管理**模块**的生命周期。这种命名上的相似性极易引起混淆。

- **结论**:
  `生命周期管理器` 是一个职责不清、逻辑冗余的组件。其功能应被一个更清晰的系统状态机模型所取代。

- **解决方案建议**:
  **移除 `生命周期管理器`，引入一个明确的系统级状态机 (System State Machine)。**
  1.  **移除 `Lifecycle Manager` 组件**: 从架构图中删除该组件。
  2.  **在 `SchedulerCore` 中实现系统状态机**:
      - `SchedulerCore` 内部维护一个状态机，描述整个**系统**的生命周期状态，例如：`Idle`, `Initializing`, `Running`, `Degraded`, `ShuttingDown`, `Failed`。
      - `SchedulerCore` 还维护所有**模块**的状态视图（见问题 #1 的解决方案）。
  3.  **状态转换由事件驱动**:
      - **系统启动**: 用户发出“启动”命令 -> `SchedulerCore` 状态转为 `Initializing` -> 调度器向所有模块发布 `START_MODULE_COMMAND`。
      - **运行中**: 当调度器收到所有模块的 `MODULE_STATUS_UPDATE(Running)` 事件后 -> `SchedulerCore` 状态转为 `Running`。
      - **模块失败**: 调度器收到某个模块的 `MODULE_FATAL_ERROR` 事件 -> `SchedulerCore` 状态转为 `Degraded` -> 触发 `RecoveryEngine` 执行恢复策略。
      - **恢复成功**: `RecoveryEngine` 成功重启模块，调度器收到该模块的 `Running` 事件 -> 如果所有其他模块也正常 -> `SchedulerCore` 状态恢复为 `Running`。
      - **恢复失败**: `RecoveryEngine` 恢复失败 -> `SchedulerCore` 状态转为 `Failed` -> 执行安全关闭流程。

  **优势**:
  - **逻辑清晰**: 用一个标准的状态机模型取代了一个模糊的“管理器”，使系统行为的变迁变得可预测和可形式化验证。
  - **职责单一**: `SchedulerCore` 的核心职责就是驱动这个状态机。
  - **消除冗余**: 移除了一个不必要的组件，简化了架构。

---

### 问题6：【错误处理不完备】恢复策略过于简单，缺乏对依赖关系和恢复顺序的考量

- **问题描述**:
  文档 `6.2 恢复策略` 中提到了“重启失败模块”、“切换到备用模块”等策略，但这些策略都过于原子化，没有考虑模块之间的依赖关系。

- **深度分析**:
  1.  **忽略依赖链**: 系统中的模块存在明确的数据流依赖关系：`数据接收 -> 信号处理 -> 数据处理`。如果 `信号处理模块` 失败了，仅仅重启它是不够的，甚至可能是错误的。因为上游的 `数据接收模块` 可能仍在向其缓冲区写入数据，而下游的 `数据处理模块` 可能因为无数据输入而超时。
  2.  **恢复顺序错误**: 正确的恢复顺序至关重要。例如，在恢复一个数据处理管道时，应首先暂停生产者（上游模块），然后清空缓冲区，接着重启或恢复故障模块，最后再恢复生产者。当前的设计没有体现出任何关于**恢复顺序**的逻辑。
  3.  **“切换到备用模块”不现实**: “备用模块”是一个非常重的概念，它意味着系统中同时运行着两套实现。在没有详细设计支持（如接口、资源隔离）的情况下，这只是一个空想。更现实的策略是“切换到降级模式”。

- **结论**:
  恢复策略的设计过于天真，没有认识到在一个存在依赖关系的分布式系统中，恢复是一个需要精确编排的**协同过程**，而不是一个简单的单点操作。

- **解决方案建议**:
  **在 `RecoveryEngine` 中引入基于依赖图的、有序的恢复工作流。**
  1.  **定义模块依赖图**:
      - 在 `任务调度器` 的配置中，明确定义模块间的依赖关系。
      - **示例配置**:
        ```yaml
        # configs/module_dependencies.yaml
        dependencies:
          - upstream: DataReceiver
            downstream: SignalProcessor
            buffer: raw_data_buffer
          - upstream: SignalProcessor
            downstream: DataProcessor
            buffer: detection_result_buffer
        ```
  2.  **设计恢复工作流 (Recovery Workflows)**:
      - `RecoveryEngine` 的预案（见问题 #2）不再是单个 `action`，而是一个 `workflow`。
      - **示例预案**:
        ```yaml
        # configs/recovery_plans.yaml
        plans:
          - event: MODULE_FATAL_ERROR
            source_module: SignalProcessor
            workflow:
              - action: issue_command
                target: upstream(SignalProcessor) # 查找依赖图，目标是DataReceiver
                command: "PAUSE_PRODUCING"
              - action: wait_for_event
                event: MODULE_STATUS_UPDATE
                source: upstream(SignalProcessor)
                status: Paused
                timeout_ms: 5000
              - action: restart_module
                target: SignalProcessor
              - action: wait_for_event
                event: MODULE_STATUS_UPDATE
                source: SignalProcessor
                status: Running
                timeout_ms: 10000
              - action: issue_command
                target: upstream(SignalProcessor)
                command: "RESUME_PRODUCING"
        ```
  3.  **实现工作流执行器**:
      - `RecoveryEngine` 内部需要一个简单的执行器，可以按顺序执行工作流中的步骤，并处理等待、超时等逻辑。

  **优势**:
  - **恢复过程可靠**: 通过明确定义依赖关系和恢复顺序，确保了在恢复过程中系统状态的一致性，避免了数据丢失或状态错乱。
  - **策略可配置**: 复杂的恢复流程被清晰地定义在配置文件中，易于理解和修改。
  - **设计严谨**: 将恢复操作从一个简单的动作提升为一个经过精心编排的工作流，体现了对分布式系统复杂性的深刻理解。

---

### 问题7：【设计模糊】系统模式（如“正常”、“诊断”、“低功耗”）的定义和切换机制缺失

- **问题描述**:
  一个复杂的实时系统通常需要在不同的全局模式下运行，例如“正常运行模式”、“性能诊断模式”、“低功耗模式”等。不同的模式下，各模块的行为（如日志级别、算法选择、资源使用）应有所不同。`任务调度器` 作为系统的“大脑”，理应负责管理和切换这些模式，但当前设计完全没有提及这个概念。

- **深度分析**:
  1.  **缺乏全局协调能力**: 如果没有统一的系统模式，当需要进行性能分析时，运维人员可能需要手动修改每个模块的配置来开启详细日志或性能剖析，操作繁琐且容易出错。
  2.  **无法实现场景化策略**: 系统无法根据外部环境（如电源状态、威胁等级）或用户指令，在不同策略集之间进行整体切换。例如，无法一键切换到“静默模式”，在该模式下所有模块都降低功耗。
  3.  **与配置管理脱节**: 模式切换的本质是批量地、协调地改变一系列配置参数。当前设计缺乏一个机制来组织和应用这些“配置集”。

- **结论**:
  系统模式管理的缺失，使得 `任务调度器` 缺少了一个关键的宏观调控手段，系统的灵活性和可运维性大打折扣。

- **解决方案建议**:
  **在 `任务调度器` 中引入系统运行模式 (System Mode) 的概念和管理机制。**
  1.  **在配置中定义模式**:
      - 在 `config.yaml` 中定义不同的系统模式，每个模式下包含对各模块参数的覆写。
      - **示例配置**:
        ```yaml
        # configs/system_modes.yaml
        modes:
          normal:
            # 默认配置
          diagnostic:
            DataReceiver:
              log_level: "trace"
            SignalProcessor:
              performance_monitor: "enabled"
            DataProcessor:
              log_level: "debug"
          low_power:
            SignalProcessor:
              pipeline:
                - type: "fft_low_power_v1"
            DisplayController:
              render_quality: "low"
        ```
  2.  **在 `SchedulerCore` 中管理当前模式**:
      - `SchedulerCore` 维护一个 `current_mode` 变量。
      - 提供一个接口（或通过事件响应）来切换模式，如 `setSystemMode("diagnostic")`。
  3.  **实现模式切换工作流**:
      - 当 `setSystemMode` 被调用时，`任务调度器` 执行以下流程：
          1.  从配置文件中加载目标模式的参数覆写集。
          2.  遍历这个参数集，对每一个变更的参数，通过**系统事件总线**发布一个 `CONFIG_CHANGED` 事件。
          3.  各模块监听到发给自己的 `CONFIG_CHANGED` 事件后，动态地应用新配置（热更新）。
  4.  **与 `ConfigManager` 协同**:
      - `ConfigManager` 负责提供基础配置。
      - `任务调度器` 负责在基础配置之上，应用当前模式的“补丁”，并将最终生效的配置通过事件分发出去。

  **优势**:
  - **宏观调控**: 赋予了调度器对系统进行整体行为模式切换的能力。
  - **简化运维**: 运维人员只需一条命令即可让整个系统进入特定模式，极大简化了调试和管理。
  - **场景自适应**: 为未来根据环境变化自动切换系统模式提供了架构基础。

---

### 问题8：【可观测性缺失】缺乏对调度器自身性能和决策过程的监控

- **问题描述**:
  文档中，`任务调度器` 被定位为监控和管理其他模块的角色，但完全没有提及**如何监控调度器自身**。

- **深度分析**:
  1.  **调度器成为监控黑洞**: 如果调度器自身的事件处理队列堵塞、决策逻辑耗时过长、或恢复工作流卡死，整个系统的可靠性将无从谈起。没有对自身的监控，调度器就成了一个无法观测的“单点故障”。
  2.  **决策无法追溯**: 当系统出现异常行为时，运维人员需要知道“调度器当时收到了什么事件？它做出了什么决策？执行了哪个恢复预案？”。当前设计没有提供任何机制来记录和查询这些关键的决策日志。
  3.  **性能瓶颈无法定位**: 调度器主循环或事件处理器的性能是系统响应能力的关键。如果这部分出现性能问题，将直接影响到对所有模块故障的响应速度。

- **结论**:
  对自身可观测性的忽视，使得 `任务调度器` 的设计存在严重缺陷，它无法保证自身的可靠性和性能，也无法为事后排障提供依据。

- **解决方案建议**:
  **将可观测性原则应用于任务调度器自身，实现全面的自监控和决策追踪。**
  1.  **监控关键性能指标**:
      - **事件队列深度**: 监控内部事件队列的长度，队列积压是过载的明确信号。
      - **事件处理延迟**: 记录从事件入队到处理器开始执行的时间差，衡量调度器的响应速度。
      - **处理器执行耗时**: 测量每个事件处理器（如 `onModuleFailed`）的执行时间，定位耗时逻辑。
      - **工作流执行耗时**: 记录每个恢复工作流的总执行时间。
      - 这些指标应定期通过**系统事件总线**发布（是的，调度器也向总线发布自己的状态），供 `日志监控模块` 消费。
  2.  **实现决策日志 (Decision Logging)**:
      - 在调度器的所有关键决策点，使用 `RADAR_INFO` 或 `RADAR_DEBUG` 记录结构化的决策日志，并**必须包含 Trace ID**。
      - **示例日志**:
        ```log
        [INFO] [TaskScheduler] Event received: MODULE_FATAL_ERROR, source: SignalProcessor, trace_id: {xyz}.
        [INFO] [TaskScheduler] Matched recovery plan: "RESTART_GPU_MODULE", trace_id: {xyz}.
        [INFO] [TaskScheduler] Executing workflow step 1: PAUSE_PRODUCING for DataReceiver, trace_id: {xyz}.
        ...
        [INFO] [TaskScheduler] Recovery workflow "RESTART_GPU_MODULE" completed successfully, trace_id: {xyz}.
        ```
  3.  **提供状态查询接口 (可选)**:
      - 提供一个轻量级的、非阻塞的查询接口或通过事件发布，允许外部（如CLI工具或UI）查询调度器的当前状态、正在执行的工作流、以及各模块的状态视图。

  **优势**:
  - **消除监控盲点**: 使调度器自身成为一个透明、可观测的组件。
  - **快速排障**: 详细的决策日志为复盘系统行为、诊断疑难杂症提供了不可或缺的线索。
  - **性能保障**: 通过对内部延迟和队列的监控，可以及时发现并解决调度器自身的性能瓶颈。

---

### 问题9：【实现细节缺失】Trace ID 的传递与使用未定义，导致调度决策无法与数据链路关联

- **问题描述**:
  所有已修复的模块都强调了 `Trace ID` 的生成、传递和记录，以实现端到端的可观测性。然而，`任务调度器` 的设计中完全没有提及它如何处理和使用从事件中获得的 `Trace ID`。

- **深度分析**:
  1.  **决策与数据脱钩**: 假设 `数据处理模块` 在处理某一帧数据时发生滤波器发散，并上报了 `FILTER_DIVERGENCE` 错误事件。这个事件必然携带了导致问题的 `Trace ID`。如果 `任务调度器` 在收到事件后，其后续的决策日志（如“开始重启数据处理模块”）中不包含这个 `Trace ID`，那么“数据处理失败”和“系统执行恢复”这两条关键信息链就断开了。
  2.  **无法进行根本原因分析**: `Trace ID` 的核心价值在于将一个业务流程（如一帧数据的处理）中所有相关的日志串联起来。如果调度器的日志是孤立的，就无法回答“是什么样的输入数据最终导致了这次模块重启？”这样的关键问题。
  3.  **违反核心设计原则**: 《核心设计原则》和已修复模块的设计都将端到端追踪作为一项基本要求。`任务调度器` 作为系统事件的核心处理者，其对 `Trace ID` 的忽视，直接破坏了这一原则的落地。

- **结论**:
  `Trace ID` 传递链在 `任务调度器` 这一环的中断，是一个严重的设计疏忽。它使得调度器的所有行为都成了“无源之水”，无法与导致这些行为的具体数据处理过程关联起来，极大地削弱了系统的可诊断性。

- **解决方案建议**:
  **将 `Trace ID` 的传递和记录作为任务调度器事件处理的强制要求。**
  1.  **事件负载必须包含 `Trace ID`**:
      - 强制要求所有模块上报的事件（特别是错误和状态更新事件）的数据结构中，必须包含生成该事件的 `Trace ID`。
  2.  **在事件处理器中传递 `Trace ID`**:
      - `任务调度器` 的所有事件处理器，如 `onModuleFailed(const ModuleFailedEvent& event)`，必须从传入的 `event` 对象中提取 `trace_id`。
  3.  **在日志和新事件中传播 `Trace ID`**:
      - 在事件处理器内部，所有由 `RADAR_*` 宏记录的日志，都必须包含这个 `trace_id`。
      - 如果该事件处理器触发了新的动作（例如，向另一个模块发布命令事件），那么新创建的命令事件中也**必须复制并传递**这个 `trace_id`。
      - 这确保了从“故障发生”到“恢复完成”的整个因果链都由同一个 `Trace ID` 串联。
  4.  **使用线程局部存储 (Thread-Local Storage)**:
      - 为了简化日志记录，可以在事件处理线程的入口处，将 `trace_id` 设置到一个线程局部存储的上下文中。这样，该线程中后续的所有日志宏都可以自动地从中获取并记录 `Trace ID`，而无需在每个日志点手动传递。

  **优势**:
  - **完整的因果链追踪**: 实现了从“数据进入”->“处理失败”->“调度器决策”->“恢复动作”->“恢复完成”的全链路追踪。
  - **高效的根本原因分析**: 任何一个系统级的恢复动作，都可以通过 `Trace ID` 快速反向追溯到最初是哪一帧数据、哪个模块、哪一行代码出了问题。
  - **架构一致性**: 与项目中其他所有模块的可观测性设计保持了完全一致。

---

### 问题10：【设计不一致】组件命名与职责描述与已修复模块存在偏差

- **问题描述**:
  文档中的组件命名和职责划分，与已修复的 `数据接收`、`信号处理` 等模块中采用的模式存在不一致，增加了项目的认知负荷。

- **深度分析**:
  1.  **驱动核心命名不一**: 在已修复的模块中，驱动数据流的核心组件被统一命名为 `ExecutionEngine`。而 `任务调度器` 的设计中，这个核心驱动者被称为 `调度核心 (SchedulerCore)`，虽然职责类似，但命名不统一。
  2.  **“管理器”泛滥**: 设计中出现了 `模块管理器`、`资源管理器`、`策略管理器`、`生命周期管理器` 等多个“管理器”，但它们的职责要么模糊（策略管理器），要么冗余（生命周期管理器），要么与其他模块的同名组件（如数据处理的`TrackLifecycleManager`）产生混淆。这种命名方式未能清晰地反映其真实职责。
  3.  **分层逻辑不一致**: 已修复模块都采用了清晰的“执行层”、“算法/策略层”、“资源/状态管理层”的逻辑分层。而 `任务调度器` 的“四层模型” (`决策控制层`, `资源管理层`, `生命周期层`, `通信接口层`) 与前两者无法完全对应，导致架构风格不统一。

- **结论**:
  设计语言和模式的不统一，是典型的“设计熵增”表现。它会增加开发人员理解和维护项目的难度，降低代码复用性，需要及早纠正以保持整个项目架构的优雅和一致。

- **解决方案建议**:
  **全面采用已在项目中建立的设计语言和架构模式。**
  1.  **统一核心驱动者命名**:
      - 将 `调度核心 (SchedulerCore)` 重命名为 `ExecutionEngine`，以反映其作为模块主循环和事件驱动核心的本质，与其他模块保持一致。
  2.  **精简和重命名“管理器”**:
      - 根据上述问题的分析，移除 `策略管理器` 和 `生命周期管理器`。
      - 将 `资源管理器` 重命名为 `SystemResourceCoordinator`，明确其协调职责。
      - 将 `模块管理器` 的职责（维护模块列表和状态视图）并入 `ExecutionEngine`，因为这是其驱动状态机的核心数据。
  3.  **统一分层模型**:
      - 废弃“四层模型”，转而采用与其他模块一致的、更简洁的逻辑分层：
          - **执行层**: `ExecutionEngine` (包含系统状态机逻辑)。
          - **策略/逻辑层**: `RecoveryEngine` (作为恢复策略的执行者)。
          - **资源/状态管理层**: `SystemResourceCoordinator` (协调跨模块资源)，`ConfigManager` (访问配置)。
          - **监控/控制层**: `PerformanceMonitor` (监控自身性能)，`ErrorHandler`。

  **优势**:
  - **降低认知负荷**: 整个项目使用一套统一的设计语言和架构模式，开发者可以快速理解任何一个模块的设计。
  - **提升代码复用**: 像 `ExecutionEngine`、`ErrorHandler` 这些基础架构组件，其设计思想甚至部分代码实现都可以在不同模块间共享。
  - **易于维护**: 一致的架构使得定位问题、增加功能、进行重构都变得更加简单和可预测。
